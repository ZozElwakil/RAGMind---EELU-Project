
----- FILE: .claude\settings.local.json -----
size: 1423 bytes | mtime: 2025-12-28T12:51:36.556095

{
  "permissions": {
    "allow": [
      "Bash(git status:*)",
      "Bash(git add:*)",
      "Bash(git commit:*)",
      "Bash(git push:*)",
      "Bash(git pull:*)",
      "Bash(git branch:*)",
      "Bash(git checkout:*)",
      "Bash(git remote:*)",
      "Bash(git check-ignore:*)",
      "Bash(git rm:*)",
      "Bash(git stash:*)",
      "Bash(git ls-tree:*)",
      "Bash(ls:*)",
      "Bash(mkdir:*)",
      "Bash(mv:*)",
      "Bash(cp:*)",
      "Bash(rm:*)",
      "Bash(chmod:*)",
      "Bash(touch:*)",
      "Bash(cat:*)",
      "Bash(grep:*)",
      "Bash(rg:*)",
      "Bash(find:*)",
      "Bash(sed:*)",
      "Bash(awk:*)",
      "Bash(npm install:*)",
      "Bash(npm run:*)",
      "Bash(npm test:*)",
      "Bash(npm run build:*)",
      "Bash(npm run compile:*)",
      "Bash(npm run watch:*)",
      "Bash(npm run check-types:*)",
      "Bash(npm run lint:*)",
      "Bash(npm run check-circular:*)",
      "Bash(npx tsc:*)",
      "Bash(npx tsx:*)",
      "Bash(npx madge:*)",
      "Bash(node:*)",
      "Bash(jq:*)",
      "Bash(curl:*)",
      "Bash(python3:*)",
      "Bash(plutil:*)",
      "WebFetch(domain:docs.anthropic.com)",
      "WebFetch(domain:raw.githubusercontent.com)",
      "WebFetch(domain:docs.voyageai.com)"
    ],
    "deny": []
  },
  "allowedTools": [],
  "ignorePatterns": [],
  "enableAllProjectMcpServers": false
}
----- END FILE -----

----- FILE: .codersinflow\index.json -----
size: 230 bytes | mtime: 2025-12-28T12:51:36.557094

[
  {
    "id": "task-1766910527320-2kjhsxd",
    "number": 1,
    "description": "New conversation",
    "status": "active",
    "startTime": 1766910527320,
    "lastAccessed": 1766910527514,
    "messageCount": 0
  }
]
----- END FILE -----

----- FILE: .codersinflow\tasks\task-task-1766910527320-2kjhsxd\context.json -----
size: 58 bytes | mtime: 2025-12-28T12:51:36.558094

{
  "mode_id": "code_mode",
  "profile_id": "default"
}
----- END FILE -----

----- FILE: .codersinflow\tasks\task-task-1766910527320-2kjhsxd\display-log.index.json -----
size: 94 bytes | mtime: 2025-12-28T12:51:36.559093

{
  "version": 1,
  "messageCount": 0,
  "lastModified": 1766910528320,
  "entries": []
}
----- END FILE -----

----- FILE: .codersinflow\tasks\task-task-1766910527320-2kjhsxd\messages.json -----
size: 2 bytes | mtime: 2025-12-28T12:51:36.560093

[]
----- END FILE -----

----- FILE: .codersinflow\tasks\task-task-1766910527320-2kjhsxd\metadata.json -----
size: 206 bytes | mtime: 2025-12-28T12:51:36.560093

{
  "id": "task-1766910527320-2kjhsxd",
  "number": 1,
  "description": "New conversation",
  "startTime": 1766910527320,
  "status": "active",
  "lastAccessed": 1766910527514,
  "messageCount": 0
}
----- END FILE -----

----- FILE: ALL_CODE_CLI.txt -----
size: 184156 bytes | mtime: 2025-12-28T17:42:31.735645

=== .claude\settings.local.json ===
{
  "permissions": {
    "allow": [
      "Bash(git status:*)",
      "Bash(git add:*)",
      "Bash(git commit:*)",
      "Bash(git push:*)",
      "Bash(git pull:*)",
      "Bash(git branch:*)",
      "Bash(git checkout:*)",
      "Bash(git remote:*)",
      "Bash(git check-ignore:*)",
      "Bash(git rm:*)",
      "Bash(git stash:*)",
      "Bash(git ls-tree:*)",
      "Bash(ls:*)",
      "Bash(mkdir:*)",
      "Bash(mv:*)",
      "Bash(cp:*)",
      "Bash(rm:*)",
      "Bash(chmod:*)",
      "Bash(touch:*)",
      "Bash(cat:*)",
      "Bash(grep:*)",
      "Bash(rg:*)",
      "Bash(find:*)",
      "Bash(sed:*)",
      "Bash(awk:*)",
      "Bash(npm install:*)",
      "Bash(npm run:*)",
      "Bash(npm test:*)",
      "Bash(npm run build:*)",
      "Bash(npm run compile:*)",
      "Bash(npm run watch:*)",
      "Bash(npm run check-types:*)",
      "Bash(npm run lint:*)",
      "Bash(npm run check-circular:*)",
      "Bash(npx tsc:*)",
      "Bash(npx tsx:*)",
      "Bash(npx madge:*)",
      "Bash(node:*)",
      "Bash(jq:*)",
      "Bash(curl:*)",
      "Bash(python3:*)",
      "Bash(plutil:*)",
      "WebFetch(domain:docs.anthropic.com)",
      "WebFetch(domain:raw.githubusercontent.com)",
      "WebFetch(domain:docs.voyageai.com)"
    ],
    "deny": []
  },
  "allowedTools": [],
  "ignorePatterns": [],
  "enableAllProjectMcpServers": false
}

=== .codersinflow\tasks\task-task-1766910527320-2kjhsxd\context.json ===
{
  "mode_id": "code_mode",
  "profile_id": "default"
}

=== .codersinflow\tasks\task-task-1766910527320-2kjhsxd\display-log.index.json ===
{
  "version": 1,
  "messageCount": 0,
  "lastModified": 1766910528320,
  "entries": []
}

=== .codersinflow\tasks\task-task-1766910527320-2kjhsxd\messages.json ===
[]

=== .codersinflow\tasks\task-task-1766910527320-2kjhsxd\metadata.json ===
{
  "id": "task-1766910527320-2kjhsxd",
  "number": 1,
  "description": "New conversation",
  "startTime": 1766910527320,
  "status": "active",
  "lastAccessed": 1766910527514,
  "messageCount": 0
}

=== .codersinflow\index.json ===
[
  {
    "id": "task-1766910527320-2kjhsxd",
    "number": 1,
    "description": "New conversation",
    "status": "active",
    "startTime": 1766910527320,
    "lastAccessed": 1766910527514,
    "messageCount": 0
  }
]

=== .vscode\settings.json ===
{
    "diffEditor.renderSideBySide": false,
    "diffEditor.experimental.showMoves": true,
    "scm.diffDecorationsGutterAction": "diff"
}

=== backend\controllers\__init__.py ===
"""Controllers package initialization."""
from backend.controllers.project_controller import ProjectController
from backend.controllers.document_controller import DocumentController
from backend.controllers.query_controller import QueryController

__all__ = ["ProjectController", "DocumentController", "QueryController"]

=== backend\controllers\document_controller.py ===
"""
Document Controller.
Business logic for document upload and processing.
"""
from typing import Optional, List
from sqlalchemy import select
from sqlalchemy.ext.asyncio import AsyncSession
from backend.database.models import Asset, Chunk, Project
from backend.services.file_service import FileService
from backend.services.document_loader import DocumentLoaderService
from backend.services.chunking_service import ChunkingService
from backend.services.embedding_service import EmbeddingService
from backend.providers.vectordb.factory import VectorDBProviderFactory
from datetime import datetime
import logging

logger = logging.getLogger(__name__)


class DocumentController:
    """Controller for document operations."""
    
    def __init__(self):
        """Initialize document controller."""
        self.file_service = FileService()
        self.document_loader = DocumentLoaderService()
        self.chunking_service = ChunkingService()
        self.embedding_service = EmbeddingService()
        self.vector_db = VectorDBProviderFactory.create_provider()
    
    async def upload_document(
        self,
        db: AsyncSession,
        project_id: int,
        file_content: bytes,
        filename: str,
        file_size: int
    ) -> Asset:
        """
        Upload document and save metadata.
        
        Args:
            db: Database session
            project_id: Project ID
            file_content: File content bytes
            filename: Original filename
            file_size: File size in bytes
            
        Returns:
            Created asset
            
        Raises:
            ValueError: If validation fails
        """
        try:
            # Validate file
            is_valid, error_msg = self.file_service.validate_file(filename, file_size)
            if not is_valid:
                raise ValueError(error_msg)
            
            # Check project exists
            project_stmt = select(Project).where(Project.id == project_id)
            project_result = await db.execute(project_stmt)
            project = project_result.scalar_one_or_none()
            if not project:
                raise ValueError(f"Project not found: {project_id}")
            
            # Save file
            unique_filename, file_path = await self.file_service.save_upload_file(
                file_content=file_content,
                filename=filename,
                project_id=project_id
            )
            
            # Get file type
            from pathlib import Path
            file_type = Path(filename).suffix.lstrip('.')
            
            # Create asset record
            asset = Asset(
                project_id=project_id,
                filename=unique_filename,
                original_filename=filename,
                file_path=file_path,
                file_size=file_size,
                file_type=file_type,
                status="uploaded"
            )
            
            db.add(asset)
            await db.commit()
            await db.refresh(asset)
            
            logger.info(f"Uploaded document: {asset.id} - {filename}")
            return asset
            
        except Exception as e:
            await db.rollback()
            logger.error(f"Error uploading document: {str(e)}")
            raise
    
    async def process_document(
        self,
        db: AsyncSession,
        asset_id: int
    ) -> bool:
        """
        Process document: extract, chunk, embed, and store.
        
        Args:
            db: Database session
            asset_id: Asset ID
            
        Returns:
            True if successful
        """
        try:
            # Get asset
            asset_stmt = select(Asset).where(Asset.id == asset_id)
            asset_result = await db.execute(asset_stmt)
            asset = asset_result.scalar_one_or_none()
            
            if not asset:
                raise ValueError(f"Asset not found: {asset_id}")
            
            # Update status to processing
            asset.status = "processing"
            await db.commit()
            
            try:
                # Extract text
                logger.info(f"Extracting text from {asset.original_filename}")
                text = await self.document_loader.load_document(asset.file_path)
                
                # Chunk text
                logger.info(f"Chunking text ({len(text)} characters)")
                chunks_data = await self.chunking_service.chunk_document(
                    text=text,
                    document_name=asset.original_filename,
                    additional_metadata={
                        'file_type': asset.file_type,
                        'asset_id': asset.id
                    }
                )
                
                # Create chunk records
                chunk_records = []
                for i, chunk_data in enumerate(chunks_data):
                    chunk = Chunk(
                        project_id=asset.project_id,
                        asset_id=asset.id,
                        content=chunk_data['content'],
                        chunk_index=i,
                        extra_metadata=chunk_data['metadata']
                    )
                    db.add(chunk)
                    chunk_records.append(chunk)
                
                await db.commit()
                
                # Refresh to get IDs
                for chunk in chunk_records:
                    await db.refresh(chunk)
                
                # Generate embeddings
                logger.info(f"Generating embeddings for {len(chunk_records)} chunks")
                texts = [chunk.content for chunk in chunk_records]
                embeddings = await self.embedding_service.generate_embeddings(texts)
                
                # Store embeddings in chunks and vector DB
                chunk_ids = [chunk.id for chunk in chunk_records]
                await self.vector_db.add_vectors(
                    collection_name=f"project_{asset.project_id}",
                    vectors=embeddings,
                    ids=chunk_ids
                )
                
                # Update asset status
                asset.status = "completed"
                asset.processed_at = datetime.utcnow()
                await db.commit()
                
                logger.info(f"Completed processing document: {asset.id}")
                return True
                
            except Exception as e:
                # Mark as failed
                asset.status = "failed"
                asset.error_message = str(e)
                await db.commit()
                raise
                
        except Exception as e:
            logger.error(f"Error processing document: {str(e)}")
            raise
    
    async def get_document(
        self,
        db: AsyncSession,
        asset_id: int
    ) -> Optional[Asset]:
        """
        Get document by ID.
        
        Args:
            db: Database session
            asset_id: Asset ID
            
        Returns:
            Asset or None
        """
        try:
            stmt = select(Asset).where(Asset.id == asset_id)
            result = await db.execute(stmt)
            return result.scalar_one_or_none()
            
        except Exception as e:
            logger.error(f"Error getting document: {str(e)}")
            raise
    
    async def list_project_documents(
        self,
        db: AsyncSession,
        project_id: int
    ) -> List[Asset]:
        """
        List all documents in project.
        
        Args:
            db: Database session
            project_id: Project ID
            
        Returns:
            List of assets
        """
        try:
            stmt = select(Asset).where(Asset.project_id == project_id).order_by(Asset.created_at.desc())
            result = await db.execute(stmt)
            return list(result.scalars().all())
            
        except Exception as e:
            logger.error(f"Error listing documents: {str(e)}")
            raise
    
    async def delete_document(
        self,
        db: AsyncSession,
        asset_id: int
    ) -> bool:
        """
        Delete document and associated chunks.
        
        Args:
            db: Database session
            asset_id: Asset ID
            
        Returns:
            True if deleted
        """
        try:
            # Get asset
            asset = await self.get_document(db, asset_id)
            if not asset:
                return False
            
            # Delete file
            await self.file_service.delete_file(asset.file_path)
            
            # Delete from database (cascade will delete chunks)
            await db.delete(asset)
            await db.commit()
            
            logger.info(f"Deleted document: {asset_id}")
            return True
            
        except Exception as e:
            await db.rollback()
            logger.error(f"Error deleting document: {str(e)}")
            raise

=== backend\controllers\project_controller.py ===
"""
Project Controller.
Business logic for project management.
"""
from typing import List, Optional, Dict, Any
from sqlalchemy import select, delete
from sqlalchemy.ext.asyncio import AsyncSession
from backend.database.models import Project, Asset, Chunk
from backend.services.file_service import FileService
from datetime import datetime
import logging

logger = logging.getLogger(__name__)


class ProjectController:
    """Controller for project operations."""
    
    def __init__(self):
        """Initialize project controller."""
        self.file_service = FileService()
    
    async def create_project(
        self,
        db: AsyncSession,
        name: str,
        description: Optional[str] = None,
        metadata: Optional[Dict[str, Any]] = None
    ) -> Project:
        """
        Create a new project.
        
        Args:
            db: Database session
            name: Project name
            description: Optional description
            metadata: Optional metadata
            
        Returns:
            Created project
        """
        try:
            project = Project(
                name=name,
                description=description,
                extra_metadata=metadata or {}
            )
            
            db.add(project)
            await db.commit()
            await db.refresh(project)
            
            logger.info(f"Created project: {project.id} - {project.name}")
            return project
            
        except Exception as e:
            await db.rollback()
            logger.error(f"Error creating project: {str(e)}")
            raise
    
    async def get_project(
        self,
        db: AsyncSession,
        project_id: int
    ) -> Optional[Project]:
        """
        Get project by ID.
        
        Args:
            db: Database session
            project_id: Project ID
            
        Returns:
            Project or None
        """
        try:
            stmt = select(Project).where(Project.id == project_id)
            result = await db.execute(stmt)
            project = result.scalar_one_or_none()
            
            return project
            
        except Exception as e:
            logger.error(f"Error getting project: {str(e)}")
            raise
    
    async def list_projects(
        self,
        db: AsyncSession,
        skip: int = 0,
        limit: int = 100
    ) -> List[Project]:
        """
        List all projects.
        
        Args:
            db: Database session
            skip: Number of projects to skip
            limit: Maximum number of projects to return
            
        Returns:
            List of projects
        """
        try:
            stmt = select(Project).offset(skip).limit(limit).order_by(Project.created_at.desc())
            result = await db.execute(stmt)
            projects = result.scalars().all()
            
            return list(projects)
            
        except Exception as e:
            logger.error(f"Error listing projects: {str(e)}")
            raise
    
    async def update_project(
        self,
        db: AsyncSession,
        project_id: int,
        name: Optional[str] = None,
        description: Optional[str] = None,
        metadata: Optional[Dict[str, Any]] = None
    ) -> Optional[Project]:
        """
        Update project.
        
        Args:
            db: Database session
            project_id: Project ID
            name: Optional new name
            description: Optional new description
            metadata: Optional new metadata
            
        Returns:
            Updated project or None
        """
        try:
            project = await self.get_project(db, project_id)
            if not project:
                return None
            
            if name is not None:
                project.name = name
            if description is not None:
                project.description = description
            if metadata is not None:
                project.extra_metadata = metadata
            
            project.updated_at = datetime.utcnow()
            
            await db.commit()
            await db.refresh(project)
            
            logger.info(f"Updated project: {project_id}")
            return project
            
        except Exception as e:
            await db.rollback()
            logger.error(f"Error updating project: {str(e)}")
            raise
    
    async def delete_project(
        self,
        db: AsyncSession,
        project_id: int
    ) -> bool:
        """
        Delete project and all associated data.
        
        Args:
            db: Database session
            project_id: Project ID
            
        Returns:
            True if deleted successfully
        """
        try:
            # Delete files from storage
            await self.file_service.delete_project_files(project_id)
            
            # Delete from database (cascade will handle assets and chunks)
            stmt = delete(Project).where(Project.id == project_id)
            result = await db.execute(stmt)
            await db.commit()
            
            deleted = result.rowcount > 0
            if deleted:
                logger.info(f"Deleted project: {project_id}")
            
            return deleted
            
        except Exception as e:
            await db.rollback()
            logger.error(f"Error deleting project: {str(e)}")
            raise
    
    async def get_project_stats(
        self,
        db: AsyncSession,
        project_id: int
    ) -> Dict[str, Any]:
        """
        Get project statistics.
        
        Args:
            db: Database session
            project_id: Project ID
            
        Returns:
            Statistics dictionary
        """
        try:
            # Get asset count
            asset_stmt = select(Asset).where(Asset.project_id == project_id)
            asset_result = await db.execute(asset_stmt)
            assets = asset_result.scalars().all()
            
            # Get chunk count
            chunk_stmt = select(Chunk).where(Chunk.project_id == project_id)
            chunk_result = await db.execute(chunk_stmt)
            chunks = chunk_result.scalars().all()
            
            return {
                'asset_count': len(assets),
                'chunk_count': len(chunks),
                'total_size': sum(a.file_size for a in assets),
                'completed_assets': sum(1 for a in assets if a.status == 'completed'),
                'processing_assets': sum(1 for a in assets if a.status == 'processing'),
                'failed_assets': sum(1 for a in assets if a.status == 'failed')
            }
            
        except Exception as e:
            logger.error(f"Error getting project stats: {str(e)}")
            raise

=== backend\controllers\query_controller.py ===
"""
Query Controller.
Business logic for query processing and answer generation.
"""
from typing import Dict, Any, Optional
from sqlalchemy.ext.asyncio import AsyncSession
from backend.services.query_service import QueryService
from backend.services.answer_service import AnswerService
import logging

logger = logging.getLogger(__name__)


class QueryController:
    """Controller for query operations."""
    
    def __init__(self):
        """Initialize query controller."""
        self.query_service = QueryService()
        self.answer_service = AnswerService()
    
    async def answer_query(
        self,
        db: AsyncSession,
        project_id: int,
        query: str,
        top_k: int = 5,
        language: str = "ar",
        asset_id: Optional[int] = None
    ) -> Dict[str, Any]:
        """
        Process query and generate answer.
        
        Args:
            db: Database session
            project_id: Project ID to search in
            query: User question
            top_k: Number of chunks to retrieve
            language: Response language ('ar' or 'en')
            asset_id: Optional specific document to search
            
        Returns:
            Dictionary with answer and metadata
        """
        try:
            # Search for relevant chunks
            logger.info(f"Processing query for project {project_id}: {query[:50]}...")
            
            similar_chunks = await self.query_service.search_similar_chunks(
                query=query,
                project_id=project_id,
                top_k=top_k,
                asset_id=asset_id
            )
            
            if not similar_chunks:
                return {
                    'answer': 'لم أتمكن من العثور على معلومات ذات صلة في المستندات.' if language == 'ar' 
                             else 'Could not find relevant information in the documents.',
                    'sources': [],
                    'context_used': 0
                }
            
            # Generate answer
            result = await self.answer_service.generate_answer(
                query=query,
                context_chunks=similar_chunks,
                language=language,
                include_sources=True
            )
            
            logger.info(f"Generated answer for query (used {result['context_used']} chunks)")
            return result
            
        except Exception as e:
            logger.error(f"Error processing query: {str(e)}")
            raise

=== backend\database\__init__.py ===
"""Database package initialization."""
from backend.database.models import Base, Project, Asset, Chunk
from backend.database.connection import engine, async_session_maker, get_db, init_db, close_db

__all__ = [
    "Base",
    "Project",
    "Asset",
    "Chunk",
    "engine",
    "async_session_maker",
    "get_db",
    "init_db",
    "close_db"
]

=== backend\database\connection.py ===
"""
Database connection management with async SQLAlchemy.
Provides engine and session factory.
"""
from sqlalchemy.ext.asyncio import create_async_engine, AsyncSession, async_sessionmaker
from sqlalchemy.pool import NullPool
from backend.config import settings
import logging

logger = logging.getLogger(__name__)

# Create async engine
engine = create_async_engine(
    settings.database_url,
    echo=False,  # Set to True for SQL query logging
    poolclass=NullPool,  # Use NullPool for async or configure pool
    future=True
)

# Create async session factory
async_session_maker = async_sessionmaker(
    engine,
    class_=AsyncSession,
    expire_on_commit=False,
    autocommit=False,
    autoflush=False
)


async def get_db() -> AsyncSession:
    """
    Dependency function to get database session.
    Use with FastAPI Depends().
    """
    async with async_session_maker() as session:
        try:
            yield session
            await session.commit()
        except Exception:
            await session.rollback()
            raise
        finally:
            await session.close()


async def init_db():
    """Initialize database - create tables if they don't exist."""
    from backend.database.models import Base
    from sqlalchemy import text
    try:
        async with engine.begin() as conn:
            # Enable pgvector extension
            await conn.execute(text("CREATE EXTENSION IF NOT EXISTS vector"))
            
            # Create all tables
            await conn.run_sync(Base.metadata.create_all)
            logger.info("Database initialized successfully with pgvector")
    except Exception as e:
        logger.warning(f"Could not initialize pgvector extension: {str(e)}")
        logger.info("Attempting to initialize other tables...")
        try:
            async with engine.begin() as conn:
                # Try to create tables one by one or skip those that fail
                await conn.run_sync(Base.metadata.create_all)
                logger.info("Database tables initialized (some might have failed)")
        except Exception as e2:
            logger.error(f"Failed to initialize database tables: {str(e2)}")


async def close_db():
    """Close database connections."""
    await engine.dispose()
    logger.info("Database connections closed")

=== backend\database\models.py ===
"""
Database models using SQLAlchemy async ORM.
Defines tables for projects, assets, and chunks with vector embeddings.
"""
from sqlalchemy import Column, Integer, String, Text, DateTime, ForeignKey, Float, JSON, LargeBinary
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.orm import relationship
from sqlalchemy.sql import func
from pgvector.sqlalchemy import Vector
from datetime import datetime

Base = declarative_base()


class Project(Base):
    """Project model for organizing documents."""
    __tablename__ = "projects"
    
    id = Column(Integer, primary_key=True, index=True)
    name = Column(String(255), nullable=False, index=True)
    description = Column(Text, nullable=True)
    created_at = Column(DateTime(timezone=True), server_default=func.now())
    updated_at = Column(DateTime(timezone=True), onupdate=func.now())
    
    # Metadata (renamed to avoid conflict with SQLAlchemy metadata)
    extra_metadata = Column("metadata", JSON, default={})
    
    # Relationships
    assets = relationship("Asset", back_populates="project", cascade="all, delete-orphan")
    chunks = relationship("Chunk", back_populates="project", cascade="all, delete-orphan")
    
    def __repr__(self):
        return f"<Project(id={self.id}, name='{self.name}')>"


class Asset(Base):
    """Asset model for uploaded documents."""
    __tablename__ = "assets"
    
    id = Column(Integer, primary_key=True, index=True)
    project_id = Column(Integer, ForeignKey("projects.id", ondelete="CASCADE"), nullable=False)
    
    # File information
    filename = Column(String(500), nullable=False)
    original_filename = Column(String(500), nullable=False)
    file_path = Column(String(1000), nullable=False)
    file_size = Column(Integer, nullable=False)  # in bytes
    file_type = Column(String(50), nullable=False)  # pdf, txt, docx
    
    # Status
    status = Column(String(50), default="uploaded")  # uploaded, processing, completed, failed
    error_message = Column(Text, nullable=True)
    
    # Timestamps
    created_at = Column(DateTime(timezone=True), server_default=func.now())
    processed_at = Column(DateTime(timezone=True), nullable=True)
    
    # Metadata (renamed to avoid conflict)
    extra_metadata = Column("metadata", JSON, default={})
    
    # Relationships
    project = relationship("Project", back_populates="assets")
    chunks = relationship("Chunk", back_populates="asset", cascade="all, delete-orphan")
    
    def __repr__(self):
        return f"<Asset(id={self.id}, filename='{self.filename}', status='{self.status}')>"


class Chunk(Base):
    """Chunk model for text chunks with vector embeddings."""
    __tablename__ = "chunks"
    
    id = Column(Integer, primary_key=True, index=True)
    project_id = Column(Integer, ForeignKey("projects.id", ondelete="CASCADE"), nullable=False)
    asset_id = Column(Integer, ForeignKey("assets.id", ondelete="CASCADE"), nullable=False)
    
    # Content
    content = Column(Text, nullable=False)
    chunk_index = Column(Integer, nullable=False)  # Position in document
    
    # Vector embedding (stored as JSON/List for compatibility if pgvector is missing)
    # Vector search is handled by Qdrant if pgvector is not available
    embedding = Column(JSON, nullable=True)
    
    # Metadata (renamed to avoid conflict)
    extra_metadata = Column("metadata", JSON, default={})  # page_number, section, etc.
    
    # Timestamps
    created_at = Column(DateTime(timezone=True), server_default=func.now())
    
    # Relationships
    project = relationship("Project", back_populates="chunks")
    asset = relationship("Asset", back_populates="chunks")
    
    def __repr__(self):
        return f"<Chunk(id={self.id}, asset_id={self.asset_id}, chunk_index={self.chunk_index})>"

=== backend\providers\llm\__init__.py ===
"""LLM providers package."""
from backend.providers.llm.interface import LLMInterface
from backend.providers.llm.gemini_provider import GeminiProvider
from backend.providers.llm.factory import LLMProviderFactory

__all__ = ["LLMInterface", "GeminiProvider", "LLMProviderFactory"]

=== backend\providers\llm\factory.py ===
"""
LLM Provider Factory.
Creates LLM provider instances based on configuration.
"""
from backend.providers.llm.interface import LLMInterface
from backend.providers.llm.gemini_provider import GeminiProvider
from backend.config import settings
import logging

logger = logging.getLogger(__name__)


class LLMProviderFactory:
    """Factory for creating LLM provider instances."""
    
    @staticmethod
    def create_provider(provider_name: str = None) -> LLMInterface:
        """
        Create LLM provider instance.
        
        Args:
            provider_name: Name of provider ('gemini', 'openai', etc.)
                          Defaults to settings.llm_provider
        
        Returns:
            LLM provider instance
            
        Raises:
            ValueError: If provider name is not supported
        """
        provider_name = provider_name or settings.llm_provider
        provider_name = provider_name.lower()
        
        if provider_name == "gemini":
            logger.info("Creating Gemini LLM provider")
            return GeminiProvider()
        
        # Add more providers here as needed
        # elif provider_name == "openai":
        #     return OpenAIProvider()
        # elif provider_name == "cohere":
        #     return CohereProvider()
        
        else:
            raise ValueError(f"Unsupported LLM provider: {provider_name}")
    
    @staticmethod
    def get_available_providers() -> list:
        """Get list of available provider names."""
        return ["gemini"]  # Add more as implemented

=== backend\providers\llm\gemini_provider.py ===
"""
Google Gemini 2.5 Flash LLM Provider Implementation.
Uses google-generativeai SDK for text generation and embeddings.
"""
from typing import List, Optional
import google.generativeai as genai
from backend.providers.llm.interface import LLMInterface
from backend.config import settings
import logging
import asyncio

logger = logging.getLogger(__name__)


class GeminiProvider(LLMInterface):
    """Google Gemini LLM provider implementation."""
    
    def __init__(self, api_key: str = None, model_name: str = None):
        """
        Initialize Gemini provider.
        
        Args:
            api_key: Gemini API key (defaults to settings)
            model_name: Model name (defaults to settings)
        """
        self.api_key = api_key or settings.gemini_api_key
        self.model_name = model_name or settings.gemini_model
        
        # Configure Gemini
        genai.configure(api_key=self.api_key)
        
        # Initialize models
        self.chat_model = genai.GenerativeModel(self.model_name)
        self.embedding_model = "models/text-embedding-004"
        
        logger.info(f"Gemini provider initialized with model: {self.model_name}")
    
    async def generate_text(
        self,
        prompt: str,
        system_prompt: Optional[str] = None,
        temperature: float = 0.7,
        max_tokens: Optional[int] = None,
        **kwargs
    ) -> str:
        """
        Generate text using Gemini.
        
        Args:
            prompt: User prompt
            system_prompt: System instruction
            temperature: Sampling temperature
            max_tokens: Maximum output tokens
            
        Returns:
            Generated text
        """
        try:
            # Combine system prompt and user prompt
            full_prompt = prompt
            if system_prompt:
                full_prompt = f"{system_prompt}\n\n{prompt}"
            
            # Configure generation
            generation_config = genai.GenerationConfig(
                temperature=temperature,
                max_output_tokens=max_tokens or 2048,
            )
            
            # Generate response (run in thread pool for async)
            loop = asyncio.get_event_loop()
            response = await loop.run_in_executor(
                None,
                lambda: self.chat_model.generate_content(
                    full_prompt,
                    generation_config=generation_config
                )
            )
            
            return response.text
            
        except Exception as e:
            logger.error(f"Error generating text with Gemini: {str(e)}")
            raise
    
    async def generate_embeddings(
        self,
        texts: List[str],
        **kwargs
    ) -> List[List[float]]:
        """
        Generate embeddings using Gemini.
        
        Args:
            texts: List of texts to embed
            
        Returns:
            List of embedding vectors
        """
        try:
            embeddings = []
            
            # Process in batches to avoid rate limits
            batch_size = kwargs.get("batch_size", 10)
            
            for i in range(0, len(texts), batch_size):
                batch = texts[i:i + batch_size]
                
                # Generate embeddings for batch
                loop = asyncio.get_event_loop()
                batch_embeddings = await loop.run_in_executor(
                    None,
                    lambda: [
                        genai.embed_content(
                            model=self.embedding_model,
                            content=text,
                            task_type="retrieval_document"
                        )["embedding"]
                        for text in batch
                    ]
                )
                
                embeddings.extend(batch_embeddings)
            
            return embeddings
            
        except Exception as e:
            logger.error(f"Error generating embeddings with Gemini: {str(e)}")
            raise
    
    def get_model_name(self) -> str:
        """Get model name."""
        return self.model_name
    
    def get_embedding_dimension(self) -> int:
        """Get embedding dimension for Gemini (768)."""
        return 768

=== backend\providers\llm\interface.py ===
"""
Abstract LLM Provider Interface.
Defines the contract that all LLM providers must implement.
"""
from abc import ABC, abstractmethod
from typing import List, Dict, Any, Optional


class LLMInterface(ABC):
    """Abstract base class for LLM providers."""
    
    @abstractmethod
    async def generate_text(
        self,
        prompt: str,
        system_prompt: Optional[str] = None,
        temperature: float = 0.7,
        max_tokens: Optional[int] = None,
        **kwargs
    ) -> str:
        """
        Generate text completion from prompt.
        
        Args:
            prompt: User prompt/question
            system_prompt: Optional system instruction
            temperature: Sampling temperature (0.0 to 1.0)
            max_tokens: Maximum tokens to generate
            **kwargs: Additional provider-specific parameters
            
        Returns:
            Generated text response
        """
        pass
    
    @abstractmethod
    async def generate_embeddings(
        self,
        texts: List[str],
        **kwargs
    ) -> List[List[float]]:
        """
        Generate vector embeddings for texts.
        
        Args:
            texts: List of text strings to embed
            **kwargs: Additional provider-specific parameters
            
        Returns:
            List of embedding vectors
        """
        pass
    
    @abstractmethod
    def get_model_name(self) -> str:
        """
        Get the model name/identifier.
        
        Returns:
            Model name string
        """
        pass
    
    @abstractmethod
    def get_embedding_dimension(self) -> int:
        """
        Get the embedding vector dimension.
        
        Returns:
            Dimension size as integer
        """
        pass

=== backend\providers\vectordb\__init__.py ===
"""VectorDB providers package."""
from backend.providers.vectordb.interface import VectorDBInterface
from backend.providers.vectordb.pgvector_provider import PGVectorProvider
from backend.providers.vectordb.qdrant_provider import QdrantProvider
from backend.providers.vectordb.factory import VectorDBProviderFactory

__all__ = ["VectorDBInterface", "PGVectorProvider", "QdrantProvider", "VectorDBProviderFactory"]

=== backend\providers\vectordb\factory.py ===
"""
VectorDB Provider Factory.
Creates vector database provider instances based on configuration.
"""
from backend.providers.vectordb.interface import VectorDBInterface
from backend.providers.vectordb.pgvector_provider import PGVectorProvider
from backend.providers.vectordb.qdrant_provider import QdrantProvider
from backend.config import settings
import logging

logger = logging.getLogger(__name__)


class VectorDBProviderFactory:
    """Factory for creating VectorDB provider instances."""
    
    _instances = {}
    
    @classmethod
    def create_provider(cls, provider_name: str = None) -> VectorDBInterface:
        """
        Create or return existing VectorDB provider instance (Singleton).
        
        Args:
            provider_name: Name of provider ('pgvector', 'qdrant', etc.)
                          Defaults to settings.vector_db_provider
        
        Returns:
            VectorDB provider instance
            
        Raises:
            ValueError: If provider name is not supported
        """
        provider_name = provider_name or settings.vector_db_provider
        provider_name = provider_name.lower()
        
        if provider_name in cls._instances:
            return cls._instances[provider_name]
        
        if provider_name == "pgvector":
            logger.info("Creating PGVector provider")
            instance = PGVectorProvider()
        
        elif provider_name == "qdrant":
            logger.info("Creating Qdrant provider")
            instance = QdrantProvider(
                url=settings.qdrant_url,
                api_key=settings.qdrant_api_key
            )
        
        else:
            raise ValueError(f"Unsupported VectorDB provider: {provider_name}")
            
        cls._instances[provider_name] = instance
        return instance
    
    @staticmethod
    def get_available_providers() -> list:
        """Get list of available provider names."""
        return ["pgvector", "qdrant"]

=== backend\providers\vectordb\interface.py ===
"""
Abstract VectorDB Provider Interface.
Defines the contract for vector database providers.
"""
from abc import ABC, abstractmethod
from typing import List, Dict, Any, Optional, Tuple


class VectorDBInterface(ABC):
    """Abstract base class for vector database providers."""
    
    @abstractmethod
    async def create_collection(
        self,
        collection_name: str,
        dimension: int,
        **kwargs
    ) -> bool:
        """
        Create a collection/index for storing vectors.
        
        Args:
            collection_name: Name of the collection
            dimension: Vector dimension size
            **kwargs: Provider-specific parameters
            
        Returns:
            True if successful
        """
        pass
    
    @abstractmethod
    async def add_vectors(
        self,
        collection_name: str,
        vectors: List[List[float]],
        ids: List[Any],
        metadata: Optional[List[Dict[str, Any]]] = None,
        **kwargs
    ) -> bool:
        """
        Add vectors to collection.
        
        Args:
            collection_name: Collection name
            vectors: List of vector embeddings
            ids: List of unique identifiers
            metadata: Optional metadata for each vector
            **kwargs: Provider-specific parameters
            
        Returns:
            True if successful
        """
        pass
    
    @abstractmethod
    async def search(
        self,
        collection_name: str,
        query_vector: List[float],
        top_k: int = 5,
        filter_dict: Optional[Dict[str, Any]] = None,
        **kwargs
    ) -> List[Tuple[Any, float, Dict[str, Any]]]:
        """
        Search for similar vectors.
        
        Args:
            collection_name: Collection name
            query_vector: Query embedding vector
            top_k: Number of results to return
            filter_dict: Optional metadata filters
            **kwargs: Provider-specific parameters
            
        Returns:
            List of tuples: (id, similarity_score, metadata)
        """
        pass
    
    @abstractmethod
    async def delete_collection(
        self,
        collection_name: str,
        **kwargs
    ) -> bool:
        """
        Delete a collection.
        
        Args:
            collection_name: Collection name
            **kwargs: Provider-specific parameters
            
        Returns:
            True if successful
        """
        pass
    
    @abstractmethod
    async def collection_exists(
        self,
        collection_name: str,
        **kwargs
    ) -> bool:
        """
        Check if collection exists.
        
        Args:
            collection_name: Collection name
            **kwargs: Provider-specific parameters
            
        Returns:
            True if exists
        """
        pass

=== backend\providers\vectordb\pgvector_provider.py ===
"""
PGVector Provider Implementation.
Uses PostgreSQL with pgvector extension for vector storage.
"""
from typing import List, Dict, Any, Optional, Tuple
from sqlalchemy import select, delete, text
from sqlalchemy.ext.asyncio import AsyncSession
from backend.providers.vectordb.interface import VectorDBInterface
from backend.database.models import Chunk, Project
from backend.database.connection import async_session_maker
import logging

logger = logging.getLogger(__name__)


class PGVectorProvider(VectorDBInterface):
    """PostgreSQL pgvector implementation."""
    
    def __init__(self):
        """Initialize PGVector provider."""
        logger.info("PGVector provider initialized")
    
    async def create_collection(
        self,
        collection_name: str,
        dimension: int,
        **kwargs
    ) -> bool:
        """
        Create collection (for pgvector, this is handled by table creation).
        
        Args:
            collection_name: Not used (using chunks table)
            dimension: Vector dimension
            
        Returns:
            True (table already exists from migrations)
        """
        # With pgvector, collections are handled by the chunks table
        # The vector column is already defined in the model
        logger.info(f"Collection '{collection_name}' ready (using chunks table)")
        return True
    
    async def add_vectors(
        self,
        collection_name: str,
        vectors: List[List[float]],
        ids: List[Any],
        metadata: Optional[List[Dict[str, Any]]] = None,
        **kwargs
    ) -> bool:
        """
        Add/update vectors in chunks table.
        
        Args:
            collection_name: Project name or identifier
            vectors: List of embeddings
            ids: List of chunk IDs
            metadata: Optional metadata
            
        Returns:
            True if successful
        """
        try:
            async with async_session_maker() as session:
                for i, (chunk_id, vector) in enumerate(zip(ids, vectors)):
                    # Update chunk with embedding
                    stmt = select(Chunk).where(Chunk.id == chunk_id)
                    result = await session.execute(stmt)
                    chunk = result.scalar_one_or_none()
                    
                    if chunk:
                        chunk.embedding = vector
                        if metadata and i < len(metadata):
                            chunk.extra_metadata.update(metadata[i])
                
                await session.commit()
                logger.info(f"Added {len(vectors)} vectors to collection '{collection_name}'")
                return True
                
        except Exception as e:
            logger.error(f"Error adding vectors: {str(e)}")
            raise
    
    async def search(
        self,
        collection_name: str,
        query_vector: List[float],
        top_k: int = 5,
        filter_dict: Optional[Dict[str, Any]] = None,
        **kwargs
    ) -> List[Tuple[Any, float, Dict[str, Any]]]:
        """
        Search for similar vectors.
        Falls back to Python-based similarity if pgvector is not available.
        """
        try:
            async with async_session_maker() as session:
                # Build query to get all relevant chunks
                # We fetch the embedding to calculate similarity in Python
                query = select(
                    Chunk.id,
                    Chunk.content,
                    Chunk.extra_metadata,
                    Chunk.asset_id,
                    Chunk.embedding
                ).where(
                    Chunk.embedding.isnot(None)
                )
                
                # Apply filters
                if filter_dict:
                    if 'project_id' in filter_dict:
                        query = query.where(Chunk.project_id == filter_dict['project_id'])
                    if 'asset_id' in filter_dict:
                        query = query.where(Chunk.asset_id == filter_dict['asset_id'])
                
                result = await session.execute(query)
                rows = result.all()
                
                # Calculate similarity in Python
                def cosine_similarity(v1, v2):
                    if not v1 or not v2: return 0.0
                    dot_product = sum(a * b for a, b in zip(v1, v2))
                    norm1 = sum(a * a for a in v1) ** 0.5
                    norm2 = sum(a * a for a in v2) ** 0.5
                    if not norm1 or not norm2: return 0.0
                    return dot_product / (norm1 * norm2)
                
                scored_results = []
                for row in rows:
                    sim = cosine_similarity(query_vector, row.embedding)
                    scored_results.append((
                        row.id,
                        sim,
                        {
                            'content': row.content,
                            'metadata': row.extra_metadata,
                            'asset_id': row.asset_id
                        }
                    ))
                
                # Sort by similarity and take top_k
                scored_results.sort(key=lambda x: x[1], reverse=True)
                results = scored_results[:top_k]
                
                logger.info(f"Found {len(results)} similar chunks using Python fallback")
                return results
                
        except Exception as e:
            logger.error(f"Error searching vectors: {str(e)}")
            raise
    
    async def delete_collection(
        self,
        collection_name: str,
        **kwargs
    ) -> bool:
        """
        Delete all chunks for a project.
        
        Args:
            collection_name: Project ID or identifier
            
        Returns:
            True if successful
        """
        try:
            async with async_session_maker() as session:
                project_id = kwargs.get('project_id')
                if project_id:
                    stmt = delete(Chunk).where(Chunk.project_id == project_id)
                    await session.execute(stmt)
                    await session.commit()
                    logger.info(f"Deleted collection '{collection_name}'")
                return True
                
        except Exception as e:
            logger.error(f"Error deleting collection: {str(e)}")
            raise
    
    async def collection_exists(
        self,
        collection_name: str,
        **kwargs
    ) -> bool:
        """
        Check if project exists.
        
        Args:
            collection_name: Project name
            
        Returns:
            True if exists
        """
        try:
            async with async_session_maker() as session:
                project_id = kwargs.get('project_id')
                if project_id:
                    stmt = select(Project).where(Project.id == project_id)
                    result = await session.execute(stmt)
                    return result.scalar_one_or_none() is not None
                return False
                
        except Exception as e:
            logger.error(f"Error checking collection: {str(e)}")
            return False

=== backend\providers\vectordb\qdrant_provider.py ===
"""
Qdrant Provider Implementation.
Uses Qdrant standalone vector database.
"""
from typing import List, Dict, Any, Optional, Tuple
from backend.providers.vectordb.interface import VectorDBInterface
import logging

logger = logging.getLogger(__name__)


class QdrantProvider(VectorDBInterface):
    """
    Qdrant vector database implementation.
    Optional provider - requires Qdrant server running.
    """
    
    def __init__(self, url: str = "http://localhost:6333", api_key: str = ""):
        """
        Initialize Qdrant provider.
        
        Args:
            url: Qdrant server URL
            api_key: Optional API key
        """
        try:
            from qdrant_client import QdrantClient
            from qdrant_client.models import Distance, VectorParams, PointStruct
            
            if url.startswith("path://"):
                path = url.replace("path://", "")
                self.client = QdrantClient(path=path)
                logger.info(f"Qdrant provider initialized with local path: {path}")
            else:
                self.client = QdrantClient(url=url, api_key=api_key if api_key else None)
                logger.info(f"Qdrant provider initialized at {url}")
        except ImportError:
            logger.error("qdrant-client not installed. Install with: pip install qdrant-client")
            raise
    
    async def create_collection(
        self,
        collection_name: str,
        dimension: int,
        **kwargs
    ) -> bool:
        """
        Create Qdrant collection.
        
        Args:
            collection_name: Collection name
            dimension: Vector dimension
            
        Returns:
            True if successful
        """
        try:
            # Check if collection exists
            collections = self.client.get_collections().collections
            exists = any(c.name == collection_name for c in collections)
            
            if not exists:
                self.client.create_collection(
                    collection_name=collection_name,
                    vectors_config=self.VectorParams(
                        size=dimension,
                        distance=self.Distance.COSINE
                    )
                )
                logger.info(f"Created Qdrant collection '{collection_name}'")
            else:
                logger.info(f"Qdrant collection '{collection_name}' already exists")
            
            return True
            
        except Exception as e:
            logger.error(f"Error creating collection: {str(e)}")
            raise
    
    async def add_vectors(
        self,
        collection_name: str,
        vectors: List[List[float]],
        ids: List[Any],
        metadata: Optional[List[Dict[str, Any]]] = None,
        **kwargs
    ) -> bool:
        """
        Add vectors to Qdrant collection.
        
        Args:
            collection_name: Collection name
            vectors: List of embeddings
            ids: List of IDs
            metadata: Optional metadata
            
        Returns:
            True if successful
        """
        try:
            points = []
            for i, (point_id, vector) in enumerate(zip(ids, vectors)):
                payload = metadata[i] if metadata and i < len(metadata) else {}
                points.append(
                    self.PointStruct(
                        id=point_id,
                        vector=vector,
                        payload=payload
                    )
                )
            
            self.client.upsert(
                collection_name=collection_name,
                points=points
            )
            
            logger.info(f"Added {len(points)} points to Qdrant collection '{collection_name}'")
            return True
            
        except Exception as e:
            logger.error(f"Error adding vectors: {str(e)}")
            raise
    
    async def search(
        self,
        collection_name: str,
        query_vector: List[float],
        top_k: int = 5,
        filter_dict: Optional[Dict[str, Any]] = None,
        **kwargs
    ) -> List[Tuple[Any, float, Dict[str, Any]]]:
        """
        Search Qdrant for similar vectors.
        
        Args:
            collection_name: Collection name
            query_vector: Query embedding
            top_k: Number of results
            filter_dict: Optional filters
            
        Returns:
            List of (id, score, payload)
        """
        try:
            # Build filter if provided
            search_filter = None
            if filter_dict:
                from qdrant_client.models import Filter, FieldCondition, MatchValue
                conditions = []
                for key, value in filter_dict.items():
                    conditions.append(
                        FieldCondition(key=key, match=MatchValue(value=value))
                    )
                search_filter = Filter(must=conditions)
            
            # Search
            search_result = self.client.search(
                collection_name=collection_name,
                query_vector=query_vector,
                limit=top_k,
                query_filter=search_filter
            )
            
            # Format results
            results = []
            for hit in search_result:
                results.append((
                    hit.id,
                    hit.score,
                    hit.payload
                ))
            
            logger.info(f"Found {len(results)} similar points in Qdrant")
            return results
            
        except Exception as e:
            logger.error(f"Error searching vectors: {str(e)}")
            raise
    
    async def delete_collection(
        self,
        collection_name: str,
        **kwargs
    ) -> bool:
        """
        Delete Qdrant collection.
        
        Args:
            collection_name: Collection name
            
        Returns:
            True if successful
        """
        try:
            self.client.delete_collection(collection_name=collection_name)
            logger.info(f"Deleted Qdrant collection '{collection_name}'")
            return True
            
        except Exception as e:
            logger.error(f"Error deleting collection: {str(e)}")
            raise
    
    async def collection_exists(
        self,
        collection_name: str,
        **kwargs
    ) -> bool:
        """
        Check if Qdrant collection exists.
        
        Args:
            collection_name: Collection name
            
        Returns:
            True if exists
        """
        try:
            collections = self.client.get_collections().collections
            return any(c.name == collection_name for c in collections)
            
        except Exception as e:
            logger.error(f"Error checking collection: {str(e)}")
            return False

=== backend\providers\__init__.py ===
"""Providers package initialization."""

=== backend\routes\__init__.py ===
"""Routes package initialization."""
from backend.routes import projects, documents, query, health

__all__ = ["projects", "documents", "query", "health"]

=== backend\routes\bot_config.py ===
"""
Bot Configuration Routes.
API endpoints for configuring the Telegram bot.
"""
from fastapi import APIRouter, HTTPException, UploadFile, File, Form
from pydantic import BaseModel
from typing import Optional
import json
import os
import httpx
from telegram_bot.config import bot_settings

router = APIRouter(prefix="/bot", tags=["Bot Config"])

CONFIG_FILE = "bot_config.json"

class BotConfig(BaseModel):
    active_project_id: Optional[int] = None

def load_config():
    if os.path.exists(CONFIG_FILE):
        try:
            with open(CONFIG_FILE, "r") as f:
                return json.load(f)
        except:
            return {}
    return {}

def save_config(config):
    with open(CONFIG_FILE, "w") as f:
        json.dump(config, f)

@router.get("/config")
async def get_bot_config():
    """Get current bot configuration."""
    return load_config()

@router.post("/config")
async def update_bot_config(config: BotConfig):
    """Update bot configuration (active project)."""
    current_config = load_config()
    if config.active_project_id is not None:
        current_config["active_project_id"] = config.active_project_id
    save_config(current_config)
    return current_config

@router.post("/profile")
async def update_bot_profile(
    name: str = Form(...),
    # image: UploadFile = File(None) # Image upload to be implemented if needed
):
    """
    Update Telegram Bot Profile (Name).
    Requires 'setMyName' permission.
    """
    try:
        async with httpx.AsyncClient() as client:
            # Update Name
            url = f"https://api.telegram.org/bot{bot_settings.telegram_bot_token}/setMyName"
            response = await client.post(url, json={"name": name})
            response.raise_for_status()
            
            return {"status": "success", "message": "Bot profile updated"}
            
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

=== backend\routes\documents.py ===
"""
Document Routes.
API endpoints for document management.
"""
from fastapi import APIRouter, Depends, HTTPException, UploadFile, File, BackgroundTasks
from sqlalchemy.ext.asyncio import AsyncSession
from pydantic import BaseModel
from typing import List, Optional, Dict, Any
from datetime import datetime
from backend.database import get_db
from backend.controllers.document_controller import DocumentController

router = APIRouter(tags=["Documents"])
document_controller = DocumentController()


# Response Models
class AssetResponse(BaseModel):
    id: int
    project_id: int
    filename: str
    original_filename: str
    file_size: int
    file_type: str
    status: str
    error_message: Optional[str]
    created_at: datetime
    processed_at: Optional[datetime]
    extra_metadata: Dict[str, Any]
    
    class Config:
        from_attributes = True


# Routes
@router.post("/projects/{project_id}/documents", response_model=AssetResponse, status_code=201)
async def upload_document(
    project_id: int,
    file: UploadFile = File(...),
    background_tasks: BackgroundTasks = BackgroundTasks(),
    db: AsyncSession = Depends(get_db)
):
    """
    Upload document to project.
    Document will be processed in background.
    """
    try:
        # Read file
        file_content = await file.read()
        file_size = len(file_content)
        
        # Upload document
        asset = await document_controller.upload_document(
            db=db,
            project_id=project_id,
            file_content=file_content,
            filename=file.filename,
            file_size=file_size
        )
        
        # Process in background
        background_tasks.add_task(
            document_controller.process_document,
            db=db,
            asset_id=asset.id
        )
        
        return asset
        
    except ValueError as e:
        raise HTTPException(status_code=400, detail=str(e))
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/projects/{project_id}/documents", response_model=List[AssetResponse])
async def list_project_documents(
    project_id: int,
    db: AsyncSession = Depends(get_db)
):
    """List all documents in project."""
    try:
        documents = await document_controller.list_project_documents(
            db=db,
            project_id=project_id
        )
        return documents
    except Exception as e:
        raise HTTPException(status_code=400, detail=str(e))


@router.get("/documents/{asset_id}", response_model=AssetResponse)
async def get_document(
    asset_id: int,
    db: AsyncSession = Depends(get_db)
):
    """Get document by ID."""
    try:
        document = await document_controller.get_document(db=db, asset_id=asset_id)
        if not document:
            raise HTTPException(status_code=404, detail="Document not found")
        return document
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=400, detail=str(e))


@router.post("/documents/{asset_id}/process", response_model=AssetResponse)
async def process_document(
    asset_id: int,
    db: AsyncSession = Depends(get_db)
):
    """Manually trigger document processing."""
    try:
        await document_controller.process_document(db=db, asset_id=asset_id)
        document = await document_controller.get_document(db=db, asset_id=asset_id)
        return document
    except ValueError as e:
        raise HTTPException(status_code=400, detail=str(e))
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@router.delete("/documents/{asset_id}", status_code=204)
async def delete_document(
    asset_id: int,
    db: AsyncSession = Depends(get_db)
):
    """Delete document."""
    try:
        deleted = await document_controller.delete_document(db=db, asset_id=asset_id)
        if not deleted:
            raise HTTPException(status_code=404, detail="Document not found")
        return None
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=400, detail=str(e))

=== backend\routes\health.py ===
"""
Health Check Routes.
API endpoints for system health monitoring.
"""
from fastapi import APIRouter, Depends
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import text
from backend.database import get_db
from backend.config import settings
from pydantic import BaseModel

router = APIRouter(tags=["Health"])


class HealthResponse(BaseModel):
    status: str
    database: str
    llm_provider: str
    vector_db_provider: str


@router.get("/health", response_model=HealthResponse)
async def health_check(db: AsyncSession = Depends(get_db)):
    """Check system health status."""
    try:
        # Check database connection
        await db.execute(text("SELECT 1"))
        db_status = "connected"
    except Exception:
        db_status = "disconnected"
    
    return {
        "status": "healthy" if db_status == "connected" else "unhealthy",
        "database": db_status,
        "llm_provider": settings.llm_provider,
        "vector_db_provider": settings.vector_db_provider
    }


@router.get("/")
async def root():
    """Root endpoint."""
    return {
        "name": settings.api_title,
        "version": settings.api_version,
        "docs": "/docs",
        "health": "/health"
    }

=== backend\routes\projects.py ===
"""
Project Routes.
API endpoints for project management.
"""
from fastapi import APIRouter, Depends, HTTPException
from sqlalchemy.ext.asyncio import AsyncSession
from pydantic import BaseModel, Field
from typing import Optional, List, Dict, Any
from datetime import datetime
from backend.database import get_db
from backend.controllers.project_controller import ProjectController

router = APIRouter(prefix="/projects", tags=["Projects"])
project_controller = ProjectController()


# Request/Response Models
class ProjectCreate(BaseModel):
    name: str = Field(..., min_length=1, max_length=255)
    description: Optional[str] = None
    metadata: Optional[Dict[str, Any]] = None


class ProjectUpdate(BaseModel):
    name: Optional[str] = Field(None, min_length=1, max_length=255)
    description: Optional[str] = None
    metadata: Optional[Dict[str, Any]] = None


class ProjectResponse(BaseModel):
    id: int
    name: str
    description: Optional[str]
    extra_metadata: Dict[str, Any]
    created_at: datetime
    updated_at: Optional[datetime]
    
    class Config:
        from_attributes = True


class ProjectStatsResponse(BaseModel):
    project: ProjectResponse
    stats: Dict[str, Any]


# Routes
@router.post("/", response_model=ProjectResponse, status_code=201)
async def create_project(
    project_data: ProjectCreate,
    db: AsyncSession = Depends(get_db)
):
    """Create a new project."""
    try:
        project = await project_controller.create_project(
            db=db,
            name=project_data.name,
            description=project_data.description,
            metadata=project_data.metadata
        )
        return project
    except Exception as e:
        raise HTTPException(status_code=400, detail=str(e))


@router.get("/", response_model=List[ProjectResponse])
async def list_projects(
    skip: int = 0,
    limit: int = 100,
    db: AsyncSession = Depends(get_db)
):
    """List all projects."""
    try:
        projects = await project_controller.list_projects(db=db, skip=skip, limit=limit)
        return projects
    except Exception as e:
        raise HTTPException(status_code=400, detail=str(e))


@router.get("/{project_id}", response_model=ProjectResponse)
async def get_project(
    project_id: int,
    db: AsyncSession = Depends(get_db)
):
    """Get project by ID."""
    try:
        project = await project_controller.get_project(db=db, project_id=project_id)
        if not project:
            raise HTTPException(status_code=404, detail="Project not found")
        return project
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=400, detail=str(e))


@router.get("/{project_id}/stats", response_model=ProjectStatsResponse)
async def get_project_stats(
    project_id: int,
    db: AsyncSession = Depends(get_db)
):
    """Get project statistics."""
    try:
        project = await project_controller.get_project(db=db, project_id=project_id)
        if not project:
            raise HTTPException(status_code=404, detail="Project not found")
        
        stats = await project_controller.get_project_stats(db=db, project_id=project_id)
        
        return {
            "project": project,
            "stats": stats
        }
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=400, detail=str(e))


@router.put("/{project_id}", response_model=ProjectResponse)
async def update_project(
    project_id: int,
    project_data: ProjectUpdate,
    db: AsyncSession = Depends(get_db)
):
    """Update project."""
    try:
        project = await project_controller.update_project(
            db=db,
            project_id=project_id,
            name=project_data.name,
            description=project_data.description,
            metadata=project_data.metadata
        )
        if not project:
            raise HTTPException(status_code=404, detail="Project not found")
        return project
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=400, detail=str(e))


@router.delete("/{project_id}", status_code=204)
async def delete_project(
    project_id: int,
    db: AsyncSession = Depends(get_db)
):
    """Delete project and all associated data."""
    try:
        deleted = await project_controller.delete_project(db=db, project_id=project_id)
        if not deleted:
            raise HTTPException(status_code=404, detail="Project not found")
        return None
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=400, detail=str(e))

=== backend\routes\query.py ===
"""
Query Routes.
API endpoints for querying documents.
"""
from fastapi import APIRouter, Depends, HTTPException
from sqlalchemy.ext.asyncio import AsyncSession
from pydantic import BaseModel, Field
from typing import Optional, List, Dict, Any
from backend.database import get_db
from backend.controllers.query_controller import QueryController

router = APIRouter(tags=["Query"])
query_controller = QueryController()


# Request/Response Models
class QueryRequest(BaseModel):
    query: str = Field(..., min_length=1)
    top_k: int = Field(default=5, ge=1, le=20)
    language: str = Field(default="ar", pattern="^(ar|en)$")
    asset_id: Optional[int] = None


class SourceInfo(BaseModel):
    document_name: str
    chunk_index: int
    similarity: float
    asset_id: int


class QueryResponse(BaseModel):
    answer: str
    sources: List[SourceInfo]
    context_used: int


# Routes
@router.post("/projects/{project_id}/query", response_model=QueryResponse)
async def query_project(
    project_id: int,
    query_data: QueryRequest,
    db: AsyncSession = Depends(get_db)
):
    """
    Ask a question about project documents.
    Returns AI-generated answer with sources.
    """
    try:
        result = await query_controller.answer_query(
            db=db,
            project_id=project_id,
            query=query_data.query,
            top_k=query_data.top_k,
            language=query_data.language,
            asset_id=query_data.asset_id
        )
        
        return result
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

=== backend\routes\stats.py ===
"""
Stats Routes.
API endpoints for global statistics.
"""
from fastapi import APIRouter, Depends, HTTPException
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import func, select
from backend.database import get_db
from backend.database.models import Project, Asset, Chunk

router = APIRouter(prefix="/stats", tags=["Stats"])

@router.get("/")
async def get_global_stats(db: AsyncSession = Depends(get_db)):
    """Get global statistics."""
    try:
        # Count projects
        projects_query = select(func.count(Project.id))
        projects_count = await db.scalar(projects_query)
        
        # Count documents
        documents_query = select(func.count(Asset.id))
        documents_count = await db.scalar(documents_query)
        
        # Count chunks
        chunks_query = select(func.count(Chunk.id))
        chunks_count = await db.scalar(chunks_query)
        
        return {
            "projects": projects_count or 0,
            "documents": documents_count or 0,
            "chunks": chunks_count or 0
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

=== backend\services\__init__.py ===
"""Services package initialization."""
from backend.services.document_loader import DocumentLoaderService
from backend.services.chunking_service import ChunkingService
from backend.services.file_service import FileService
from backend.services.embedding_service import EmbeddingService
from backend.services.query_service import QueryService
from backend.services.answer_service import AnswerService

__all__ = [
    "DocumentLoaderService",
    "ChunkingService",
    "FileService",
    "EmbeddingService",
    "QueryService",
    "AnswerService"
]

=== backend\services\answer_service.py ===
"""
Answer Generation Service.
Handles generating AI-powered answers using LLM.
"""
from typing import List, Dict, Any, Optional
from backend.providers.llm.factory import LLMProviderFactory
import logging

logger = logging.getLogger(__name__)


class AnswerService:
    """Service for generating answers from context."""
    
    def __init__(self):
        """Initialize answer service."""
        self.llm_provider = LLMProviderFactory.create_provider()
        logger.info("Answer service initialized")
    
    async def generate_answer(
        self,
        query: str,
        context_chunks: List[Dict[str, Any]],
        language: str = "ar",  # Default to Arabic
        include_sources: bool = True
    ) -> Dict[str, Any]:
        """
        Generate answer from query and context.
        
        Args:
            query: User question
            context_chunks: List of relevant chunks
            language: Response language ('ar' or 'en')
            include_sources: Whether to include source references
            
        Returns:
            Dict with 'answer' and optional 'sources'
        """
        try:
            # Build context from chunks
            context = self._build_context(context_chunks)
            
            # Build prompt
            prompt = self._build_prompt(query, context, language)
            
            # Generate answer
            answer = await self.llm_provider.generate_text(
                prompt=prompt,
                temperature=0.7,
                max_tokens=1024
            )
            
            # Format response
            response = {
                'answer': answer.strip(),
                'context_used': len(context_chunks)
            }
            
            if include_sources:
                response['sources'] = self._extract_sources(context_chunks)
            
            logger.info(f"Generated answer (length={len(answer)})")
            return response
            
        except Exception as e:
            logger.error(f"Error generating answer: {str(e)}")
            raise
    
    def _build_context(self, chunks: List[Dict[str, Any]]) -> str:
        """
        Build context string from chunks.
        
        Args:
            chunks: List of chunk dictionaries
            
        Returns:
            Formatted context string
        """
        context_parts = []
        for i, chunk in enumerate(chunks, 1):
            content = chunk.get('content', '')
            metadata = chunk.get('metadata', {})
            doc_name = metadata.get('document_name', 'Unknown')
            
            context_parts.append(f"[مصدر {i} - {doc_name}]\n{content}")
        
        return "\n\n".join(context_parts)
    
    def _build_prompt(self, query: str, context: str, language: str) -> str:
        """
        Build prompt for LLM.
        
        Args:
            query: User question
            context: Context text
            language: Response language
            
        Returns:
            Formatted prompt
        """
        if language == "ar":
            system_prompt = """أنت مساعد ذكي متخصص في الإجابة على الأسئلة بناءً على المحتوى المقدم.
قم بتحليل السياق المقدم وأجب على السؤال بدقة واحترافية.
إذا لم تجد الإجابة في السياق، قل ذلك بوضوح.
استخدم اللغة العربية الفصحى في إجاباتك."""

            prompt = f"""{system_prompt}

السياق:
{context}

السؤال: {query}

الإجابة:"""
        else:
            system_prompt = """You are an intelligent assistant specialized in answering questions based on provided content.
Analyze the given context and answer the question accurately and professionally.
If you cannot find the answer in the context, state that clearly."""

            prompt = f"""{system_prompt}

Context:
{context}

Question: {query}

Answer:"""
        
        return prompt
    
    def _extract_sources(self, chunks: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        Extract source information from chunks.
        
        Args:
            chunks: List of chunk dictionaries
            
        Returns:
            List of source information
        """
        sources = []
        for chunk in chunks:
            metadata = chunk.get('metadata', {})
            sources.append({
                'document_name': metadata.get('document_name', 'Unknown'),
                'chunk_index': metadata.get('chunk_index', 0),
                'similarity': chunk.get('similarity', 0.0),
                'asset_id': chunk.get('asset_id')
            })
        
        return sources

=== backend\services\chunking_service.py ===
"""
Text Chunking Service.
Handles splitting text into chunks using LangChain.
"""
from typing import List, Dict, Any
from langchain_text_splitters import RecursiveCharacterTextSplitter
from backend.config import settings
import logging

logger = logging.getLogger(__name__)


class ChunkingService:
    """Service for chunking text documents."""
    
    def __init__(
        self,
        chunk_size: int = None,
        chunk_overlap: int = None
    ):
        """
        Initialize chunking service.
        
        Args:
            chunk_size: Size of each chunk (defaults to settings)
            chunk_overlap: Overlap between chunks (defaults to settings)
        """
        self.chunk_size = chunk_size or settings.chunk_size
        self.chunk_overlap = chunk_overlap or settings.chunk_overlap
        
        # Initialize text splitter
        self.text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=self.chunk_size,
            chunk_overlap=self.chunk_overlap,
            length_function=len,
            separators=["\n\n", "\n", ". ", " ", ""]
        )
        
        logger.info(f"Chunking service initialized (size={self.chunk_size}, overlap={self.chunk_overlap})")
    
    async def chunk_text(
        self,
        text: str,
        metadata: Dict[str, Any] = None
    ) -> List[Dict[str, Any]]:
        """
        Split text into chunks with metadata.
        
        Args:
            text: Text to chunk
            metadata: Optional base metadata for all chunks
            
        Returns:
            List of chunk dictionaries with 'content' and 'metadata'
        """
        try:
            # Split text
            text_chunks = self.text_splitter.split_text(text)
            
            # Create chunk objects with metadata
            chunks = []
            base_metadata = metadata or {}
            
            for i, chunk_text in enumerate(text_chunks):
                chunk_metadata = {
                    **base_metadata,
                    'chunk_index': i,
                    'total_chunks': len(text_chunks),
                    'chunk_size': len(chunk_text)
                }
                
                chunks.append({
                    'content': chunk_text,
                    'metadata': chunk_metadata
                })
            
            logger.info(f"Created {len(chunks)} chunks from text ({len(text)} characters)")
            return chunks
            
        except Exception as e:
            logger.error(f"Error chunking text: {str(e)}")
            raise
    
    async def chunk_document(
        self,
        text: str,
        document_name: str,
        additional_metadata: Dict[str, Any] = None
    ) -> List[Dict[str, Any]]:
        """
        Chunk document with automatic metadata.
        
        Args:
            text: Document text
            document_name: Name of document
            additional_metadata: Optional additional metadata
            
        Returns:
            List of chunks with metadata
        """
        metadata = {
            'document_name': document_name,
            **(additional_metadata or {})
        }
        
        return await self.chunk_text(text, metadata)

=== backend\services\document_loader.py ===
"""
Document Loader Service.
Handles loading and extracting text from various document formats.
"""
from typing import Optional
import os
import logging
from pathlib import Path

logger = logging.getLogger(__name__)


class DocumentLoaderService:
    """Service for loading documents and extracting text."""
    
    @staticmethod
    async def load_document(file_path: str) -> str:
        """
        Load document and extract text content.
        
        Args:
            file_path: Path to document file
            
        Returns:
            Extracted text content
            
        Raises:
            ValueError: If file type is not supported
        """
        file_ext = Path(file_path).suffix.lower()
        
        if file_ext == '.pdf':
            return await DocumentLoaderService._load_pdf(file_path)
        elif file_ext == '.txt':
            return await DocumentLoaderService._load_txt(file_path)
        elif file_ext == '.docx':
            return await DocumentLoaderService._load_docx(file_path)
        else:
            raise ValueError(f"Unsupported file type: {file_ext}")
    
    @staticmethod
    async def _load_pdf(file_path: str) -> str:
        """
        Load PDF file and extract text.
        
        Args:
            file_path: Path to PDF file
            
        Returns:
            Extracted text
        """
        try:
            from pypdf import PdfReader
            
            reader = PdfReader(file_path)
            text_parts = []
            
            for page_num, page in enumerate(reader.pages, 1):
                text = page.extract_text()
                if text.strip():
                    text_parts.append(text)
            
            full_text = "\n\n".join(text_parts)
            logger.info(f"Extracted {len(full_text)} characters from PDF ({len(reader.pages)} pages)")
            
            return full_text
            
        except Exception as e:
            logger.error(f"Error loading PDF: {str(e)}")
            raise
    
    @staticmethod
    async def _load_txt(file_path: str) -> str:
        """
        Load text file.
        
        Args:
            file_path: Path to text file
            
        Returns:
            File content
        """
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                text = f.read()
            
            logger.info(f"Loaded {len(text)} characters from TXT file")
            return text
            
        except UnicodeDecodeError:
            # Try with different encoding
            try:
                with open(file_path, 'r', encoding='latin-1') as f:
                    text = f.read()
                logger.info(f"Loaded {len(text)} characters from TXT file (latin-1 encoding)")
                return text
            except Exception as e:
                logger.error(f"Error loading TXT file: {str(e)}")
                raise
        except Exception as e:
            logger.error(f"Error loading TXT file: {str(e)}")
            raise
    
    @staticmethod
    async def _load_docx(file_path: str) -> str:
        """
        Load DOCX file and extract text.
        
        Args:
            file_path: Path to DOCX file
            
        Returns:
            Extracted text
        """
        try:
            from docx import Document
            
            doc = Document(file_path)
            text_parts = []
            
            for para in doc.paragraphs:
                if para.text.strip():
                    text_parts.append(para.text)
            
            full_text = "\n\n".join(text_parts)
            logger.info(f"Extracted {len(full_text)} characters from DOCX ({len(doc.paragraphs)} paragraphs)")
            
            return full_text
            
        except Exception as e:
            logger.error(f"Error loading DOCX: {str(e)}")
            raise
    
    @staticmethod
    def get_supported_extensions() -> list:
        """Get list of supported file extensions."""
        return ['.pdf', '.txt', '.docx']
    
    @staticmethod
    def is_supported_file(filename: str) -> bool:
        """
        Check if file type is supported.
        
        Args:
            filename: File name or path
            
        Returns:
            True if supported
        """
        ext = Path(filename).suffix.lower()
        return ext in DocumentLoaderService.get_supported_extensions()

=== backend\services\embedding_service.py ===
"""
Embedding Service.
Handles generating embeddings using LLM provider.
"""
from typing import List
from backend.providers.llm.factory import LLMProviderFactory
import logging

logger = logging.getLogger(__name__)


class EmbeddingService:
    """Service for generating embeddings."""
    
    def __init__(self):
        """Initialize embedding service with LLM provider."""
        self.llm_provider = LLMProviderFactory.create_provider()
        logger.info(f"Embedding service initialized with {self.llm_provider.get_model_name()}")
    
    async def generate_embeddings(
        self,
        texts: List[str],
        batch_size: int = 10
    ) -> List[List[float]]:
        """
        Generate embeddings for list of texts.
        
        Args:
            texts: List of text strings
            batch_size: Batch size for processing
            
        Returns:
            List of embedding vectors
        """
        try:
            if not texts:
                return []
            
            embeddings = await self.llm_provider.generate_embeddings(
                texts=texts,
                batch_size=batch_size
            )
            
            logger.info(f"Generated {len(embeddings)} embeddings")
            return embeddings
            
        except Exception as e:
            logger.error(f"Error generating embeddings: {str(e)}")
            raise
    
    async def generate_single_embedding(self, text: str) -> List[float]:
        """
        Generate embedding for single text.
        
        Args:
            text: Text string
            
        Returns:
            Embedding vector
        """
        embeddings = await self.generate_embeddings([text])
        return embeddings[0] if embeddings else []
    
    def get_embedding_dimension(self) -> int:
        """
        Get the embedding vector dimension.
        
        Returns:
            Dimension size
        """
        return self.llm_provider.get_embedding_dimension()

=== backend\services\file_service.py ===
"""
File Management Service.
Handles file storage with project-based organization.
"""
import os
import uuid
import shutil
from pathlib import Path
from typing import Optional
from backend.config import settings
import logging
import aiofiles

logger = logging.getLogger(__name__)


class FileService:
    """Service for managing uploaded files."""
    
    def __init__(self):
        """Initialize file service."""
        self.upload_dir = Path(settings.upload_dir)
        self.max_size_bytes = settings.max_file_size_mb * 1024 * 1024
        
        # Create upload directory if it doesn't exist
        self.upload_dir.mkdir(parents=True, exist_ok=True)
        logger.info(f"File service initialized (upload_dir={self.upload_dir})")
    
    def get_project_dir(self, project_id: int) -> Path:
        """
        Get directory path for project.
        
        Args:
            project_id: Project ID
            
        Returns:
            Path to project directory
        """
        project_dir = self.upload_dir / f"project_{project_id}"
        project_dir.mkdir(parents=True, exist_ok=True)
        return project_dir
    
    def generate_unique_filename(self, original_filename: str) -> str:
        """
        Generate unique filename while preserving extension.
        
        Args:
            original_filename: Original file name
            
        Returns:
            Unique filename
        """
        file_ext = Path(original_filename).suffix
        unique_id = uuid.uuid4().hex[:12]
        safe_name = Path(original_filename).stem[:50]  # Limit length
        return f"{safe_name}_{unique_id}{file_ext}"
    
    async def save_upload_file(
        self,
        file_content: bytes,
        filename: str,
        project_id: int
    ) -> tuple[str, str]:
        """
        Save uploaded file to project directory.
        
        Args:
            file_content: File content as bytes
            filename: Original filename
            project_id: Project ID
            
        Returns:
            Tuple of (unique_filename, file_path)
            
        Raises:
            ValueError: If file is too large
        """
        # Check file size
        if len(file_content) > self.max_size_bytes:
            raise ValueError(
                f"File too large ({len(file_content)} bytes). "
                f"Maximum size is {settings.max_file_size_mb}MB"
            )
        
        # Generate unique filename
        unique_filename = self.generate_unique_filename(filename)
        
        # Get project directory
        project_dir = self.get_project_dir(project_id)
        file_path = project_dir / unique_filename
        
        # Save file asynchronously
        async with aiofiles.open(file_path, 'wb') as f:
            await f.write(file_content)
        
        logger.info(f"Saved file: {file_path} ({len(file_content)} bytes)")
        
        return unique_filename, str(file_path)
    
    async def delete_file(self, file_path: str) -> bool:
        """
        Delete file from storage.
        
        Args:
            file_path: Path to file
            
        Returns:
            True if deleted successfully
        """
        try:
            path = Path(file_path)
            if path.exists():
                path.unlink()
                logger.info(f"Deleted file: {file_path}")
                return True
            else:
                logger.warning(f"File not found: {file_path}")
                return False
        except Exception as e:
            logger.error(f"Error deleting file: {str(e)}")
            raise
    
    async def delete_project_files(self, project_id: int) -> bool:
        """
        Delete all files for a project.
        
        Args:
            project_id: Project ID
            
        Returns:
            True if deleted successfully
        """
        try:
            project_dir = self.get_project_dir(project_id)
            if project_dir.exists():
                shutil.rmtree(project_dir)
                logger.info(f"Deleted project directory: {project_dir}")
                return True
            return False
        except Exception as e:
            logger.error(f"Error deleting project files: {str(e)}")
            raise
    
    def validate_file(self, filename: str, file_size: int) -> tuple[bool, Optional[str]]:
        """
        Validate file before upload.
        
        Args:
            filename: File name
            file_size: File size in bytes
            
        Returns:
            Tuple of (is_valid, error_message)
        """
        # Check file extension
        from backend.services.document_loader import DocumentLoaderService
        if not DocumentLoaderService.is_supported_file(filename):
            return False, f"Unsupported file type. Supported: {DocumentLoaderService.get_supported_extensions()}"
        
        # Check file size
        if file_size > self.max_size_bytes:
            return False, f"File too large. Maximum size is {settings.max_file_size_mb}MB"
        
        return True, None

=== backend\services\query_service.py ===
"""
Query Service.
Handles query processing and similarity search.
"""
from typing import List, Dict, Any, Optional
from backend.services.embedding_service import EmbeddingService
from backend.providers.vectordb.factory import VectorDBProviderFactory
import logging

logger = logging.getLogger(__name__)


class QueryService:
    """Service for processing queries and searching."""
    
    def __init__(self):
        """Initialize query service."""
        self.embedding_service = EmbeddingService()
        self.vector_db = VectorDBProviderFactory.create_provider()
        logger.info("Query service initialized")
    
    async def search_similar_chunks(
        self,
        query: str,
        project_id: int,
        top_k: int = 5,
        asset_id: Optional[int] = None
    ) -> List[Dict[str, Any]]:
        """
        Search for chunks similar to query.
        
        Args:
            query: Search query
            project_id: Project ID to search within
            top_k: Number of results to return
            asset_id: Optional asset ID to filter by
            
        Returns:
            List of similar chunks with metadata
        """
        try:
            # Generate query embedding
            query_embedding = await self.embedding_service.generate_single_embedding(query)
            
            # Build filter
            filter_dict = {'project_id': project_id}
            if asset_id:
                filter_dict['asset_id'] = asset_id
            
            # Search vector database
            results = await self.vector_db.search(
                collection_name=f"project_{project_id}",
                query_vector=query_embedding,
                top_k=top_k,
                filter_dict=filter_dict
            )
            
            # Format results
            formatted_results = []
            for chunk_id, similarity, metadata in results:
                formatted_results.append({
                    'chunk_id': chunk_id,
                    'similarity': similarity,
                    'content': metadata.get('content', ''),
                    'metadata': metadata.get('metadata', {}),
                    'asset_id': metadata.get('asset_id')
                })
            
            logger.info(f"Found {len(formatted_results)} similar chunks for query")
            return formatted_results
            
        except Exception as e:
            logger.error(f"Error searching chunks: {str(e)}")
            raise

=== backend\__init__.py ===
"""Backend package initialization."""
__version__ = "1.0.0"

=== backend\config.py ===
"""
Configuration management using Pydantic Settings.
Loads environment variables from .env file.
"""
from pydantic_settings import BaseSettings, SettingsConfigDict
from pydantic import Field
from typing import List
import json


class Settings(BaseSettings):
    """Application settings loaded from environment variables."""
    
    # Database Configuration
    database_url: str = Field(
        default="postgresql+asyncpg://postgres:Ezz123456@localhost:5432/ragmind",
        alias="DATABASE_URL"
    )
    
    # LLM Provider Configuration
    gemini_api_key: str = Field(
        default="AIzaSyD2N-rsmfER9P2dZznBh4wXKAFZRajJ0eU",
        alias="GEMINI_API_KEY"
    )
    llm_provider: str = Field(default="gemini", alias="LLM_PROVIDER")
    gemini_model: str = Field(default="gemini-2.5-flash", alias="GEMINI_MODEL")
    
    # Vector DB Configuration
    vector_db_provider: str = Field(default="pgvector", alias="VECTOR_DB_PROVIDER")
    qdrant_url: str = Field(default="http://localhost:6333", alias="QDRANT_URL")
    qdrant_api_key: str = Field(default="", alias="QDRANT_API_KEY")
    
    # Storage Configuration
    upload_dir: str = Field(default="./uploads", alias="UPLOAD_DIR")
    max_file_size_mb: int = Field(default=50, alias="MAX_FILE_SIZE_MB")
    
    # Chunking Configuration
    chunk_size: int = Field(default=1000, alias="CHUNK_SIZE")
    chunk_overlap: int = Field(default=200, alias="CHUNK_OVERLAP")
    
    # API Configuration
    api_host: str = Field(default="0.0.0.0", alias="API_HOST")
    api_port: int = Field(default=8000, alias="API_PORT")
    api_title: str = Field(default="RAGMind API", alias="API_TITLE")
    api_version: str = Field(default="1.0.0", alias="API_VERSION")
    
    # Telegram Bot Configuration
    telegram_bot_token: str = Field(default="", alias="TELEGRAM_BOT_TOKEN")
    telegram_admin_id: str = Field(default="", alias="TELEGRAM_ADMIN_ID")
    
    # CORS Configuration
    cors_origins: List[str] = Field(
        default=["http://localhost:3000", "http://localhost:8080"],
        alias="CORS_ORIGINS"
    )
    
    # Logging
    log_level: str = Field(default="INFO", alias="LOG_LEVEL")
    
    model_config = SettingsConfigDict(
        env_file=".env",
        env_file_encoding="utf-8",
        case_sensitive=False,
        extra="ignore"
    )


# Global settings instance - use default values if .env not found
try:
    settings = Settings()
except Exception as e:
    # If .env is missing, use defaults
    import warnings
    warnings.warn(f".env file not found or invalid, using default settings: {str(e)}")
    # In Pydantic v2, we can't just pass _env_file=None to the constructor easily if it fails
    # We'll try to create a default instance without loading from env
    try:
        settings = Settings(_env_file=None)
    except:
        # Fallback to a very basic settings if even that fails
        settings = Settings()

=== backend\init_database.py ===
"""
Database initialization script.
Creates database and tables with pgvector extension.
"""
import asyncio
import sys
import os
from pathlib import Path

# Add parent directory to path
sys.path.insert(0, str(Path(__file__).parent.parent))

from backend.database import init_db
from backend.config import settings
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


async def create_database_if_not_exists():
    """Create the database if it doesn't exist."""
    import psycopg2
    from psycopg2.extensions import ISOLATION_LEVEL_AUTOCOMMIT
    
    # Parse connection string to get credentials for default 'postgres' db
    # Example: postgresql+asyncpg://postgres:Ezz123456@localhost:5432/ragmind
    db_url = settings.database_url.replace("postgresql+asyncpg://", "")
    auth, rest = db_url.split("@")
    user, password = auth.split(":")
    host_port, db_name = rest.split("/")
    host = host_port.split(":")[0]
    port = host_port.split(":")[1] if ":" in host_port else "5432"
    
    try:
        # Connect to default 'postgres' database
        conn = psycopg2.connect(
            dbname='postgres',
            user=user,
            password=password,
            host=host,
            port=port
        )
        conn.set_isolation_level(ISOLATION_LEVEL_AUTOCOMMIT)
        cur = conn.cursor()
        
        # Check if database exists
        cur.execute(f"SELECT 1 FROM pg_catalog.pg_database WHERE datname = '{db_name}'")
        exists = cur.fetchone()
        
        if not exists:
            logger.info(f"Creating database {db_name}...")
            cur.execute(f"CREATE DATABASE {db_name}")
            logger.info(f"Database {db_name} created successfully")
        else:
            logger.info(f"Database {db_name} already exists")
            
        cur.close()
        conn.close()
    except Exception as e:
        logger.error(f"Error creating database: {str(e)}")
        # We continue anyway, maybe it exists but we couldn't check


async def main():
    """Initialize database."""
    try:
        # Step 1: Create database if needed
        await create_database_if_not_exists()
        
        logger.info(f"Connecting to database: {settings.database_url.split('@')[1]}")
        
        # Step 2: Initialize tables and extensions
        await init_db()
        
        logger.info("✅ Database initialized successfully!")
        logger.info("Tables created:")
        logger.info("  - projects")
        logger.info("  - assets")
        logger.info("  - chunks (with vector embeddings)")
        logger.info("Extensions enabled:")
        logger.info("  - pgvector")
        
        return 0
        
    except Exception as e:
        logger.error(f"❌ Failed to initialize database: {str(e)}")
        return 1
    
    finally:
        from backend.database import close_db
        await close_db()


if __name__ == "__main__":
    exit_code = asyncio.run(main())
    sys.exit(exit_code)

=== backend\main.py ===
"""
Main FastAPI Application.
Entry point for the RAGMind backend API.
"""
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from contextlib import asynccontextmanager
# Configure logging
from backend.config import settings
import logging

logging.basicConfig(
    level=getattr(logging, settings.log_level),
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

from backend.database import init_db, close_db
from backend.routes import projects, documents, query, health, stats, bot_config


@asynccontextmanager
async def lifespan(app: FastAPI):
    """Application lifespan handler."""
    # Startup
    logger.info("Starting RAGMind API...")
    try:
        await init_db()
        logger.info("Database initialized successfully")
    except Exception as e:
        logger.error(f"Failed to initialize database: {str(e)}")
        raise
    
    yield
    
    # Shutdown
    logger.info("Shutting down RAGMind API...")
    await close_db()
    logger.info("Database connections closed")


# Create FastAPI app
app = FastAPI(
    title=settings.api_title,
    version=settings.api_version,
    description="""
    RAGMind - Retrieval Augmented Generation System
    
    A powerful document processing and question-answering API using:
    - Google Gemini 2.5 Flash for LLM capabilities
    - PostgreSQL with pgvector for vector storage
    - LangChain for document processing
    
    ## Features
    - Project-based document organization
    - Multi-format document support (PDF, TXT, DOCX)
    - Automatic text chunking and embedding
    - Vector similarity search
    - AI-powered question answering
    - Multi-language support (Arabic/English)
    """,
    lifespan=lifespan
)

# Configure CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # Allow all origins for development
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Include routers
app.include_router(health.router)
app.include_router(projects.router)
app.include_router(documents.router)
app.include_router(query.router)
app.include_router(stats.router)
app.include_router(bot_config.router)


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(
        "backend.main:app",
        host=settings.api_host,
        port=settings.api_port,
        reload=True
    )

=== frontend\app.js ===
/**
 * RAGMind Web Frontend
 * Main Application Logic
 */

// Configuration
const API_BASE_URL = 'http://localhost:8000';

// Translations
const i18n = {
    ar: {
        nav_dashboard: "لوحة التحكم",
        nav_projects: "المشاريع",
        nav_chat: "المحادثة الذكية",
        nav_bot: "إعدادات البوت",
        stat_projects: "إجمالي المشاريع",
        stat_docs: "المستندات",
        stat_chunks: "القطع النصية",
        recent_projects: "المشاريع الأخيرة",
        view_all: "عرض الكل",
        your_projects: "مشاريعك",
        welcome_title: "مرحباً بك في RAGMind",
        project_name_ph: "مثلاً: أبحاث الذكاء الاصطناعي",
        project_desc_ph: "وصف مختصر للمشروع...",
        create_project_btn: "إنشاء المشروع",
        upload_title: "رفع مستندات جديدة",
        upload_desc: "اسحب الملفات هنا أو اضغط للاختيار",
        docs_title: "المستندات الحالية",
        bot_settings_title: "إعدادات بوت التليجرام",
        bot_active_project: "المشروع النشط",
        bot_active_project_desc: "اختر المشروع الذي سيقوم البوت بالإجابة منه.",
        save_settings: "حفظ الإعدادات",
        bot_profile: "ملف البوت",
        bot_profile_desc: "تحديث اسم البوت على تليجرام.",
        bot_name: "اسم البوت",
        update_profile: "تحديث الملف الشخصي",
        select_project_ph: "اختر مشروعاً...",
        delete_confirm: "هل أنت متأكد؟",
        success_saved: "تم الحفظ بنجاح",
        error_generic: "حدث خطأ ما"
    },
    en: {
        nav_dashboard: "Dashboard",
        nav_projects: "Projects",
        nav_chat: "Smart Chat",
        nav_bot: "Bot Settings",
        stat_projects: "Total Projects",
        stat_docs: "Documents",
        stat_chunks: "Text Chunks",
        recent_projects: "Recent Projects",
        view_all: "View All",
        your_projects: "Your Projects",
        welcome_title: "Welcome to RAGMind",
        project_name_ph: "Ex: AI Research",
        project_desc_ph: "Short description...",
        create_project_btn: "Create Project",
        upload_title: "Upload New Documents",
        upload_desc: "Drag files here or click to select",
        docs_title: "Current Documents",
        bot_settings_title: "Telegram Bot Settings",
        bot_active_project: "Active Project",
        bot_active_project_desc: "Select the project the bot will answer from.",
        save_settings: "Save Settings",
        bot_profile: "Bot Profile",
        bot_profile_desc: "Update Bot Name on Telegram.",
        bot_name: "Bot Name",
        update_profile: "Update Profile",
        select_project_ph: "Select a project...",
        delete_confirm: "Are you sure?",
        success_saved: "Saved successfully",
        error_generic: "Something went wrong"
    }
};

// State Management
const state = {
    currentView: 'dashboard',
    projects: [],
    stats: null,
    selectedProject: null,
    chatMessages: [],
    isUploading: false,
    lang: localStorage.getItem('lang') || 'ar',
    theme: localStorage.getItem('theme') || 'dark'
};

// DOM Elements
const elements = {
    viewContainer: document.getElementById('view-container'),
    navItems: document.querySelectorAll('.sidebar-nav li'),
    newProjectBtn: document.getElementById('new-project-btn'),
    modalOverlay: document.getElementById('modal-overlay'),
    modalTitle: document.getElementById('modal-title'),
    modalBody: document.getElementById('modal-body'),
    closeModalBtn: document.querySelector('.close-modal'),
    themeToggle: document.getElementById('theme-toggle'),
    langToggle: document.getElementById('lang-toggle')
};

// --- API Client ---

const api = {
    async get(endpoint) {
        try {
            const response = await fetch(`${API_BASE_URL}${endpoint}`);
            if (!response.ok) throw new Error(`HTTP error! status: ${response.status}`);
            return await response.json();
        } catch (error) {
            console.error(`API Get Error (${endpoint}):`, error);
            showNotification(state.lang === 'ar' ? 'خطأ في الاتصال بالسيرفر' : 'Server Connection Error', 'error');
            throw error;
        }
    },

    async post(endpoint, data, isFormData = false) {
        try {
            const options = {
                method: 'POST',
                body: isFormData ? data : JSON.stringify(data)
            };
            if (!isFormData) {
                options.headers = { 'Content-Type': 'application/json' };
            }

            const response = await fetch(`${API_BASE_URL}${endpoint}`, options);
            if (!response.ok) {
                const errorData = await response.json();
                throw new Error(errorData.detail || 'Error');
            }
            return await response.json();
        } catch (error) {
            console.error(`API Post Error (${endpoint}):`, error);
            showNotification(error.message, 'error');
            throw error;
        }
    },

    async delete(endpoint) {
        try {
            const response = await fetch(`${API_BASE_URL}${endpoint}`, { method: 'DELETE' });
            if (!response.ok) throw new Error('Delete failed');
            return true;
        } catch (error) {
            console.error(`API Delete Error (${endpoint}):`, error);
            showNotification(error.message, 'error');
            throw error;
        }
    }
};

// --- View Rendering ---

const views = {
    async dashboard() {
        renderTemplate('dashboard-template');
        showLoader();

        try {
            const [projects, stats] = await Promise.all([
                api.get('/projects/'),
                api.get('/stats/')
            ]);
            state.projects = projects;

            // Update stats
            document.getElementById('stat-projects').textContent = stats.projects;
            document.getElementById('stat-docs').textContent = stats.documents;
            document.getElementById('stat-chunks').textContent = stats.chunks;

            // Render recent projects
            const list = document.getElementById('recent-projects-list');
            list.innerHTML = '';
            projects.slice(0, 3).forEach(project => {
                list.appendChild(createProjectCard(project));
            });

            applyTranslations();
        } catch (error) {
            console.error('Dashboard Load Error:', error);
        } finally {
            hideLoader();
        }
    },

    async projects() {
        renderTemplate('projects-template');
        showLoader();

        try {
            const projects = await api.get('/projects/');
            state.projects = projects;

            const list = document.getElementById('all-projects-list');
            list.innerHTML = '';
            projects.forEach(project => {
                list.appendChild(createProjectCard(project));
            });
            applyTranslations();
        } catch (error) {
            console.error('Projects Load Error:', error);
        } finally {
            hideLoader();
        }
    },

    async projectDetail(projectId) {
        renderTemplate('project-detail-template');
        showLoader();

        try {
            const project = await api.get(`/projects/${projectId}`);
            const docs = await api.get(`/projects/${projectId}/documents`);

            state.selectedProject = project;

            document.getElementById('project-name-title').textContent = project.name;

            const docsList = document.getElementById('project-docs-list');
            docsList.innerHTML = '';

            if (docs.length === 0) {
                docsList.innerHTML = `<p class="empty-msg">${state.lang === 'ar' ? 'لا توجد مستندات بعد' : 'No documents yet'}</p>`;
            } else {
                docs.forEach(doc => {
                    docsList.appendChild(createDocItem(doc));
                });
            }

            // Setup Upload Zone
            setupUploadZone(projectId);

            document.getElementById('back-to-projects').onclick = () => switchView('projects');
            applyTranslations();
        } catch (error) {
            console.error('Project Detail Load Error:', error);
        } finally {
            hideLoader();
        }
    },

    async chat() {
        renderTemplate('chat-template');

        const select = document.getElementById('chat-project-select');
        const projects = await api.get('/projects/');

        projects.forEach(p => {
            const opt = document.createElement('option');
            opt.value = p.id;
            opt.textContent = p.name;
            select.appendChild(opt);
        });

        const sendBtn = document.getElementById('send-btn');
        const chatInput = document.getElementById('chat-input');

        sendBtn.onclick = handleChatSubmit;
        chatInput.onkeydown = (e) => {
            if (e.key === 'Enter' && !e.shiftKey) {
                e.preventDefault();
                handleChatSubmit();
            }
        };
        applyTranslations();
    },

    async 'bot-config'() {
        renderTemplate('bot-config-template');
        showLoader();

        try {
            const [projects, config] = await Promise.all([
                api.get('/projects/'),
                api.get('/bot/config')
            ]);

            const select = document.getElementById('bot-active-project');
            projects.forEach(p => {
                const opt = document.createElement('option');
                opt.value = p.id;
                opt.textContent = p.name;
                if (config.active_project_id == p.id) opt.selected = true;
                select.appendChild(opt);
            });

            document.getElementById('save-bot-config-btn').onclick = async () => {
                const projectId = select.value;
                if (!projectId) return;
                try {
                    await api.post('/bot/config', { active_project_id: parseInt(projectId) });
                    showNotification(i18n[state.lang].success_saved, 'success');
                } catch (e) {
                    console.error(e);
                }
            };

            document.getElementById('update-bot-profile-btn').onclick = async () => {
                const name = document.getElementById('bot-name-input').value;
                if (!name) return;
                const formData = new FormData();
                formData.append('name', name);
                try {
                    await api.post('/bot/profile', formData, true);
                    showNotification(i18n[state.lang].success_saved, 'success');
                } catch (e) {
                    console.error(e);
                }
            };

            applyTranslations();
        } catch (error) {
            console.error('Bot Config Error:', error);
        } finally {
            hideLoader();
        }
    }
};

// --- Helpers ---

function renderTemplate(templateId) {
    const template = document.getElementById(templateId);
    const clone = template.content.cloneNode(true);
    elements.viewContainer.innerHTML = '';
    elements.viewContainer.appendChild(clone);
}

function showLoader() {
    const loader = document.createElement('div');
    loader.className = 'loader-container';
    loader.innerHTML = '<div class="loader"></div>';
    elements.viewContainer.appendChild(loader);
}

function hideLoader() {
    const loader = elements.viewContainer.querySelector('.loader-container');
    if (loader) loader.remove();
}

function createProjectCard(project) {
    const card = document.createElement('div');
    card.className = 'project-card';
    card.innerHTML = `
        <h3>${project.name}</h3>
        <p>${project.description || (state.lang === 'ar' ? 'لا يوجد وصف' : 'No description')}</p>
        <div class="project-meta">
            <span><i class="far fa-calendar"></i> ${new Date(project.created_at).toLocaleDateString(state.lang === 'ar' ? 'ar-EG' : 'en-US')}</span>
            <button class="delete-project-btn" data-id="${project.id}"><i class="fas fa-trash"></i></button>
        </div>
    `;

    card.onclick = (e) => {
        if (e.target.closest('.delete-project-btn')) {
            handleDeleteProject(project.id);
            return;
        }
        switchView('projectDetail', project.id);
    };

    return card;
}

function createDocItem(doc) {
    const item = document.createElement('div');
    item.className = 'doc-item';
    const statusClass = doc.status === 'completed' ? 'status-done' : (doc.status === 'failed' ? 'status-error' : 'status-processing');
    const statusIcon = doc.status === 'completed' ? 'fa-check-circle' : (doc.status === 'failed' ? 'fa-exclamation-circle' : 'fa-spinner fa-spin');

    const statusText = {
        completed: state.lang === 'ar' ? 'مكتمل' : 'Completed',
        failed: state.lang === 'ar' ? 'فشل' : 'Failed',
        processing: state.lang === 'ar' ? 'جاري المعالجة' : 'Processing'
    };

    item.innerHTML = `
        <div class="doc-info">
            <i class="fas fa-file-pdf"></i>
            <div class="doc-details">
                <span class="doc-name">${doc.original_filename}</span>
                <span class="doc-size">${(doc.file_size / 1024).toFixed(1)} KB</span>
            </div>
        </div>
        <div class="doc-status ${statusClass}">
            <i class="fas ${statusIcon}"></i>
            <span>${statusText[doc.status] || doc.status}</span>
        </div>
        <button class="delete-doc-btn" data-id="${doc.id}"><i class="fas fa-trash"></i></button>
    `;

    item.querySelector('.delete-doc-btn').onclick = () => handleDeleteDoc(doc.id);

    return item;
}

function showNotification(message, type = 'info') {
    const toast = document.createElement('div');
    toast.className = `toast toast-${type}`;
    toast.textContent = message;
    document.body.appendChild(toast);
    setTimeout(() => toast.classList.add('show'), 100);
    setTimeout(() => {
        toast.classList.remove('show');
        setTimeout(() => toast.remove(), 300);
    }, 3000);
}

function applyTranslations() {
    const t = i18n[state.lang];
    document.querySelectorAll('[data-i18n]').forEach(el => {
        const key = el.dataset.i18n;
        if (t[key]) el.textContent = t[key];
    });

    // Update placeholders
    if (document.getElementById('new-project-name')) {
        document.getElementById('new-project-name').placeholder = t.project_name_ph;
        document.getElementById('new-project-desc').placeholder = t.project_desc_ph;
    }

    // Update Lang Button
    elements.langToggle.querySelector('.lang-code').textContent = state.lang === 'ar' ? 'EN' : 'AR';

    // Update Dir
    document.documentElement.dir = state.lang === 'ar' ? 'rtl' : 'ltr';
    document.documentElement.lang = state.lang;
}

function toggleTheme() {
    state.theme = state.theme === 'dark' ? 'light' : 'dark';
    document.body.classList.toggle('light-theme', state.theme === 'light');
    document.body.classList.toggle('dark-theme', state.theme === 'dark');

    const icon = elements.themeToggle.querySelector('i');
    icon.className = state.theme === 'dark' ? 'fas fa-moon' : 'fas fa-sun';

    localStorage.setItem('theme', state.theme);
}

function toggleLang() {
    state.lang = state.lang === 'ar' ? 'en' : 'ar';
    localStorage.setItem('lang', state.lang);
    applyTranslations();
    switchView(state.currentView, state.selectedProject ? state.selectedProject.id : null);
}

// --- Event Handlers ---

async function switchView(viewName, params = null) {
    state.currentView = viewName;

    // Update Nav
    elements.navItems.forEach(item => {
        item.classList.toggle('active', item.dataset.view === viewName);
    });

    // Render View
    if (viewName === 'projectDetail') {
        await views.projectDetail(params);
    } else if (views[viewName]) {
        await views[viewName]();
    }
}

async function handleNewProject() {
    elements.modalTitle.textContent = i18n[state.lang].create_project_btn;
    elements.modalBody.innerHTML = `
        <div class="form-group">
            <label>${state.lang === 'ar' ? 'اسم المشروع' : 'Project Name'}</label>
            <input type="text" id="new-project-name" class="form-control">
        </div>
        <div class="form-group">
            <label>${state.lang === 'ar' ? 'الوصف' : 'Description'}</label>
            <textarea id="new-project-desc" class="form-control"></textarea>
        </div>
        <button id="save-project-btn" class="btn btn-primary w-100 mt-4">${i18n[state.lang].create_project_btn}</button>
    `;
    applyTranslations();

    elements.modalOverlay.classList.remove('hidden');

    document.getElementById('save-project-btn').onclick = async () => {
        const name = document.getElementById('new-project-name').value;
        const description = document.getElementById('new-project-desc').value;

        if (!name) {
            showNotification(state.lang === 'ar' ? 'يرجى إدخال اسم المشروع' : 'Please enter project name', 'warning');
            return;
        }

        try {
            await api.post('/projects/', { name, description });
            showNotification(i18n[state.lang].success_saved, 'success');
            elements.modalOverlay.classList.add('hidden');
            switchView(state.currentView); // Refresh current view
        } catch (error) {
            console.error('Create Project Error:', error);
        }
    };
}

async function handleDeleteProject(id) {
    if (confirm(i18n[state.lang].delete_confirm)) {
        try {
            await api.delete(`/projects/${id}`);
            showNotification(i18n[state.lang].success_saved, 'success');
            switchView(state.currentView);
        } catch (error) {
            console.error('Delete Project Error:', error);
        }
    }
}

async function handleDeleteDoc(id) {
    if (confirm(i18n[state.lang].delete_confirm)) {
        try {
            await api.delete(`/documents/${id}`);
            showNotification(i18n[state.lang].success_saved, 'success');
            if (state.selectedProject) {
                switchView('projectDetail', state.selectedProject.id);
            }
        } catch (error) {
            console.error('Delete Doc Error:', error);
        }
    }
}

async function handleChatSubmit() {
    const input = document.getElementById('chat-input');
    const projectSelect = document.getElementById('chat-project-select');
    const langSelect = document.getElementById('chat-lang');

    const query = input.value.trim();
    const projectId = projectSelect.value;
    const language = langSelect.value;

    if (!query) return;
    if (!projectId) {
        showNotification(state.lang === 'ar' ? 'يرجى اختيار مشروع أولاً' : 'Select a project first', 'warning');
        return;
    }

    addChatMessage('user', query);
    input.value = '';

    const thinkingId = addChatMessage('bot', state.lang === 'ar' ? 'جاري التفكير...' : 'Thinking...', true);

    try {
        const result = await api.post(`/projects/${projectId}/query`, {
            query,
            language,
            top_k: 5
        });

        updateChatMessage(thinkingId, result.answer, result.sources);
    } catch (error) {
        updateChatMessage(thinkingId, i18n[state.lang].error_generic);
    }
}

function addChatMessage(role, text, isThinking = false) {
    const messagesContainer = document.getElementById('chat-messages');
    const welcome = messagesContainer.querySelector('.welcome-msg');
    if (welcome) welcome.remove();

    const id = Date.now();
    const msgDiv = document.createElement('div');
    msgDiv.className = `chat-msg ${role}-msg`;
    msgDiv.id = `msg-${id}`;
    msgDiv.innerHTML = `
        <div class="msg-avatar">${role === 'user' ? 'U' : '<i class="fas fa-robot"></i>'}</div>
        <div class="msg-content">
            <div class="text">${text}</div>
            ${isThinking ? '<div class="typing-indicator"><span></span><span></span><span></span></div>' : ''}
        </div>
    `;
    messagesContainer.appendChild(msgDiv);
    messagesContainer.scrollTop = messagesContainer.scrollHeight;
    return id;
}

function updateChatMessage(id, text, sources = null) {
    const msgDiv = document.getElementById(`msg-${id}`);
    if (!msgDiv) return;

    const content = msgDiv.querySelector('.text');
    const indicator = msgDiv.querySelector('.typing-indicator');
    if (indicator) indicator.remove();

    content.textContent = text;

    if (sources && sources.length > 0) {
        const sourcesDiv = document.createElement('div');
        sourcesDiv.className = 'msg-sources';
        sourcesDiv.innerHTML = `<strong>${state.lang === 'ar' ? 'المصادر:' : 'Sources:'}</strong>`;
        const list = document.createElement('ul');
        sources.slice(0, 3).forEach(s => {
            const li = document.createElement('li');
            li.textContent = `${s.document_name} (${(s.similarity * 100).toFixed(1)}%)`;
            list.appendChild(li);
        });
        sourcesDiv.appendChild(list);
        msgDiv.querySelector('.msg-content').appendChild(sourcesDiv);
    }

    const container = document.getElementById('chat-messages');
    container.scrollTop = container.scrollHeight;
}

function setupUploadZone(projectId) {
    const zone = document.getElementById('upload-zone');
    const input = document.getElementById('file-input');

    zone.onclick = () => input.click();

    zone.ondragover = (e) => {
        e.preventDefault();
        zone.classList.add('dragover');
    };

    zone.ondragleave = () => zone.classList.remove('dragover');

    zone.ondrop = (e) => {
        e.preventDefault();
        zone.classList.remove('dragover');
        handleFiles(e.dataTransfer.files, projectId);
    };

    input.onchange = () => handleFiles(input.files, projectId);
}

async function handleFiles(files, projectId) {
    for (const file of files) {
        const formData = new FormData();
        formData.append('file', file);

        showNotification(`${state.lang === 'ar' ? 'جاري رفع' : 'Uploading'} ${file.name}...`, 'info');

        try {
            await api.post(`/projects/${projectId}/documents`, formData, true);
            showNotification(`${state.lang === 'ar' ? 'تم رفع' : 'Uploaded'} ${file.name}`, 'success');
            switchView('projectDetail', projectId); // Refresh list
        } catch (error) {
            console.error('Upload Error:', error);
        }
    }
}

// --- Initialization ---

document.addEventListener('DOMContentLoaded', () => {
    // Nav Clicks
    elements.navItems.forEach(item => {
        item.onclick = () => switchView(item.dataset.view);
    });

    // New Project Click
    elements.newProjectBtn.onclick = handleNewProject;

    // Close Modal
    elements.closeModalBtn.onclick = () => elements.modalOverlay.classList.add('hidden');
    elements.modalOverlay.onclick = (e) => {
        if (e.target === elements.modalOverlay) elements.modalOverlay.classList.add('hidden');
    };

    // Theme & Lang
    elements.themeToggle.onclick = toggleTheme;
    elements.langToggle.onclick = toggleLang;

    // Init State
    if (state.theme === 'light') {
        document.body.classList.add('light-theme');
        document.body.classList.remove('dark-theme');
        elements.themeToggle.querySelector('i').className = 'fas fa-sun';
    }

    // Initial View
    applyTranslations();
    switchView('dashboard');
});

=== frontend\index.html ===
<!DOCTYPE html>
<html lang="ar" dir="rtl">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>RAGMind | لوحة التحكم الذكية</title>
    <!-- Fonts -->
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link
        href="https://fonts.googleapis.com/css2?family=Cairo:wght@300;400;600;700&family=Inter:wght@300;400;600;700&display=swap"
        rel="stylesheet">
    <!-- Icons -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
    <!-- Custom Styles -->
    <link rel="stylesheet" href="style.css">
</head>

<body class="dark-theme">
    <div class="app-container">
        <!-- Sidebar -->
        <aside class="sidebar">
            <div class="sidebar-header">
                <div class="logo">
                    <i class="fas fa-brain-circuit"></i>
                    <span>RAGMind</span>
                </div>
            </div>

            <nav class="sidebar-nav">
                <ul>
                    <li class="active" data-view="dashboard">
                        <i class="fas fa-chart-pie"></i>
                        <span data-i18n="nav_dashboard">لوحة التحكم</span>
                    </li>
                    <li data-view="projects">
                        <i class="fas fa-folder-tree"></i>
                        <span data-i18n="nav_projects">المشاريع</span>
                    </li>
                    <li data-view="chat">
                        <i class="fas fa-comment-dots"></i>
                        <span data-i18n="nav_chat">المحادثة الذكية</span>
                    </li>
                    <li data-view="bot-config">
                        <i class="fas fa-robot"></i>
                        <span data-i18n="nav_bot">إعدادات البوت</span>
                    </li>
                </ul>
            </nav>

            <div class="sidebar-footer">
                <div class="user-info">
                    <div class="avatar">A</div>
                    <div class="details">
                        <p class="name">المستخدم</p>
                        <p class="status">متصل</p>
                    </div>
                </div>
                <button id="lang-toggle" class="icon-btn" title="Switch Language">
                    <span class="lang-code">EN</span>
                </button>
                <button id="theme-toggle" class="icon-btn">
                    <i class="fas fa-moon"></i>
                </button>
            </div>
        </aside>

        <!-- Main Content -->
        <main class="main-content">
            <header class="top-bar">
                <div class="search-bar">
                    <i class="fas fa-search"></i>
                    <input type="text" placeholder="ابحث عن مشروع أو مستند...">
                </div>
                <div class="actions">
                    <button id="new-project-btn" class="btn btn-primary">
                        <i class="fas fa-plus"></i>
                        <span data-i18n="create_project_btn">مشروع جديد</span>
                    </button>
                </div>
            </header>

            <div id="view-container" class="view-container">
                <!-- Views will be injected here -->
                <div class="loader-container">
                    <div class="loader"></div>
                </div>
            </div>
        </main>
    </div>

    <!-- Modals -->
    <div id="modal-overlay" class="modal-overlay hidden">
        <div class="modal">
            <div class="modal-header">
                <h3 id="modal-title">عنوان النافذة</h3>
                <button class="close-modal"><i class="fas fa-times"></i></button>
            </div>
            <div id="modal-body" class="modal-body">
                <!-- Modal content -->
            </div>
        </div>
    </div>

    <!-- Templates -->
    <template id="dashboard-template">
        <div class="dashboard-view">
            <h1 class="view-title" data-i18n="welcome_title">مرحباً بك في RAGMind</h1>
            <div class="stats-grid">
                <div class="stat-card">
                    <div class="icon"><i class="fas fa-folder"></i></div>
                    <div class="info">
                        <span class="label" data-i18n="stat_projects">إجمالي المشاريع</span>
                        <span class="value" id="stat-projects">0</span>
                    </div>
                </div>
                <div class="stat-card">
                    <div class="icon"><i class="fas fa-file-alt"></i></div>
                    <div class="info">
                        <span class="label" data-i18n="stat_docs">المستندات</span>
                        <span class="value" id="stat-docs">0</span>
                    </div>
                </div>
                <div class="stat-card">
                    <div class="icon"><i class="fas fa-microchip"></i></div>
                    <div class="info">
                        <span class="label" data-i18n="stat_chunks">القطع النصية</span>
                        <span class="value" id="stat-chunks">0</span>
                    </div>
                </div>
            </div>

            <section class="recent-projects">
                <div class="section-header">
                    <h2 data-i18n="recent_projects">المشاريع الأخيرة</h2>
                    <a href="#" class="link" data-i18n="view_all">عرض الكل</a>
                </div>
                <div class="projects-grid" id="recent-projects-list">
                    <!-- Projects will be injected here -->
                </div>
            </section>
        </div>
    </template>

    <template id="projects-template">
        <div class="projects-view">
            <div class="section-header">
                <h1 class="view-title" data-i18n="your_projects">مشاريعك</h1>
            </div>
            <div class="projects-grid" id="all-projects-list">
                <!-- Projects will be injected here -->
            </div>
        </div>
    </template>

    <template id="chat-template">
        <div class="chat-view">
            <div class="chat-sidebar">
                <h3 data-i18n="select_project_ph">اختر مشروعاً</h3>
                <select id="chat-project-select" class="form-control">
                    <option value="" data-i18n="select_project_ph">اختر مشروعاً للبدء...</option>
                </select>
                <div class="chat-settings">
                    <label>اللغة:</label>
                    <select id="chat-lang" class="form-control">
                        <option value="ar">العربية</option>
                        <option value="en">English</option>
                    </select>
                </div>
            </div>
            <div class="chat-main">
                <div class="chat-messages" id="chat-messages">
                    <div class="welcome-msg">
                        <i class="fas fa-robot"></i>
                        <h2>كيف يمكنني مساعدتك اليوم؟</h2>
                        <p>اختر مشروعاً من القائمة الجانبية وابدأ في طرح الأسئلة حول مستنداتك.</p>
                    </div>
                </div>
                <div class="chat-input-container">
                    <div class="chat-input-wrapper">
                        <textarea id="chat-input" placeholder="اسأل أي شيء حول مستنداتك..." rows="1"></textarea>
                        <button id="send-btn" class="send-btn">
                            <i class="fas fa-paper-plane"></i>
                        </button>
                    </div>
                </div>
            </div>
        </div>
    </template>

    <template id="project-detail-template">
        <div class="project-detail-view">
            <div class="project-header">
                <button class="back-btn" id="back-to-projects"><i class="fas fa-arrow-right"></i></button>
                <h1 id="project-name-title">اسم المشروع</h1>
            </div>

            <div class="project-content-grid">
                <div class="upload-section">
                    <h3 data-i18n="upload_title">رفع مستندات جديدة</h3>
                    <div class="upload-zone" id="upload-zone">
                        <i class="fas fa-cloud-upload-alt"></i>
                        <p data-i18n="upload_desc">اسحب الملفات هنا أو اضغط للاختيار</p>
                        <span class="hint">يدعم PDF, TXT, DOCX</span>
                        <input type="file" id="file-input" multiple hidden>
                    </div>
                    <div id="upload-progress-list" class="upload-progress-list"></div>
                </div>

                <div class="documents-section">
                    <h3 data-i18n="docs_title">المستندات الحالية</h3>
                    <div class="documents-list" id="project-docs-list">
                        <!-- Documents will be injected here -->
                    </div>
                </div>
            </div>
        </div>
    </template>

    <template id="bot-config-template">
        <div class="bot-config-view">
            <h1 class="view-title" data-i18n="bot_settings_title">إعدادات بوت التليجرام</h1>

            <div class="config-card">
                <div class="config-section">
                    <h3 data-i18n="bot_active_project">المشروع النشط</h3>
                    <p class="config-desc" data-i18n="bot_active_project_desc">اختر المشروع الذي سيقوم البوت بالإجابة
                        منه.</p>
                    <select id="bot-active-project" class="form-control">
                        <option value="">اختر مشروعاً...</option>
                    </select>
                    <button id="save-bot-config-btn" class="btn btn-primary mt-4">
                        <i class="fas fa-save"></i>
                        <span data-i18n="save_settings">حفظ الإعدادات</span>
                    </button>
                </div>

                <div class="config-section mt-4">
                    <h3 data-i18n="bot_profile">ملف البوت</h3>
                    <p class="config-desc" data-i18n="bot_profile_desc">تحديث اسم البوت على تليجرام.</p>

                    <div class="form-group">
                        <label data-i18n="bot_name">اسم البوت</label>
                        <input type="text" id="bot-name-input" class="form-control" placeholder="RAGMind Bot">
                    </div>

                    <button id="update-bot-profile-btn" class="btn btn-primary mt-4">
                        <i class="fas fa-user-edit"></i>
                        <span data-i18n="update_profile">تحديث الملف الشخصي</span>
                    </button>
                </div>
            </div>
        </div>
    </template>

    <!-- Scripts -->
    <script src="app.js"></script>
</body>

</html>

=== frontend\style.css ===
:root {
    /* Color Palette - Premium Dark Mode */
    --bg-main: #0a0b10;
    --bg-sidebar: #11131a;
    --bg-card: rgba(255, 255, 255, 0.03);
    --bg-card-hover: rgba(255, 255, 255, 0.06);
    --accent-primary: #6366f1;
    --accent-secondary: #8b5cf6;
    --text-main: #f8fafc;
    --text-muted: #94a3b8;
    --border-color: rgba(255, 255, 255, 0.08);
    --glass-bg: rgba(255, 255, 255, 0.02);
    --glass-border: rgba(255, 255, 255, 0.05);
    --success: #10b981;
    --error: #ef4444;
    --warning: #f59e0b;

    /* Transitions */
    --transition-fast: 0.2s ease;
    --transition-slow: 0.4s cubic-bezier(0.4, 0, 0.2, 1);
}

/* Light Mode Overrides */
body.light-theme {
    --bg-main: #f8fafc;
    --bg-sidebar: #ffffff;
    --bg-card: #ffffff;
    --bg-card-hover: #f1f5f9;
    --text-main: #0f172a;
    --text-muted: #64748b;
    --border-color: #e2e8f0;
    --glass-bg: rgba(255, 255, 255, 0.8);
    --glass-border: #e2e8f0;
}

body.light-theme .main-content {
    background: radial-gradient(circle at top right, rgba(99, 102, 241, 0.1), transparent);
}

body.light-theme .stat-card {
    box-shadow: 0 4px 6px -1px rgba(0, 0, 0, 0.1), 0 2px 4px -1px rgba(0, 0, 0, 0.06);
}

body.light-theme .project-card {
    box-shadow: 0 1px 3px 0 rgba(0, 0, 0, 0.1), 0 1px 2px 0 rgba(0, 0, 0, 0.06);
}

* {
    margin: 0;
    padding: 0;
    box-sizing: border-box;
}

body {
    font-family: 'Inter', 'Cairo', sans-serif;
    background-color: var(--bg-main);
    color: var(--text-main);
    overflow: hidden;
    line-height: 1.6;
}

/* App Layout */
.app-container {
    display: flex;
    height: 100vh;
    width: 100vw;
}

/* Sidebar */
.sidebar {
    width: 280px;
    background-color: var(--bg-sidebar);
    border-left: 1px solid var(--border-color);
    display: flex;
    flex-direction: column;
    padding: 24px;
    z-index: 100;
}

.sidebar-header .logo {
    display: flex;
    align-items: center;
    gap: 12px;
    font-size: 24px;
    font-weight: 700;
    color: var(--accent-primary);
    margin-bottom: 48px;
}

.sidebar-nav ul {
    list-style: none;
}

.sidebar-nav li {
    display: flex;
    align-items: center;
    gap: 12px;
    padding: 14px 18px;
    border-radius: 12px;
    margin-bottom: 8px;
    cursor: pointer;
    color: var(--text-muted);
    transition: var(--transition-fast);
}

.sidebar-nav li:hover {
    background-color: var(--bg-card-hover);
    color: var(--text-main);
}

.sidebar-nav li.active {
    background-color: var(--accent-primary);
    color: white;
    box-shadow: 0 4px 12px rgba(99, 102, 241, 0.3);
}

.sidebar-footer {
    margin-top: auto;
    display: flex;
    align-items: center;
    justify-content: space-between;
    padding-top: 24px;
    border-top: 1px solid var(--border-color);
}

.user-info {
    display: flex;
    align-items: center;
    gap: 12px;
}

.avatar {
    width: 40px;
    height: 40px;
    background: linear-gradient(135deg, var(--accent-primary), var(--accent-secondary));
    border-radius: 50%;
    display: flex;
    align-items: center;
    justify-content: center;
    font-weight: 600;
}

.user-info .name {
    font-size: 14px;
    font-weight: 600;
}

.user-info .status {
    font-size: 12px;
    color: var(--success);
}

/* Main Content */
.main-content {
    flex: 1;
    display: flex;
    flex-direction: column;
    overflow: hidden;
    background: radial-gradient(circle at top right, rgba(99, 102, 241, 0.05), transparent);
}

.top-bar {
    height: 80px;
    padding: 0 40px;
    display: flex;
    align-items: center;
    justify-content: space-between;
    border-bottom: 1px solid var(--border-color);
}

.search-bar {
    display: flex;
    align-items: center;
    background-color: var(--bg-card);
    padding: 10px 20px;
    border-radius: 30px;
    width: 400px;
    border: 1px solid var(--border-color);
}

.search-bar input {
    background: none;
    border: none;
    color: var(--text-main);
    margin-right: 12px;
    width: 100%;
    outline: none;
}

.view-container {
    flex: 1;
    padding: 40px;
    overflow-y: auto;
}

/* Dashboard */
.view-title {
    font-size: 32px;
    font-weight: 700;
    margin-bottom: 32px;
}

.stats-grid {
    display: grid;
    grid-template-columns: repeat(auto-fit, minmax(240px, 1fr));
    gap: 24px;
    margin-bottom: 48px;
}

.stat-card {
    background: var(--glass-bg);
    backdrop-filter: blur(10px);
    border: 1px solid var(--glass-border);
    padding: 24px;
    border-radius: 20px;
    display: flex;
    align-items: center;
    gap: 20px;
    transition: var(--transition-slow);
}

.stat-card:hover {
    transform: translateY(-5px);
    border-color: var(--accent-primary);
}

.stat-card .icon {
    width: 56px;
    height: 56px;
    background: rgba(99, 102, 241, 0.1);
    border-radius: 16px;
    display: flex;
    align-items: center;
    justify-content: center;
    font-size: 24px;
    color: var(--accent-primary);
}

.stat-card .label {
    display: block;
    color: var(--text-muted);
    font-size: 14px;
}

.stat-card .value {
    font-size: 28px;
    font-weight: 700;
}

/* Projects Grid */
.projects-grid {
    display: grid;
    grid-template-columns: repeat(auto-fill, minmax(300px, 1fr));
    gap: 24px;
}

.project-card {
    background: var(--bg-card);
    border: 1px solid var(--border-color);
    border-radius: 20px;
    padding: 24px;
    cursor: pointer;
    transition: var(--transition-fast);
    position: relative;
    overflow: hidden;
}

.project-card:hover {
    background: var(--bg-card-hover);
    border-color: var(--accent-primary);
}

.project-card h3 {
    font-size: 20px;
    margin-bottom: 12px;
}

.project-card p {
    color: var(--text-muted);
    font-size: 14px;
    margin-bottom: 20px;
    display: -webkit-box;
    -webkit-line-clamp: 2;
    -webkit-box-orient: vertical;
    overflow: hidden;
}

.project-meta {
    display: flex;
    justify-content: space-between;
    font-size: 12px;
    color: var(--text-muted);
}

/* Chat View */
.chat-view {
    display: flex;
    height: 100%;
    gap: 24px;
}

.chat-sidebar {
    width: 300px;
    background: var(--bg-card);
    border-radius: 20px;
    padding: 24px;
    display: flex;
    flex-direction: column;
    gap: 20px;
}

.chat-main {
    flex: 1;
    display: flex;
    flex-direction: column;
    background: var(--bg-card);
    border-radius: 20px;
    overflow: hidden;
}

.chat-messages {
    flex: 1;
    padding: 32px;
    overflow-y: auto;
    display: flex;
    flex-direction: column;
    gap: 24px;
}

.welcome-msg {
    text-align: center;
    margin-top: 100px;
    color: var(--text-muted);
}

.welcome-msg i {
    font-size: 64px;
    color: var(--accent-primary);
    margin-bottom: 24px;
}

.chat-input-container {
    padding: 24px 32px;
    background: rgba(0, 0, 0, 0.2);
}

.chat-input-wrapper {
    background: var(--bg-main);
    border: 1px solid var(--border-color);
    border-radius: 16px;
    padding: 12px 20px;
    display: flex;
    align-items: center;
    gap: 16px;
}

.chat-input-wrapper textarea {
    flex: 1;
    background: none;
    border: none;
    color: var(--text-main);
    resize: none;
    outline: none;
    font-family: inherit;
    font-size: 16px;
}

.send-btn {
    width: 44px;
    height: 44px;
    background: var(--accent-primary);
    border: none;
    border-radius: 12px;
    color: white;
    cursor: pointer;
    transition: var(--transition-fast);
}

.send-btn:hover {
    transform: scale(1.05);
    background: var(--accent-secondary);
}

/* Chat Messages */
.chat-msg {
    display: flex;
    gap: 16px;
    max-width: 85%;
    animation: fadeIn 0.3s ease;
}

.user-msg {
    align-self: flex-end;
    flex-direction: row-reverse;
}

.msg-avatar {
    width: 36px;
    height: 36px;
    background: var(--bg-card-hover);
    border-radius: 10px;
    display: flex;
    align-items: center;
    justify-content: center;
    font-weight: 700;
    flex-shrink: 0;
}

.user-msg .msg-avatar {
    background: var(--accent-primary);
}

.msg-content {
    background: var(--bg-card);
    padding: 16px 20px;
    border-radius: 20px;
    border: 1px solid var(--border-color);
}

.user-msg .msg-content {
    background: var(--accent-primary);
    border: none;
    border-bottom-right-radius: 4px;
}

.bot-msg .msg-content {
    border-bottom-left-radius: 4px;
}

.msg-sources {
    margin-top: 12px;
    padding-top: 12px;
    border-top: 1px solid var(--border-color);
    font-size: 13px;
}

.msg-sources ul {
    list-style: none;
    margin-top: 4px;
}

.msg-sources li {
    color: var(--text-muted);
    display: flex;
    align-items: center;
    gap: 8px;
}

.msg-sources li::before {
    content: '•';
    color: var(--accent-primary);
}

/* Typing Indicator */
.typing-indicator {
    display: flex;
    gap: 4px;
    padding: 4px 0;
}

.typing-indicator span {
    width: 6px;
    height: 6px;
    background: var(--text-muted);
    border-radius: 50%;
    animation: bounce 1.4s infinite ease-in-out both;
}

.typing-indicator span:nth-child(1) {
    animation-delay: -0.32s;
}

.typing-indicator span:nth-child(2) {
    animation-delay: -0.16s;
}

@keyframes bounce {

    0%,
    80%,
    100% {
        transform: scale(0);
    }

    40% {
        transform: scale(1.0);
    }
}

/* Document Items */
.doc-item {
    background: var(--bg-card);
    border: 1px solid var(--border-color);
    padding: 16px;
    border-radius: 16px;
    display: flex;
    align-items: center;
    justify-content: space-between;
    margin-bottom: 12px;
    transition: var(--transition-fast);
}

.doc-item:hover {
    border-color: var(--accent-primary);
    background: var(--bg-card-hover);
}

.doc-info {
    display: flex;
    align-items: center;
    gap: 16px;
}

.doc-info i {
    font-size: 24px;
    color: var(--error);
}

.doc-details {
    display: flex;
    flex-direction: column;
}

.doc-name {
    font-weight: 600;
    font-size: 14px;
}

.doc-size {
    font-size: 12px;
    color: var(--text-muted);
}

.doc-status {
    display: flex;
    align-items: center;
    gap: 8px;
    font-size: 12px;
    padding: 4px 12px;
    border-radius: 20px;
}

.status-done {
    background: rgba(16, 185, 129, 0.1);
    color: var(--success);
}

.status-processing {
    background: rgba(245, 158, 11, 0.1);
    color: var(--warning);
}

.status-error {
    background: rgba(239, 68, 68, 0.1);
    color: var(--error);
}

/* Project Detail Layout */
.project-content-grid {
    display: grid;
    grid-template-columns: 1fr 1.5fr;
    gap: 32px;
}

.upload-zone {
    border: 2px dashed var(--border-color);
    border-radius: 20px;
    padding: 40px;
    text-align: center;
    cursor: pointer;
    transition: var(--transition-fast);
}

.upload-zone:hover,
.upload-zone.dragover {
    border-color: var(--accent-primary);
    background: rgba(99, 102, 241, 0.05);
}

.upload-zone i {
    font-size: 48px;
    color: var(--accent-primary);
    margin-bottom: 16px;
}

/* Buttons */
.btn {
    padding: 10px 24px;
    border-radius: 12px;
    border: none;
    font-weight: 600;
    cursor: pointer;
    display: flex;
    align-items: center;
    gap: 10px;
    transition: var(--transition-fast);
}

.btn-primary {
    background: var(--accent-primary);
    color: white;
}

.btn-primary:hover {
    background: var(--accent-secondary);
    box-shadow: 0 4px 15px rgba(99, 102, 241, 0.4);
}

/* Modal */
.modal-overlay {
    position: fixed;
    top: 0;
    left: 0;
    width: 100%;
    height: 100%;
    background: rgba(0, 0, 0, 0.8);
    backdrop-filter: blur(5px);
    display: flex;
    align-items: center;
    justify-content: center;
    z-index: 1000;
    transition: var(--transition-fast);
}

.modal {
    background: var(--bg-sidebar);
    width: 500px;
    border-radius: 24px;
    padding: 32px;
    border: 1px solid var(--border-color);
}

.hidden {
    display: none;
    opacity: 0;
    pointer-events: none;
}

/* Loader */
.loader-container {
    display: flex;
    justify-content: center;
    align-items: center;
    height: 100%;
}

.loader {
    width: 48px;
    height: 48px;
    border: 5px solid var(--bg-card);
    border-bottom-color: var(--accent-primary);
    border-radius: 50%;
    animation: rotation 1s linear infinite;
}

@keyframes rotation {
    0% {
        transform: rotate(0deg);
    }

    100% {
        transform: rotate(360deg);
    }
}

/* Toasts */
.toast {
    position: fixed;
    bottom: 32px;
    left: 50%;
    transform: translateX(-50%) translateY(100px);
    padding: 12px 24px;
    border-radius: 12px;
    background: var(--bg-sidebar);
    border: 1px solid var(--border-color);
    color: var(--text-main);
    z-index: 2000;
    transition: var(--transition-slow);
    box-shadow: 0 10px 30px rgba(0, 0, 0, 0.5);
}

.toast.show {
    transform: translateX(-50%) translateY(0);
}

.toast-success {
    border-left: 4px solid var(--success);
}

.toast-error {
    border-left: 4px solid var(--error);
}

.toast-warning {
    border-left: 4px solid var(--warning);
}

/* Custom Scrollbar */
::-webkit-scrollbar {
    width: 6px;
}

::-webkit-scrollbar-track {
    background: transparent;
}

::-webkit-scrollbar-thumb {
    background: var(--border-color);
    border-radius: 10px;
}

::-webkit-scrollbar-thumb:hover {
    background: var(--text-muted);
}

/* Forms */
.form-control {
    width: 100%;
    background: var(--bg-main);
    border: 1px solid var(--border-color);
    padding: 12px 16px;
    border-radius: 10px;
    color: var(--text-main);
    outline: none;
}

.form-control:focus {
    border-color: var(--accent-primary);
}

/* Animations */
@keyframes fadeIn {
    from {
        opacity: 0;
        transform: translateY(10px);
    }

    to {
        opacity: 1;
        transform: translateY(0);
    }
}

/* Utilities */
.w-100 {
    width: 100%;
}

.mt-4 {
    margin-top: 16px;
}

.empty-msg {
    text-align: center;
    color: var(--text-muted);
    padding: 40px;
}

=== qdrant_data\meta.json ===
{"collections": {}, "aliases": {}}

=== qdrant_data_test\meta.json ===
{"collections": {"test": {"vectors": {"size": 768, "distance": "Cosine", "hnsw_config": null, "quantization_config": null, "on_disk": null, "datatype": null, "multivector_config": null}, "shard_number": null, "sharding_method": null, "replication_factor": null, "write_consistency_factor": null, "on_disk_payload": null, "hnsw_config": null, "wal_config": null, "optimizers_config": null, "quantization_config": null, "sparse_vectors": null, "strict_mode_config": null, "metadata": null}}, "aliases": {}}

=== telegram_bot\__init__.py ===
"""Telegram bot package initialization."""
__version__ = "1.0.0"

=== telegram_bot\bot.py ===
"""
RAGMind Telegram Bot.
Main bot application using pyTelegramBotAPI.
"""
import telebot
from telegram_bot.config import bot_settings
from telegram_bot import handlers
import logging

# Configure logging
logging.basicConfig(
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    level=logging.INFO
)
logger = logging.getLogger(__name__)

# Initialize bot
bot = telebot.TeleBot(bot_settings.telegram_bot_token)

def print_bot_link():
    """Print bot link to console."""
    try:
        bot_info = bot.get_me()
        bot_link = f"https://t.me/{bot_info.username}"
        logger.info(f"Bot is running! Share this link: {bot_link}")
    except Exception as e:
        logger.error(f"Error getting bot info: {str(e)}")

def setup_handlers():
    """Register all handlers."""
    # Pass bot instance to handlers
    handlers.set_bot(bot)
    
    # Command handlers
    bot.message_handler(commands=['start'])(handlers.start_command)
    bot.message_handler(commands=['help'])(handlers.help_command)
    
    # Text message handler (for queries)
    bot.message_handler(func=lambda message: True)(handlers.handle_message)

def main():
    """Start the bot."""
    setup_handlers()
    print_bot_link()
    logger.info("Starting RAGMind Telegram Bot (infinity_polling)...")
    bot.infinity_polling()

if __name__ == "__main__":
    main()

=== telegram_bot\config.py ===
"""
Telegram Bot Configuration.
Loads bot settings from environment.
"""
from pydantic_settings import BaseSettings, SettingsConfigDict
from pydantic import Field
from pathlib import Path

# Get project root directory
ROOT_DIR = Path(__file__).resolve().parent.parent
ENV_FILE = ROOT_DIR / ".env"

class BotSettings(BaseSettings):
    """Bot configuration settings."""
    
    telegram_bot_token: str = Field(default="", alias="TELEGRAM_BOT_TOKEN")
    telegram_admin_id: str = Field(default="", alias="TELEGRAM_ADMIN_ID")
    api_base_url: str = Field(default="http://localhost:8000", alias="API_BASE_URL")
    
    model_config = SettingsConfigDict(
        env_file=str(ENV_FILE),
        env_file_encoding="utf-8",
        case_sensitive=False,
        extra="ignore"
    )


# Global settings instance
try:
    bot_settings = BotSettings()
except Exception:
    # Fallback to defaults if .env fails
    bot_settings = BotSettings(_env_file=None)

=== telegram_bot\handlers.py ===
"""
Telegram Bot Handlers.
Command and message handlers for the bot using pyTelegramBotAPI.
"""
import httpx
from telegram_bot.config import bot_settings
import logging
import json
import os

logger = logging.getLogger(__name__)

# Bot instance (will be set from bot.py)
bot = None

CONFIG_FILE = "bot_config.json"

def set_bot(bot_instance):
    global bot
    bot = bot_instance

def get_active_project():
    """Get active project ID from config."""
    if os.path.exists(CONFIG_FILE):
        try:
            with open(CONFIG_FILE, "r") as f:
                config = json.load(f)
                return config.get("active_project_id")
        except:
            return None
    return None

def start_command(message):
    """Handle /start command."""
    bot.reply_to(
        message,
        "مرحباً بك في RAGMind Bot! 🤖\n\n"
        "أنا هنا للإجابة على أسئلتك بناءً على المشروع النشط.\n"
        "فقط أرسل سؤالك وسأجيب فوراً."
    )

def help_command(message):
    """Handle /help command."""
    bot.reply_to(
        message,
        "📚 دليل الاستخدام\n\n"
        "فقط أرسل سؤالك كتابةً وسأقوم بالبحث في مستندات المشروع النشط والإجابة عليك.\n"
        "لا توجد أوامر معقدة!"
    )

def handle_message(message):
    """Handle text messages (queries)."""
    # Ignore commands
    if message.text.startswith('/'):
        return
    
    project_id = get_active_project()
    
    if not project_id:
        bot.reply_to(
            message,
            "⚠️ عذراً، البوت غير مرتبط بمشروع حالياً.\n"
            "يرجى التواصل مع المسؤول لتحديد مشروع نشط."
        )
        return
    
    query = message.text
    
    # Send thinking message
    thinking_msg = bot.reply_to(message, "🤔 جاري البحث عن الإجابة...")
    
    try:
        # Query API
        with httpx.Client() as client:
            response = client.post(
                f"{bot_settings.api_base_url}/projects/{project_id}/query",
                json={
                    "query": query,
                    "top_k": 5,
                    "language": "ar"
                },
                timeout=60.0
            )
            response.raise_for_status()
            result = response.json()
        
        # Format answer
        answer = f"💡 الإجابة:\n\n{result['answer']}\n\n"
        
        if result.get('sources'):
            answer += "📚 المصادر:\n"
            for i, source in enumerate(result['sources'][:3], 1):
                answer += f"{i}. {source['document_name']} "
                answer += f"({source['similarity']:.1%})\n"
        
        bot.edit_message_text(
            answer,
            chat_id=message.chat.id,
            message_id=thinking_msg.message_id
        )
        
    except Exception as e:
        logger.error(f"Error querying: {str(e)}")
        bot.edit_message_text(
            f"❌ حدث خطأ في معالجة السؤال: {str(e)}",
            chat_id=message.chat.id,
            message_id=thinking_msg.message_id
        )

=== bot_config.json ===
{"active_project_id": 2}

=== check_extension.py ===
import psycopg2
from backend.config import settings

def check_extension():
    db_url = settings.database_url.replace("postgresql+asyncpg://", "")
    auth, rest = db_url.split("@")
    user, password = auth.split(":")
    host_port, db_name = rest.split("/")
    host = host_port.split(":")[0]
    port = host_port.split(":")[1] if ":" in host_port else "5432"
    
    try:
        conn = psycopg2.connect(
            dbname=db_name,
            user=user,
            password=password,
            host=host,
            port=port
        )
        cur = conn.cursor()
        cur.execute("SELECT * FROM pg_available_extensions WHERE name = 'vector'")
        extension = cur.fetchone()
        if extension:
            print(f"Extension 'vector' is available. Version: {extension[2]}")
        else:
            print("Extension 'vector' is NOT available in pg_available_extensions.")
        cur.close()
        conn.close()
    except Exception as e:
        print(f"Error: {e}")

if __name__ == "__main__":
    check_extension()

=== create_database.sql ===
-- RAGMind Database Creation Script
-- Run this in PostgreSQL before starting the application

-- Create database
CREATE DATABASE ragmind;

-- Connect to the ragmind database (in psql: \c ragmind)
\c ragmind

-- Enable pgvector extension
CREATE EXTENSION IF NOT EXISTS vector;

-- Verify extension is installed
SELECT * FROM pg_extension WHERE extname = 'vector';

=== health_check_utf8.json ===
{
    "status":  "healthy",
    "database":  "connected",
    "llm_provider":  "gemini",
    "vector_db_provider":  "pgvector"
}

=== health_check.json ===
{
    "status":  "healthy",
    "database":  "connected",
    "llm_provider":  "gemini",
    "vector_db_provider":  "pgvector"
}

=== push_to_github.bat ===
@echo off
chcp 65001 >nul
color 0B
echo ========================================
echo    RAGMind - Push to GitHub
echo    رفع المشروع على GitHub
echo ========================================
echo.

:: Repository URL - CHANGE THIS!
set REPO_URL=https://github.com/ZozElwakil/RAGMind.git

echo [!] هام: تأكد من تغيير REPO_URL في هذا الملف!
echo     Current URL: %REPO_URL%
echo.
choice /C YN /M "هل قمت بتغيير الرابط إلى repository الخاص بك؟"
if errorlevel 2 (
    echo [!] يرجى تعديل الملف وتغيير REPO_URL
    pause
    exit /b 1
)

echo.
echo ========================================
echo 1. تهيئة Git Repository
echo ========================================

:: Check if already initialized
if exist ".git\" (
    echo [✓] Git repository موجود بالفعل
) else (
    echo [INFO] جاري تهيئة Git...
    git init
    if errorlevel 1 (
        echo [ERROR] فشل تهيئة Git!
        echo تأكد من تثبيت Git: https://git-scm.com/
        pause
        exit /b 1
    )
    echo [✓] تم تهيئة Git بنجاح
)
echo.

echo ========================================
echo 2. إضافة جميع الملفات
echo ========================================
git add .
if errorlevel 1 (
    echo [ERROR] فشل إضافة الملفات!
    pause
    exit /b 1
)
echo [✓] تم إضافة جميع الملفات
echo.

echo ========================================
echo 3. عمل Commit
echo ========================================
git commit -m "Initial commit: RAGMind - Intelligent Document Q&A System"
if errorlevel 1 (
    echo [WARNING] ربما لا توجد تغييرات جديدة أو Commit موجود بالفعل
)
echo [✓] تم عمل Commit
echo.

echo ========================================
echo 4. تسمية البرانش الرئيسي
echo ========================================
git branch -M main
echo [✓] تم تسمية البرانش بـ main
echo.

echo ========================================
echo 5. ربط المشروع بـ GitHub
echo ========================================

:: Check if origin already exists
git remote | findstr /C:"origin" >nul 2>&1
if errorlevel 1 (
    echo [INFO] جاري ربط المشروع بـ %REPO_URL%...
    git remote add origin %REPO_URL%
    if errorlevel 1 (
        echo [ERROR] فشل ربط المشروع!
        pause
        exit /b 1
    )
    echo [✓] تم ربط المشروع بنجاح
) else (
    echo [!] Remote origin موجود بالفعل
    echo [INFO] تحديث الرابط...
    git remote set-url origin %REPO_URL%
    echo [✓] تم تحديث الرابط
)
echo.

echo ========================================
echo 6. رفع الملفات على GitHub
echo ========================================
echo [INFO] جاري رفع الملفات...
echo [!] سيُطلب منك إدخال:
echo     - Username: اسم المستخدم على GitHub
echo     - Password: Personal Access Token (ليس الباسورد العادي!)
echo.
echo [INFO] للحصول على Token:
echo     GitHub → Settings → Developer settings → Personal access tokens
echo.

git push -u origin main
if errorlevel 1 (
    echo.
    echo [ERROR] فشل رفع الملفات!
    echo.
    echo الأسباب المحتملة:
    echo   1. بيانات الدخول غير صحيحة (استخدم Token ليس Password)
    echo   2. الرابط غير صحيح
    echo   3. لا يوجد اتصال بالإنترنت
    echo.
    echo للمحاولة مرة أخرى، شغل الأمر:
    echo   git push -u origin main
    echo.
    pause
    exit /b 1
)

echo.
echo ========================================
echo ✅ تم رفع المشروع بنجاح!
echo ========================================
echo.
echo يمكنك الآن زيارة المشروع على:
echo %REPO_URL%
echo.
echo للتحديثات المستقبلية، استخدم: update_github.bat
echo.
pause

=== restore_env.py ===
with open('.env', 'w', encoding='utf-8') as f:
    f.write('DATABASE_URL=postgresql+asyncpg://postgres:Ezz123456@localhost:5432/ragmind\n')
    f.write('GEMINI_API_KEY=AIzaSyD2N-rsmfER9P2dZznBh4wXKAFZRajJ0eU\n')
    f.write('LLM_PROVIDER=gemini\n')
    f.write('GEMINI_MODEL=gemini-2.0-flash\n')
    f.write('VECTOR_DB_PROVIDER=pgvector\n')
    f.write('QDRANT_URL=path://./qdrant_data\n')
    f.write('UPLOAD_DIR=./uploads\n')
    f.write('MAX_FILE_SIZE_MB=50\n')
    f.write('CHUNK_SIZE=1000\n')
    f.write('CHUNK_OVERLAP=200\n')
    f.write('API_HOST=0.0.0.0\n')
    f.write('API_PORT=8000\n')
    f.write('TELEGRAM_BOT_TOKEN=8264239620:AAEjhI1736D8fRwpW5YBNqqtiUj0gL3xFcZA\n')
    f.write('TELEGRAM_ADMIN_ID=966049293\n')
    f.write('CORS_ORIGINS=["http://localhost:3000", "http://localhost:8080"]\n')
    f.write('LOG_LEVEL=INFO\n')

=== setup.bat ===
@echo off
setlocal EnableExtensions EnableDelayedExpansion

chcp 65001 >nul
color 0A
title RAGMind - Setup

:: Ensure we run from the script directory (project root)
set "ROOT=%~dp0"
pushd "%ROOT%" >nul

echo ========================================
echo    RAGMind - Setup Script
echo    تثبيت جميع متطلبات المشروع
echo ========================================
echo.
echo [INFO] Project root: "%CD%"
echo.

:: Check if Python is installed
python --version >nul 2>&1
if errorlevel 1 (
    echo [ERROR] Python غير مثبت على الجهاز!
    echo يرجى تثبيت Python 3.8 أو أحدث من: https://www.python.org/
    pause
    popd
    exit /b 1
)

echo [✓] Python مثبت:
python --version
echo.

:: Optional: Check if psql exists (non-blocking)
where psql >nul 2>&1
if errorlevel 1 (
    echo [INFO] لم يتم العثور على psql في PATH. تأكد من تثبيت PostgreSQL وتشغيله.
    echo        يمكن تحميله من: https://www.postgresql.org/download/
) else (
    echo [✓] PostgreSQL client (psql) موجود
)
echo.

:: Create virtual environment
echo ========================================
echo 1. إنشاء البيئة الافتراضية (Virtual Environment)
echo ========================================
if exist "venv\" (
    echo [!] البيئة الافتراضية موجودة بالفعل: "%CD%\venv"
    choice /C YN /M "هل تريد إعادة إنشائها؟"
    if errorlevel 2 goto skip_venv
    echo [INFO] حذف البيئة القديمة...
    rmdir /s /q "venv"
)

echo [INFO] إنشاء بيئة افتراضية جديدة...
python -m venv "venv"
if errorlevel 1 (
    echo [ERROR] فشل إنشاء البيئة الافتراضية!
    pause
    popd
    exit /b 1
)
echo [✓] تم إنشاء البيئة الافتراضية بنجاح
echo.

:skip_venv

:: Activate virtual environment
echo ========================================
echo 2. تفعيل البيئة الافتراضية
echo ========================================
if not exist "venv\Scripts\activate.bat" (
    echo [ERROR] لم يتم العثور على ملف التفعيل: venv\Scripts\activate.bat
    echo        تأكد أن إنشاء venv تم بنجاح.
    pause
    popd
    exit /b 1
)
call "venv\Scripts\activate.bat"
if errorlevel 1 (
    echo [ERROR] فشل تفعيل البيئة الافتراضية!
    pause
    popd
    exit /b 1
)
echo [✓] تم تفعيل البيئة الافتراضية
echo.

:: Upgrade pip (use python -m pip to guarantee venv pip)
echo ========================================
echo 3. تحديث pip
echo ========================================
python -m pip install --upgrade pip
if errorlevel 1 (
    echo [ERROR] فشل تحديث pip
    pause
    popd
    exit /b 1
)
echo [✓] تم تحديث pip
echo.

:: Resolve requirements file
echo ========================================
echo 4. تثبيت المكتبات المطلوبة (قد يستغرق بضع دقائق...)
echo ========================================
set "REQ_FILE="

if exist "backend\requirements.txt" set "REQ_FILE=backend\requirements.txt"
if not defined REQ_FILE if exist "requirements.txt" set "REQ_FILE=requirements.txt"

if not defined REQ_FILE (
    echo [ERROR] لم يتم العثور على ملف requirements:
    echo        - backend\requirements.txt
    echo        - requirements.txt
    echo.
    echo [INFO] محتويات المجلد الحالي:
    dir /b
    echo.
    if exist "backend\" (
        echo [INFO] محتويات مجلد backend:
        dir /b "backend"
    ) else (
        echo [WARNING] مجلد backend غير موجود
    )
    pause
    popd
    exit /b 1
)

echo [INFO] سيتم التثبيت من: "%REQ_FILE%"
python -m pip install -r "%REQ_FILE%"
if errorlevel 1 (
    echo [ERROR] فشل تثبيت المكتبات!
    echo يرجى التحقق من ملف requirements والاتصال بالإنترنت
    pause
    popd
    exit /b 1
)
echo [✓] تم تثبيت جميع المكتبات بنجاح
echo.

:: Create .env file if not exists
echo ========================================
echo 5. إنشاء ملف الإعدادات (.env)
echo ========================================
if exist ".env" (
    echo [!] ملف .env موجود بالفعل
    choice /C YN /M "هل تريد إعادة إنشائه من القالب؟"
    if errorlevel 2 goto skip_env
)

if exist ".env.example" (
    echo [INFO] نسخ الإعدادات من .env.example...
    copy /Y ".env.example" ".env" >nul
    echo [✓] تم إنشاء ملف .env
    echo [!] يرجى تعديل ملف .env وإضافة:
    echo     - DATABASE_URL
    echo     - GEMINI_API_KEY
    echo     - TELEGRAM_BOT_TOKEN (اختياري)
) else (
    echo [WARNING] ملف .env.example غير موجود
    echo يرجى إنشاء ملف .env يدوياً وإضافة الإعدادات المطلوبة
)
echo.

:skip_env

:: Create directories
echo ========================================
echo 6. إنشاء مجلدات المشروع
echo ========================================
if not exist "uploads\" mkdir "uploads"
echo [✓] تم إنشاء/التأكد من مجلد uploads
if not exist "qdrant_data\" mkdir "qdrant_data"
echo [✓] تم إنشاء/التأكد من مجلد qdrant_data
echo.

:: Database setup instructions
echo ========================================
echo 7. إعداد قاعدة البيانات
echo ========================================
echo [!] يجب إعداد PostgreSQL يدوياً:
echo.
echo     1. تشغيل PostgreSQL
echo     2. فتح pgAdmin أو psql
echo     3. تشغيل الأوامر:
echo        CREATE DATABASE ragmind;
echo        \c ragmind
echo        CREATE EXTENSION vector;
echo.
echo     4. تحديث DATABASE_URL في ملف .env
echo.
choice /C YN /M "هل قمت بإعداد قاعدة البيانات؟"
if errorlevel 2 (
    echo [!] يرجى إعداد قاعدة البيانات قبل تشغيل المشروع
) else (
    echo [✓] قاعدة البيانات جاهزة
)
echo.

:: Initialize database (FIXED choice logic)
echo ========================================
echo 8. تهيئة جداول قاعدة البيانات
echo ========================================
choice /C YN /M "هل تريد تهيئة جداول قاعدة البيانات الآن؟"
if errorlevel 2 goto skip_db_init

echo [INFO] جاري تهيئة قاعدة البيانات...
python -m backend.init_database
if errorlevel 1 (
    echo [ERROR] فشلت تهيئة قاعدة البيانات
    echo يرجى التحقق من:
    echo   - اتصال PostgreSQL
    echo   - DATABASE_URL في ملف .env
    echo   - تثبيت pgvector extension (CREATE EXTENSION vector;)
) else (
    echo [✓] تم تهيئة قاعدة البيانات بنجاح
)
goto after_db_init

:skip_db_init
echo [!] يمكنك تهيئة قاعدة البيانات لاحقاً بالأمر:
echo     python -m backend.init_database

:after_db_init
echo.

:: Summary
echo ========================================
echo ✅ اكتمل التثبيت!
echo ========================================
echo.
echo الخطوات التالية:
echo ----------------
echo 1. تعديل ملف .env وإضافة:
echo    - DATABASE_URL (مطلوب)
echo    - GEMINI_API_KEY (مطلوب)
echo    - TELEGRAM_BOT_TOKEN (اختياري)
echo.
echo 2. لتشغيل المشروع:
echo    - تشغيل Backend: start_backend.bat
echo    - تشغيل Telegram Bot: start_telegram_bot.bat (اختياري)
echo.
echo 3. فتح المتصفح على: http://localhost:8000
echo.
echo ========================================
echo 📚 للمزيد من المعلومات، راجع ملف README.md
echo ========================================
echo.

popd >nul
pause
endlocal

=== start_backend.bat ===
@echo off
REM RAGMind Backend Startup Script

echo ========================================
echo    RAGMind Backend Server
echo ========================================
echo.

REM Check if virtual environment exists
if not exist "venv" (
    echo Creating virtual environment...
    python -m venv venv
    echo.
)

REM Activate virtual environment
echo Activating virtual environment...
call venv\Scripts\activate.bat
echo.

REM Install dependencies
echo Installing/Updating dependencies...
pip install -r backend\requirements.txt
echo.

REM Initialize database
echo Initializing database...
python backend\init_database.py
echo.

REM Start server
echo Starting FastAPI server...
echo Server will be available at: http://localhost:8000
echo API docs at: http://localhost:8000/docs
echo.
python -m uvicorn backend.main:app --reload --host 0.0.0.0 --port 8000

=== start_telegram_bot.bat ===
@echo off
REM RAGMind Telegram Bot Startup Script

echo ========================================
echo    RAGMind Telegram Bot
echo ========================================
echo.

REM Activate virtual environment
if not exist "venv" (
    echo ERROR: Virtual environment not found!
    echo Please run start_backend.bat first to create it.
    pause
    exit /b 1
)

echo Activating virtual environment...
call venv\Scripts\activate.bat
echo.

REM Check if bot token is configured
echo Checking configuration...
python -c "from telegram_bot.config import bot_settings; assert bot_settings.telegram_bot_token != 'your_telegram_bot_token_here', 'Please configure TELEGRAM_BOT_TOKEN in .env file'" 2>nul
if errorlevel 1 (
    echo.
    echo ERROR: Telegram bot token not configured!
    echo Please set TELEGRAM_BOT_TOKEN in the .env file
    echo.
    pause
    exit /b 1
)

REM Start bot
echo Starting Telegram bot...
echo.
python -m telegram_bot.bot

=== test_qdrant.py ===
from qdrant_client import QdrantClient
import os

try:
    path = "./qdrant_data_test"
    if not os.path.exists(path):
        os.makedirs(path)
    
    print(f"Initializing Qdrant at {path}...")
    client = QdrantClient(path=path)
    print("Success!")
    
    # Try to create a collection
    from qdrant_client.models import Distance, VectorParams
    client.create_collection(
        collection_name="test",
        vectors_config=VectorParams(size=768, distance=Distance.COSINE)
    )
    print("Collection created!")
    
except Exception as e:
    print(f"Error: {str(e)}")
    import traceback
    traceback.print_exc()

=== update_github.bat ===
@echo off
chcp 65001 >nul
color 0E
echo ========================================
echo    RAGMind - Update GitHub
echo    تحديث المشروع على GitHub
echo ========================================
echo.

:: Check if Git is initialized
if not exist ".git\" (
    echo [ERROR] المشروع غير مربوط بـ Git!
    echo يرجى تشغيل push_to_github.bat أولاً
    pause
    exit /b 1
)

echo ========================================
echo 1. إضافة التعديلات الجديدة
echo ========================================
git add .
echo [✓] تم إضافة التعديلات
echo.

echo ========================================
echo 2. عرض الملفات المتغيرة
echo ========================================
git status --short
echo.

echo ========================================
echo 3. عمل Commit
echo ========================================
set /p COMMIT_MSG="اكتب وصف التعديلات: "
if "%COMMIT_MSG%"=="" set COMMIT_MSG=Update project files

git commit -m "%COMMIT_MSG%"
if errorlevel 1 (
    echo [WARNING] لا توجد تغييرات جديدة للـ commit
    echo.
    choice /C YN /M "هل تريد المتابعة على أي حال؟"
    if errorlevel 2 (
        echo [INFO] تم الإلغاء
        pause
        exit /b 0
    )
)
echo [✓] تم عمل Commit
echo.

echo ========================================
echo 4. رفع التحديثات على GitHub
echo ========================================
echo [INFO] جاري رفع التحديثات...
git push
if errorlevel 1 (
    echo.
    echo [ERROR] فشل رفع التحديثات!
    echo.
    echo جرب الأمر التالي:
    echo   git pull origin main --rebase
    echo   git push
    echo.
    pause
    exit /b 1
)

echo.
echo ========================================
echo ✅ تم تحديث المشروع بنجاح!
echo ========================================
echo.
pause

=== update_token.py ===
import os
from pathlib import Path

# Path to .env file
env_file = Path("c:/Users/abdul/Documents/EELU/RAGMind/.env")

# Read current content
if env_file.exists():
    with open(env_file, 'r', encoding='utf-8') as f:
        lines = f.readlines()
    
    # Update or add TELEGRAM_BOT_TOKEN
    token_found = False
    for i, line in enumerate(lines):
        if line.startswith('TELEGRAM_BOT_TOKEN='):
            lines[i] = 'TELEGRAM_BOT_TOKEN=8264239620:AAEjhI1736D8fRwpW5YBNqtiUj0gL3xFcZA\n'
            token_found = True
            break
    
    if not token_found:
        lines.append('TELEGRAM_BOT_TOKEN=8264239620:AAEjhI1736D8fRwpW5YBNqtiUj0gL3xFcZA\n')
    
    # Write back
    with open(env_file, 'w', encoding='utf-8') as f:
        f.writelines(lines)
    
    print("✓ Token updated successfully!")
else:
    print("✗ .env file not found!")


----- END FILE -----

----- FILE: backend\__init__.py -----
size: 62 bytes | mtime: 2025-12-28T12:51:36.566126

"""Backend package initialization."""
__version__ = "1.0.0"

----- END FILE -----

----- FILE: backend\config.py -----
size: 3034 bytes | mtime: 2025-12-29T08:50:18.952729

"""
Configuration management using Pydantic Settings.
Loads environment variables from .env file.
"""
from pydantic_settings import BaseSettings, SettingsConfigDict
from pydantic import Field
from typing import List
import json


class Settings(BaseSettings):
    """Application settings loaded from environment variables."""
    
    # Database Configuration
    database_url: str = Field(
        default="postgresql+asyncpg://postgres:postgres@localhost:5432/ragmind",
        alias="DATABASE_URL"
    )
    
    # LLM Provider Configuration
    gemini_api_key: str = Field(
        default="",
        alias="GEMINI_API_KEY"
    )
    llm_provider: str = Field(default="gemini", alias="LLM_PROVIDER")
    gemini_model: str = Field(default="gemini-2.5-flash", alias="GEMINI_MODEL")
    
    # Vector DB Configuration
    vector_db_provider: str = Field(default="pgvector", alias="VECTOR_DB_PROVIDER")
    qdrant_url: str = Field(default="http://localhost:6333", alias="QDRANT_URL")
    qdrant_api_key: str = Field(default="", alias="QDRANT_API_KEY")
    
    # Storage Configuration
    upload_dir: str = Field(default="./uploads", alias="UPLOAD_DIR")
    max_file_size_mb: int = Field(default=50, alias="MAX_FILE_SIZE_MB")
    
    # Chunking Configuration
    chunk_size: int = Field(default=1000, alias="CHUNK_SIZE")
    chunk_overlap: int = Field(default=200, alias="CHUNK_OVERLAP")
    
    # API Configuration
    api_host: str = Field(default="0.0.0.0", alias="API_HOST")
    api_port: int = Field(default=8000, alias="API_PORT")
    api_title: str = Field(default="RAGMind API", alias="API_TITLE")
    api_version: str = Field(default="1.0.0", alias="API_VERSION")
    
    # Telegram Bot Configuration
    telegram_bot_token: str = Field(default="", alias="TELEGRAM_BOT_TOKEN")
    telegram_admin_id: str = Field(default="", alias="TELEGRAM_ADMIN_ID")
    
    # CORS Configuration
    cors_origins: List[str] = Field(
        default=["http://localhost:3000", "http://localhost:8080"],
        alias="CORS_ORIGINS"
    )
    
    # Logging
    log_level: str = Field(default="INFO", alias="LOG_LEVEL")
    
    environment: str = Field(default="development", validation_alias="ENVIRONMENT")
    model_config = SettingsConfigDict(
        env_file=".env",
        env_file_encoding="utf-8",
        case_sensitive=False,
        extra="ignore"
    )


# Global settings instance - use default values if .env not found
try:
    settings = Settings()
except Exception as e:
    # If .env is missing, use defaults
    import warnings
    warnings.warn(f".env file not found or invalid, using default settings: {str(e)}")
    # In Pydantic v2, we can't just pass _env_file=None to the constructor easily if it fails
    # We'll try to create a default instance without loading from env
    try:
        settings = Settings(_env_file=None)
    except:
        # Fallback to a very basic settings if even that fails
        settings = Settings()

----- END FILE -----

----- FILE: backend\controllers\__init__.py -----
size: 327 bytes | mtime: 2025-12-28T12:51:36.570147

"""Controllers package initialization."""
from backend.controllers.project_controller import ProjectController
from backend.controllers.document_controller import DocumentController
from backend.controllers.query_controller import QueryController

__all__ = ["ProjectController", "DocumentController", "QueryController"]

----- END FILE -----

----- FILE: backend\controllers\document_controller.py -----
size: 11422 bytes | mtime: 2025-12-28T18:16:01.982472

"""
Document Controller.
Business logic for document upload and processing.
"""
from typing import Optional, List
from sqlalchemy import select
from sqlalchemy.ext.asyncio import AsyncSession
from backend.database.models import Asset, Chunk, Project
from backend.database.connection import async_session_maker
from backend.services.file_service import FileService
from backend.services.document_loader import DocumentLoaderService
from backend.services.chunking_service import ChunkingService
from backend.services.embedding_service import EmbeddingService
from backend.providers.vectordb.factory import VectorDBProviderFactory
from datetime import datetime
import logging

logger = logging.getLogger(__name__)


class DocumentController:
    """Controller for document operations."""
    
    def __init__(self):
        """Initialize document controller."""
        logger.info("Initializing DocumentController...")
        self.file_service = FileService()
        self.document_loader = DocumentLoaderService()
        self.chunking_service = ChunkingService()
        self.embedding_service = EmbeddingService()
        self.vector_db = VectorDBProviderFactory.create_provider()
        logger.info("✅ DocumentController initialized")
    
    async def upload_document(
        self,
        db: AsyncSession,
        project_id: int,
        file_content: bytes,
        filename: str,
        file_size: int
    ) -> Asset:
        """
        Upload document and save metadata.
        
        Args:
            db: Database session
            project_id: Project ID
            file_content: File content bytes
            filename: Original filename
            file_size: File size in bytes
            
        Returns:
            Created asset
            
        Raises:
            ValueError: If validation fails
        """
        try:
            logger.debug(f"Uploading document: {filename} ({file_size} bytes) to project {project_id}")
            
            # Validate file
            is_valid, error_msg = self.file_service.validate_file(filename, file_size)
            if not is_valid:
                logger.warning(f"File validation failed: {error_msg}")
                raise ValueError(error_msg)
            
            # Check project exists
            project_stmt = select(Project).where(Project.id == project_id)
            project_result = await db.execute(project_stmt)
            project = project_result.scalar_one_or_none()
            if not project:
                raise ValueError(f"Project not found: {project_id}")
            
            # Save file
            unique_filename, file_path = await self.file_service.save_upload_file(
                file_content=file_content,
                filename=filename,
                project_id=project_id
            )
            
            # Get file type
            from pathlib import Path
            file_type = Path(filename).suffix.lstrip('.')
            
            # Create asset record
            asset = Asset(
                project_id=project_id,
                filename=unique_filename,
                original_filename=filename,
                file_path=file_path,
                file_size=file_size,
                file_type=file_type,
                status="uploaded"
            )
            
            db.add(asset)
            await db.commit()
            await db.refresh(asset)
            
            logger.info(f"Uploaded document: {asset.id} - {filename}")
            return asset
            
        except Exception as e:
            await db.rollback()
            logger.error(f"Error uploading document: {str(e)}")
            raise
    
    async def process_document(self, asset_id: int) -> bool:
        """
        Process document: extract, chunk, embed, and store.

        Returns:
            True if successful
        """
        logger.info(f"🔄 Starting document processing for asset {asset_id}")
        
        async with async_session_maker() as db:
            # Get asset
            asset_stmt = select(Asset).where(Asset.id == asset_id)
            asset_result = await db.execute(asset_stmt)
            asset = asset_result.scalar_one_or_none()
            
            if not asset:
                raise ValueError(f"Asset not found: {asset_id}")
            
            logger.debug(f"Processing document: {asset.original_filename} ({asset.file_size} bytes)")
            
            # Update status to processing
            asset.status = "processing"
            await db.commit()
            
            try:
                # Extract text
                logger.info(f"📖 Extracting text from {asset.original_filename}")
                text = await self.document_loader.load_document(asset.file_path)
                if not text or not text.strip():
                    raise ValueError("No text extracted from document (empty content).")
                
                logger.debug(f"Extracted {len(text)} characters of text")
                
                # Chunk text
                logger.info(f"✂️ Chunking text ({len(text)} characters)")
                chunks_data = await self.chunking_service.chunk_document(
                    text=text,
                    document_name=asset.original_filename,
                    additional_metadata={
                        'file_type': asset.file_type,
                        'asset_id': asset.id
                    }
                )
                
                logger.debug(f"Created {len(chunks_data)} chunks")
                
                # Create chunk records
                chunk_records = []
                for i, chunk_data in enumerate(chunks_data):
                    chunk = Chunk(
                        project_id=asset.project_id,
                        asset_id=asset.id,
                        content=chunk_data['content'],
                        chunk_index=i,
                        extra_metadata=chunk_data['metadata']
                    )
                    db.add(chunk)
                    chunk_records.append(chunk)
                
                await db.commit()
                
                # Refresh to get IDs
                for chunk in chunk_records:
                    await db.refresh(chunk)
                
                logger.debug(f"Saved {len(chunk_records)} chunks to database")
                
                # Generate embeddings
                logger.info(f"🧠 Generating embeddings for {len(chunk_records)} chunks")
                texts = [chunk.content for chunk in chunk_records]
                embeddings = await self.embedding_service.generate_embeddings(texts)
                
                logger.debug(f"Generated {len(embeddings)} embeddings")

                # Ensure collection exists (needed for Qdrant)
                collection_name = f"project_{asset.project_id}"
                dim = self.embedding_service.get_embedding_dimension()
                exists = await self.vector_db.collection_exists(collection_name, project_id=asset.project_id)
                if not exists:
                    logger.info(f"Creating vector collection: {collection_name}")
                    await self.vector_db.create_collection(collection_name, dimension=dim)
                else:
                    logger.debug(f"Vector collection {collection_name} already exists")

                # Store embeddings in chunks and vector DB
                chunk_ids = [chunk.id for chunk in chunk_records]
                payloads = [
                    {
                        "content": c.content,
                        "metadata": c.extra_metadata,
                        "asset_id": c.asset_id,
                        "project_id": c.project_id,
                    }
                    for c in chunk_records
                ]
                logger.info(f"💾 Storing {len(embeddings)} vectors in database")
                await self.vector_db.add_vectors(
                    collection_name=collection_name,
                    vectors=embeddings,
                    ids=chunk_ids,
                    metadata=payloads
                )
                
                # Update asset status
                asset.status = "completed"
                asset.processed_at = datetime.utcnow()
                await db.commit()
                
                logger.info(f"✅ Completed processing document: {asset.id} - {asset.original_filename}")
                return True
                
            except Exception as e:
                # Mark as failed
                asset.status = "failed"
                asset.error_message = str(e)
                await db.commit()
                logger.error(f"❌ Document processing failed for asset {asset_id}: {str(e)}")
                raise
    
    async def get_document(
        self,
        db: AsyncSession,
        asset_id: int
    ) -> Optional[Asset]:
        """
        Get document by ID.
        
        Args:
            db: Database session
            asset_id: Asset ID
            
        Returns:
            Asset or None
        """
        try:
            stmt = select(Asset).where(Asset.id == asset_id)
            result = await db.execute(stmt)
            return result.scalar_one_or_none()
            
        except Exception as e:
            logger.error(f"Error getting document: {str(e)}")
            raise
    
    async def list_project_documents(
        self,
        db: AsyncSession,
        project_id: int
    ) -> List[Asset]:
        """
        List all documents in project.
        
        Args:
            db: Database session
            project_id: Project ID
            
        Returns:
            List of assets
        """
        try:
            stmt = select(Asset).where(Asset.project_id == project_id).order_by(Asset.created_at.desc())
            result = await db.execute(stmt)
            return list(result.scalars().all())
            
        except Exception as e:
            logger.error(f"Error listing documents: {str(e)}")
            raise
    
    async def delete_document(
        self,
        db: AsyncSession,
        asset_id: int
    ) -> bool:
        """
        Delete document and associated chunks.
        
        Args:
            db: Database session
            asset_id: Asset ID
            
        Returns:
            True if deleted
        """
        try:
            # Get asset
            asset = await self.get_document(db, asset_id)
            if not asset:
                return False
            
            # Delete file
            await self.file_service.delete_file(asset.file_path)
            
            # Delete from database (cascade will delete chunks)
            await db.delete(asset)
            await db.commit()
            
            logger.info(f"Deleted document: {asset_id}")
            return True
            
        except Exception as e:
            await db.rollback()
            logger.error(f"Error deleting document: {str(e)}")
            raise

----- END FILE -----

----- FILE: backend\controllers\project_controller.py -----
size: 7092 bytes | mtime: 2025-12-28T12:51:36.576158

"""
Project Controller.
Business logic for project management.
"""
from typing import List, Optional, Dict, Any
from sqlalchemy import select, delete
from sqlalchemy.ext.asyncio import AsyncSession
from backend.database.models import Project, Asset, Chunk
from backend.services.file_service import FileService
from datetime import datetime
import logging

logger = logging.getLogger(__name__)


class ProjectController:
    """Controller for project operations."""
    
    def __init__(self):
        """Initialize project controller."""
        self.file_service = FileService()
    
    async def create_project(
        self,
        db: AsyncSession,
        name: str,
        description: Optional[str] = None,
        metadata: Optional[Dict[str, Any]] = None
    ) -> Project:
        """
        Create a new project.
        
        Args:
            db: Database session
            name: Project name
            description: Optional description
            metadata: Optional metadata
            
        Returns:
            Created project
        """
        try:
            project = Project(
                name=name,
                description=description,
                extra_metadata=metadata or {}
            )
            
            db.add(project)
            await db.commit()
            await db.refresh(project)
            
            logger.info(f"Created project: {project.id} - {project.name}")
            return project
            
        except Exception as e:
            await db.rollback()
            logger.error(f"Error creating project: {str(e)}")
            raise
    
    async def get_project(
        self,
        db: AsyncSession,
        project_id: int
    ) -> Optional[Project]:
        """
        Get project by ID.
        
        Args:
            db: Database session
            project_id: Project ID
            
        Returns:
            Project or None
        """
        try:
            stmt = select(Project).where(Project.id == project_id)
            result = await db.execute(stmt)
            project = result.scalar_one_or_none()
            
            return project
            
        except Exception as e:
            logger.error(f"Error getting project: {str(e)}")
            raise
    
    async def list_projects(
        self,
        db: AsyncSession,
        skip: int = 0,
        limit: int = 100
    ) -> List[Project]:
        """
        List all projects.
        
        Args:
            db: Database session
            skip: Number of projects to skip
            limit: Maximum number of projects to return
            
        Returns:
            List of projects
        """
        try:
            stmt = select(Project).offset(skip).limit(limit).order_by(Project.created_at.desc())
            result = await db.execute(stmt)
            projects = result.scalars().all()
            
            return list(projects)
            
        except Exception as e:
            logger.error(f"Error listing projects: {str(e)}")
            raise
    
    async def update_project(
        self,
        db: AsyncSession,
        project_id: int,
        name: Optional[str] = None,
        description: Optional[str] = None,
        metadata: Optional[Dict[str, Any]] = None
    ) -> Optional[Project]:
        """
        Update project.
        
        Args:
            db: Database session
            project_id: Project ID
            name: Optional new name
            description: Optional new description
            metadata: Optional new metadata
            
        Returns:
            Updated project or None
        """
        try:
            project = await self.get_project(db, project_id)
            if not project:
                return None
            
            if name is not None:
                project.name = name
            if description is not None:
                project.description = description
            if metadata is not None:
                project.extra_metadata = metadata
            
            project.updated_at = datetime.utcnow()
            
            await db.commit()
            await db.refresh(project)
            
            logger.info(f"Updated project: {project_id}")
            return project
            
        except Exception as e:
            await db.rollback()
            logger.error(f"Error updating project: {str(e)}")
            raise
    
    async def delete_project(
        self,
        db: AsyncSession,
        project_id: int
    ) -> bool:
        """
        Delete project and all associated data.
        
        Args:
            db: Database session
            project_id: Project ID
            
        Returns:
            True if deleted successfully
        """
        try:
            # Delete files from storage
            await self.file_service.delete_project_files(project_id)
            
            # Delete from database (cascade will handle assets and chunks)
            stmt = delete(Project).where(Project.id == project_id)
            result = await db.execute(stmt)
            await db.commit()
            
            deleted = result.rowcount > 0
            if deleted:
                logger.info(f"Deleted project: {project_id}")
            
            return deleted
            
        except Exception as e:
            await db.rollback()
            logger.error(f"Error deleting project: {str(e)}")
            raise
    
    async def get_project_stats(
        self,
        db: AsyncSession,
        project_id: int
    ) -> Dict[str, Any]:
        """
        Get project statistics.
        
        Args:
            db: Database session
            project_id: Project ID
            
        Returns:
            Statistics dictionary
        """
        try:
            # Get asset count
            asset_stmt = select(Asset).where(Asset.project_id == project_id)
            asset_result = await db.execute(asset_stmt)
            assets = asset_result.scalars().all()
            
            # Get chunk count
            chunk_stmt = select(Chunk).where(Chunk.project_id == project_id)
            chunk_result = await db.execute(chunk_stmt)
            chunks = chunk_result.scalars().all()
            
            return {
                'asset_count': len(assets),
                'chunk_count': len(chunks),
                'total_size': sum(a.file_size for a in assets),
                'completed_assets': sum(1 for a in assets if a.status == 'completed'),
                'processing_assets': sum(1 for a in assets if a.status == 'processing'),
                'failed_assets': sum(1 for a in assets if a.status == 'failed')
            }
            
        except Exception as e:
            logger.error(f"Error getting project stats: {str(e)}")
            raise

----- END FILE -----

----- FILE: backend\controllers\query_controller.py -----
size: 2631 bytes | mtime: 2025-12-28T12:51:36.576158

"""
Query Controller.
Business logic for query processing and answer generation.
"""
from typing import Dict, Any, Optional
from sqlalchemy.ext.asyncio import AsyncSession
from backend.services.query_service import QueryService
from backend.services.answer_service import AnswerService
import logging

logger = logging.getLogger(__name__)


class QueryController:
    """Controller for query operations."""
    
    def __init__(self):
        """Initialize query controller."""
        self.query_service = QueryService()
        self.answer_service = AnswerService()
    
    async def answer_query(
        self,
        db: AsyncSession,
        project_id: int,
        query: str,
        top_k: int = 5,
        language: str = "ar",
        asset_id: Optional[int] = None
    ) -> Dict[str, Any]:
        """
        Process query and generate answer.
        
        Args:
            db: Database session
            project_id: Project ID to search in
            query: User question
            top_k: Number of chunks to retrieve
            language: Response language ('ar' or 'en')
            asset_id: Optional specific document to search
            
        Returns:
            Dictionary with answer and metadata
        """
        try:
            # Search for relevant chunks
            logger.info(f"Processing query for project {project_id}: {query[:50]}...")
            
            similar_chunks = await self.query_service.search_similar_chunks(
                query=query,
                project_id=project_id,
                top_k=top_k,
                asset_id=asset_id
            )
            
            if not similar_chunks:
                return {
                    'answer': 'لم أتمكن من العثور على معلومات ذات صلة في المستندات.' if language == 'ar' 
                             else 'Could not find relevant information in the documents.',
                    'sources': [],
                    'context_used': 0
                }
            
            # Generate answer
            result = await self.answer_service.generate_answer(
                query=query,
                context_chunks=similar_chunks,
                language=language,
                include_sources=True
            )
            
            logger.info(f"Generated answer for query (used {result['context_used']} chunks)")
            return result
            
        except Exception as e:
            logger.error(f"Error processing query: {str(e)}")
            raise

----- END FILE -----

----- FILE: backend\database\__init__.py -----
size: 366 bytes | mtime: 2025-12-28T12:51:36.578286

"""Database package initialization."""
from backend.database.models import Base, Project, Asset, Chunk
from backend.database.connection import engine, async_session_maker, get_db, init_db, close_db

__all__ = [
    "Base",
    "Project",
    "Asset",
    "Chunk",
    "engine",
    "async_session_maker",
    "get_db",
    "init_db",
    "close_db"
]

----- END FILE -----

----- FILE: backend\database\connection.py -----
size: 2387 bytes | mtime: 2025-12-28T13:32:10.570998

"""
Database connection management with async SQLAlchemy.
Provides engine and session factory.
"""
from sqlalchemy.ext.asyncio import create_async_engine, AsyncSession, async_sessionmaker
from sqlalchemy.pool import NullPool
from backend.config import settings
import logging

logger = logging.getLogger(__name__)

# Create async engine
engine = create_async_engine(
    settings.database_url,
    echo=False,  # Set to True for SQL query logging
    poolclass=NullPool,  # Use NullPool for async or configure pool
    future=True
)

# Create async session factory
async_session_maker = async_sessionmaker(
    engine,
    class_=AsyncSession,
    expire_on_commit=False,
    autocommit=False,
    autoflush=False
)


async def get_db() -> AsyncSession:
    """
    Dependency function to get database session.
    Use with FastAPI Depends().
    """
    async with async_session_maker() as session:
        try:
            yield session
            await session.commit()
        except Exception:
            await session.rollback()
            raise
        finally:
            await session.close()


async def init_db():
    """Initialize database - create tables if they don't exist."""
    from backend.database.models import Base
    from sqlalchemy import text
    try:
        async with engine.begin() as conn:
            # Enable pgvector extension
            await conn.execute(text("CREATE EXTENSION IF NOT EXISTS vector"))
            
            # Create all tables
            await conn.run_sync(Base.metadata.create_all)
            logger.info("Database initialized successfully with pgvector")
    except Exception as e:
        logger.warning(f"Could not initialize pgvector extension: {str(e)}")
        logger.info("Attempting to initialize other tables...")
        try:
            async with engine.begin() as conn:
                # Try to create tables one by one or skip those that fail
                await conn.run_sync(Base.metadata.create_all)
                logger.info("Database tables initialized (some might have failed)")
        except Exception as e2:
            logger.error(f"Failed to initialize database tables: {str(e2)}")


async def close_db():
    """Close database connections."""
    await engine.dispose()
    logger.info("Database connections closed")

----- END FILE -----

----- FILE: backend\database\models.py -----
size: 3866 bytes | mtime: 2025-12-28T18:02:52.656420

"""
Database models using SQLAlchemy async ORM.
Defines tables for projects, assets, and chunks with vector embeddings.
"""
from sqlalchemy import Column, Integer, String, Text, DateTime, ForeignKey, Float, JSON, LargeBinary
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.orm import relationship
from sqlalchemy.sql import func
from datetime import datetime

Base = declarative_base()


class Project(Base):
    """Project model for organizing documents."""
    __tablename__ = "projects"
    
    id = Column(Integer, primary_key=True, index=True)
    name = Column(String(255), nullable=False, index=True)
    description = Column(Text, nullable=True)
    created_at = Column(DateTime(timezone=True), server_default=func.now())
    updated_at = Column(DateTime(timezone=True), onupdate=func.now())
    
    # Metadata (renamed to avoid conflict with SQLAlchemy metadata)
    extra_metadata = Column("metadata", JSON, default=dict)
    
    # Relationships
    assets = relationship("Asset", back_populates="project", cascade="all, delete-orphan")
    chunks = relationship("Chunk", back_populates="project", cascade="all, delete-orphan")
    
    def __repr__(self):
        return f"<Project(id={self.id}, name='{self.name}')>"


class Asset(Base):
    """Asset model for uploaded documents."""
    __tablename__ = "assets"
    
    id = Column(Integer, primary_key=True, index=True)
    project_id = Column(Integer, ForeignKey("projects.id", ondelete="CASCADE"), nullable=False)
    
    # File information
    filename = Column(String(500), nullable=False)
    original_filename = Column(String(500), nullable=False)
    file_path = Column(String(1000), nullable=False)
    file_size = Column(Integer, nullable=False)  # in bytes
    file_type = Column(String(50), nullable=False)  # pdf, txt, docx
    
    # Status
    status = Column(String(50), default="uploaded")  # uploaded, processing, completed, failed
    error_message = Column(Text, nullable=True)
    
    # Timestamps
    created_at = Column(DateTime(timezone=True), server_default=func.now())
    processed_at = Column(DateTime(timezone=True), nullable=True)
    
    # Metadata (renamed to avoid conflict)
    extra_metadata = Column("metadata", JSON, default=dict)
    
    # Relationships
    project = relationship("Project", back_populates="assets")
    chunks = relationship("Chunk", back_populates="asset", cascade="all, delete-orphan")
    
    def __repr__(self):
        return f"<Asset(id={self.id}, filename='{self.filename}', status='{self.status}')>"


class Chunk(Base):
    """Chunk model for text chunks with vector embeddings."""
    __tablename__ = "chunks"
    
    id = Column(Integer, primary_key=True, index=True)
    project_id = Column(Integer, ForeignKey("projects.id", ondelete="CASCADE"), nullable=False)
    asset_id = Column(Integer, ForeignKey("assets.id", ondelete="CASCADE"), nullable=False)
    
    # Content
    content = Column(Text, nullable=False)
    chunk_index = Column(Integer, nullable=False)  # Position in document
    
    # Vector embedding (stored as JSON/List for compatibility if pgvector is missing)
    # Vector search is handled by Qdrant if pgvector is not available
    embedding = Column(JSON, nullable=True)
    
    # Metadata (renamed to avoid conflict)
    extra_metadata = Column("metadata", JSON, default=dict)  # page_number, section, etc.
    
    # Timestamps
    created_at = Column(DateTime(timezone=True), server_default=func.now())
    
    # Relationships
    project = relationship("Project", back_populates="chunks")
    asset = relationship("Asset", back_populates="chunks")
    
    def __repr__(self):
        return f"<Chunk(id={self.id}, asset_id={self.asset_id}, chunk_index={self.chunk_index})>"

----- END FILE -----

----- FILE: backend\init_database.py -----
size: 3088 bytes | mtime: 2025-12-28T13:32:10.570998

"""
Database initialization script.
Creates database and tables with pgvector extension.
"""
import asyncio
import sys
import os
from pathlib import Path

# Add parent directory to path
sys.path.insert(0, str(Path(__file__).parent.parent))

from backend.database import init_db
from backend.config import settings
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


async def create_database_if_not_exists():
    """Create the database if it doesn't exist."""
    import psycopg2
    from psycopg2.extensions import ISOLATION_LEVEL_AUTOCOMMIT
    
    # Parse connection string to get credentials for default 'postgres' db
    # Example: postgresql+asyncpg://postgres:Ezz123456@localhost:5432/ragmind
    db_url = settings.database_url.replace("postgresql+asyncpg://", "")
    auth, rest = db_url.split("@")
    user, password = auth.split(":")
    host_port, db_name = rest.split("/")
    host = host_port.split(":")[0]
    port = host_port.split(":")[1] if ":" in host_port else "5432"
    
    try:
        # Connect to default 'postgres' database
        conn = psycopg2.connect(
            dbname='postgres',
            user=user,
            password=password,
            host=host,
            port=port
        )
        conn.set_isolation_level(ISOLATION_LEVEL_AUTOCOMMIT)
        cur = conn.cursor()
        
        # Check if database exists
        cur.execute(f"SELECT 1 FROM pg_catalog.pg_database WHERE datname = '{db_name}'")
        exists = cur.fetchone()
        
        if not exists:
            logger.info(f"Creating database {db_name}...")
            cur.execute(f"CREATE DATABASE {db_name}")
            logger.info(f"Database {db_name} created successfully")
        else:
            logger.info(f"Database {db_name} already exists")
            
        cur.close()
        conn.close()
    except Exception as e:
        logger.error(f"Error creating database: {str(e)}")
        # We continue anyway, maybe it exists but we couldn't check


async def main():
    """Initialize database."""
    try:
        # Step 1: Create database if needed
        await create_database_if_not_exists()
        
        logger.info(f"Connecting to database: {settings.database_url.split('@')[1]}")
        
        # Step 2: Initialize tables and extensions
        await init_db()
        
        logger.info("✅ Database initialized successfully!")
        logger.info("Tables created:")
        logger.info("  - projects")
        logger.info("  - assets")
        logger.info("  - chunks (with vector embeddings)")
        logger.info("Extensions enabled:")
        logger.info("  - pgvector")
        
        return 0
        
    except Exception as e:
        logger.error(f"❌ Failed to initialize database: {str(e)}")
        return 1
    
    finally:
        from backend.database import close_db
        await close_db()


if __name__ == "__main__":
    exit_code = asyncio.run(main())
    sys.exit(exit_code)

----- END FILE -----

----- FILE: backend\main.py -----
size: 3176 bytes | mtime: 2025-12-28T18:16:01.984524

"""
Main FastAPI Application.
Entry point for the RAGMind backend API.
"""
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from contextlib import asynccontextmanager
# Configure logging
from backend.config import settings
import logging

logging.basicConfig(
    level=getattr(logging, settings.log_level),
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

from backend.database import init_db, close_db
from backend.routes import projects, documents, query, health, stats, bot_config


@asynccontextmanager
async def lifespan(app: FastAPI):
    """Application lifespan handler."""
    # Startup
    logger.info("🚀 Starting RAGMind API...")
    logger.debug(f"Environment: {settings.environment}")
    logger.debug(f"Database URL: {settings.database_url.replace(settings.database_url.split('@')[0].split(':')[1], '***') if '@' in settings.database_url else 'configured'}")
    logger.debug(f"Vector DB Provider: {settings.vector_db_provider}")
    logger.debug(f"LLM Provider: {settings.llm_provider}")
    try:
        logger.info("Initializing database...")
        await init_db()
        logger.info("✅ Database initialized successfully")
    except Exception as e:
        logger.error(f"Failed to initialize database: {str(e)}")
        raise
    
    yield
    
    # Shutdown
    logger.info("Shutting down RAGMind API...")
    await close_db()
    logger.info("Database connections closed")


# Create FastAPI app
app = FastAPI(
    title=settings.api_title,
    version=settings.api_version,
    description="""
    RAGMind - Retrieval Augmented Generation System
    
    A powerful document processing and question-answering API using:
    - Google Gemini 2.5 Flash for LLM capabilities
    - PostgreSQL with pgvector for vector storage
    - LangChain for document processing
    
    ## Features
    - Project-based document organization
    - Multi-format document support (PDF, TXT, DOCX)
    - Automatic text chunking and embedding
    - Vector similarity search
    - AI-powered question answering
    - Multi-language support (Arabic/English)
    """,
    lifespan=lifespan
)

# Configure CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # Allow all origins for development
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Include routers
app.include_router(health.router)
app.include_router(projects.router)
app.include_router(documents.router)
app.include_router(query.router)
app.include_router(stats.router)
app.include_router(bot_config.router)

logger.info("✅ All routers registered")
logger.info(f"🚀 RAGMind API ready at http://{settings.api_host}:{settings.api_port}")
logger.info(f"📚 API documentation at http://{settings.api_host}:{settings.api_port}/docs")


if __name__ == "__main__":
    import uvicorn
    logger.info("Starting development server...")
    uvicorn.run(
        "backend.main:app",
        host=settings.api_host,
        port=settings.api_port,
        reload=True
    )

----- END FILE -----

----- FILE: backend\providers\__init__.py -----
size: 41 bytes | mtime: 2025-12-28T12:51:36.584305

"""Providers package initialization."""

----- END FILE -----

----- FILE: backend\providers\llm\__init__.py -----
size: 286 bytes | mtime: 2025-12-28T12:51:36.585304

"""LLM providers package."""
from backend.providers.llm.interface import LLMInterface
from backend.providers.llm.gemini_provider import GeminiProvider
from backend.providers.llm.factory import LLMProviderFactory

__all__ = ["LLMInterface", "GeminiProvider", "LLMProviderFactory"]

----- END FILE -----

----- FILE: backend\providers\llm\factory.py -----
size: 1613 bytes | mtime: 2025-12-28T12:51:36.590835

"""
LLM Provider Factory.
Creates LLM provider instances based on configuration.
"""
from backend.providers.llm.interface import LLMInterface
from backend.providers.llm.gemini_provider import GeminiProvider
from backend.config import settings
import logging

logger = logging.getLogger(__name__)


class LLMProviderFactory:
    """Factory for creating LLM provider instances."""
    
    @staticmethod
    def create_provider(provider_name: str = None) -> LLMInterface:
        """
        Create LLM provider instance.
        
        Args:
            provider_name: Name of provider ('gemini', 'openai', etc.)
                          Defaults to settings.llm_provider
        
        Returns:
            LLM provider instance
            
        Raises:
            ValueError: If provider name is not supported
        """
        provider_name = provider_name or settings.llm_provider
        provider_name = provider_name.lower()
        
        if provider_name == "gemini":
            logger.info("Creating Gemini LLM provider")
            return GeminiProvider()
        
        # Add more providers here as needed
        # elif provider_name == "openai":
        #     return OpenAIProvider()
        # elif provider_name == "cohere":
        #     return CohereProvider()
        
        else:
            raise ValueError(f"Unsupported LLM provider: {provider_name}")
    
    @staticmethod
    def get_available_providers() -> list:
        """Get list of available provider names."""
        return ["gemini"]  # Add more as implemented

----- END FILE -----

----- FILE: backend\providers\llm\gemini_provider.py -----
size: 4572 bytes | mtime: 2025-12-28T18:02:52.657421

"""
Google Gemini 2.5 Flash LLM Provider Implementation.
Uses google-generativeai SDK for text generation and embeddings.
"""
from typing import List, Optional
import google.generativeai as genai
from backend.providers.llm.interface import LLMInterface
from backend.config import settings
import logging
import asyncio

logger = logging.getLogger(__name__)


class GeminiProvider(LLMInterface):
    """Google Gemini LLM provider implementation."""
    
    def __init__(self, api_key: str = None, model_name: str = None):
        """
        Initialize Gemini provider.
        
        Args:
            api_key: Gemini API key (defaults to settings)
            model_name: Model name (defaults to settings)
        """
        self.api_key = api_key or settings.gemini_api_key
        self.model_name = model_name or settings.gemini_model

        if not self.api_key:
            raise ValueError("GEMINI_API_KEY is required. Set it in .env or environment variables.")
        
        # Configure Gemini
        genai.configure(api_key=self.api_key)
        
        # Initialize models
        self.chat_model = genai.GenerativeModel(self.model_name)
        self.embedding_model = "models/text-embedding-004"
        
        logger.info(f"Gemini provider initialized with model: {self.model_name}")
    
    async def generate_text(
        self,
        prompt: str,
        system_prompt: Optional[str] = None,
        temperature: float = 0.7,
        max_tokens: Optional[int] = None,
        **kwargs
    ) -> str:
        """
        Generate text using Gemini.
        
        Args:
            prompt: User prompt
            system_prompt: System instruction
            temperature: Sampling temperature
            max_tokens: Maximum output tokens
            
        Returns:
            Generated text
        """
        try:
            # Combine system prompt and user prompt
            full_prompt = prompt
            if system_prompt:
                full_prompt = f"{system_prompt}\n\n{prompt}"
            
            # Configure generation
            generation_config = genai.GenerationConfig(
                temperature=temperature,
                max_output_tokens=max_tokens or 2048,
            )
            
            # Generate response (run in thread pool for async)
            loop = asyncio.get_event_loop()
            response = await loop.run_in_executor(
                None,
                lambda: self.chat_model.generate_content(
                    full_prompt,
                    generation_config=generation_config
                )
            )
            
            return response.text
            
        except Exception as e:
            logger.error(f"Error generating text with Gemini: {str(e)}")
            raise
    
    async def generate_embeddings(
        self,
        texts: List[str],
        **kwargs
    ) -> List[List[float]]:
        """
        Generate embeddings using Gemini.
        
        Args:
            texts: List of texts to embed
            
        Returns:
            List of embedding vectors
        """
        try:
            embeddings = []
            
            # Process in batches to avoid rate limits
            batch_size = kwargs.get("batch_size", 10)
            
            for i in range(0, len(texts), batch_size):
                batch = texts[i:i + batch_size]
                
                # Generate embeddings for batch
                loop = asyncio.get_event_loop()
                batch_embeddings = await loop.run_in_executor(
                    None,
                    lambda: [
                        genai.embed_content(
                            model=self.embedding_model,
                            content=text,
                            task_type="retrieval_document"
                        )["embedding"]
                        for text in batch
                    ]
                )
                
                embeddings.extend(batch_embeddings)
            
            return embeddings
            
        except Exception as e:
            logger.error(f"Error generating embeddings with Gemini: {str(e)}")
            raise
    
    def get_model_name(self) -> str:
        """Get model name."""
        return self.model_name
    
    def get_embedding_dimension(self) -> int:
        """Get embedding dimension for Gemini (768)."""
        return 768

----- END FILE -----

----- FILE: backend\providers\llm\interface.py -----
size: 1851 bytes | mtime: 2025-12-28T12:51:36.591833

"""
Abstract LLM Provider Interface.
Defines the contract that all LLM providers must implement.
"""
from abc import ABC, abstractmethod
from typing import List, Dict, Any, Optional


class LLMInterface(ABC):
    """Abstract base class for LLM providers."""
    
    @abstractmethod
    async def generate_text(
        self,
        prompt: str,
        system_prompt: Optional[str] = None,
        temperature: float = 0.7,
        max_tokens: Optional[int] = None,
        **kwargs
    ) -> str:
        """
        Generate text completion from prompt.
        
        Args:
            prompt: User prompt/question
            system_prompt: Optional system instruction
            temperature: Sampling temperature (0.0 to 1.0)
            max_tokens: Maximum tokens to generate
            **kwargs: Additional provider-specific parameters
            
        Returns:
            Generated text response
        """
        pass
    
    @abstractmethod
    async def generate_embeddings(
        self,
        texts: List[str],
        **kwargs
    ) -> List[List[float]]:
        """
        Generate vector embeddings for texts.
        
        Args:
            texts: List of text strings to embed
            **kwargs: Additional provider-specific parameters
            
        Returns:
            List of embedding vectors
        """
        pass
    
    @abstractmethod
    def get_model_name(self) -> str:
        """
        Get the model name/identifier.
        
        Returns:
            Model name string
        """
        pass
    
    @abstractmethod
    def get_embedding_dimension(self) -> int:
        """
        Get the embedding vector dimension.
        
        Returns:
            Dimension size as integer
        """
        pass

----- END FILE -----

----- FILE: backend\providers\vectordb\__init__.py -----
size: 421 bytes | mtime: 2025-12-28T12:51:36.592836

"""VectorDB providers package."""
from backend.providers.vectordb.interface import VectorDBInterface
from backend.providers.vectordb.pgvector_provider import PGVectorProvider
from backend.providers.vectordb.qdrant_provider import QdrantProvider
from backend.providers.vectordb.factory import VectorDBProviderFactory

__all__ = ["VectorDBInterface", "PGVectorProvider", "QdrantProvider", "VectorDBProviderFactory"]

----- END FILE -----

----- FILE: backend\providers\vectordb\factory.py -----
size: 2042 bytes | mtime: 2025-12-28T12:51:36.597346

"""
VectorDB Provider Factory.
Creates vector database provider instances based on configuration.
"""
from backend.providers.vectordb.interface import VectorDBInterface
from backend.providers.vectordb.pgvector_provider import PGVectorProvider
from backend.providers.vectordb.qdrant_provider import QdrantProvider
from backend.config import settings
import logging

logger = logging.getLogger(__name__)


class VectorDBProviderFactory:
    """Factory for creating VectorDB provider instances."""
    
    _instances = {}
    
    @classmethod
    def create_provider(cls, provider_name: str = None) -> VectorDBInterface:
        """
        Create or return existing VectorDB provider instance (Singleton).
        
        Args:
            provider_name: Name of provider ('pgvector', 'qdrant', etc.)
                          Defaults to settings.vector_db_provider
        
        Returns:
            VectorDB provider instance
            
        Raises:
            ValueError: If provider name is not supported
        """
        provider_name = provider_name or settings.vector_db_provider
        provider_name = provider_name.lower()
        
        if provider_name in cls._instances:
            return cls._instances[provider_name]
        
        if provider_name == "pgvector":
            logger.info("Creating PGVector provider")
            instance = PGVectorProvider()
        
        elif provider_name == "qdrant":
            logger.info("Creating Qdrant provider")
            instance = QdrantProvider(
                url=settings.qdrant_url,
                api_key=settings.qdrant_api_key
            )
        
        else:
            raise ValueError(f"Unsupported VectorDB provider: {provider_name}")
            
        cls._instances[provider_name] = instance
        return instance
    
    @staticmethod
    def get_available_providers() -> list:
        """Get list of available provider names."""
        return ["pgvector", "qdrant"]

----- END FILE -----

----- FILE: backend\providers\vectordb\interface.py -----
size: 2983 bytes | mtime: 2025-12-28T12:51:36.598358

"""
Abstract VectorDB Provider Interface.
Defines the contract for vector database providers.
"""
from abc import ABC, abstractmethod
from typing import List, Dict, Any, Optional, Tuple


class VectorDBInterface(ABC):
    """Abstract base class for vector database providers."""
    
    @abstractmethod
    async def create_collection(
        self,
        collection_name: str,
        dimension: int,
        **kwargs
    ) -> bool:
        """
        Create a collection/index for storing vectors.
        
        Args:
            collection_name: Name of the collection
            dimension: Vector dimension size
            **kwargs: Provider-specific parameters
            
        Returns:
            True if successful
        """
        pass
    
    @abstractmethod
    async def add_vectors(
        self,
        collection_name: str,
        vectors: List[List[float]],
        ids: List[Any],
        metadata: Optional[List[Dict[str, Any]]] = None,
        **kwargs
    ) -> bool:
        """
        Add vectors to collection.
        
        Args:
            collection_name: Collection name
            vectors: List of vector embeddings
            ids: List of unique identifiers
            metadata: Optional metadata for each vector
            **kwargs: Provider-specific parameters
            
        Returns:
            True if successful
        """
        pass
    
    @abstractmethod
    async def search(
        self,
        collection_name: str,
        query_vector: List[float],
        top_k: int = 5,
        filter_dict: Optional[Dict[str, Any]] = None,
        **kwargs
    ) -> List[Tuple[Any, float, Dict[str, Any]]]:
        """
        Search for similar vectors.
        
        Args:
            collection_name: Collection name
            query_vector: Query embedding vector
            top_k: Number of results to return
            filter_dict: Optional metadata filters
            **kwargs: Provider-specific parameters
            
        Returns:
            List of tuples: (id, similarity_score, metadata)
        """
        pass
    
    @abstractmethod
    async def delete_collection(
        self,
        collection_name: str,
        **kwargs
    ) -> bool:
        """
        Delete a collection.
        
        Args:
            collection_name: Collection name
            **kwargs: Provider-specific parameters
            
        Returns:
            True if successful
        """
        pass
    
    @abstractmethod
    async def collection_exists(
        self,
        collection_name: str,
        **kwargs
    ) -> bool:
        """
        Check if collection exists.
        
        Args:
            collection_name: Collection name
            **kwargs: Provider-specific parameters
            
        Returns:
            True if exists
        """
        pass

----- END FILE -----

----- FILE: backend\providers\vectordb\pgvector_provider.py -----
size: 7380 bytes | mtime: 2025-12-28T18:02:52.657421

"""
PGVector Provider Implementation.
Uses PostgreSQL with pgvector extension for vector storage.
"""
from typing import List, Dict, Any, Optional, Tuple
from sqlalchemy import select, delete, text
from sqlalchemy.ext.asyncio import AsyncSession
from backend.providers.vectordb.interface import VectorDBInterface
from backend.database.models import Chunk, Project
from backend.database.connection import async_session_maker
import logging

logger = logging.getLogger(__name__)


class PGVectorProvider(VectorDBInterface):
    """PostgreSQL pgvector implementation."""
    
    def __init__(self):
        """Initialize PGVector provider."""
        logger.info("PGVector provider initialized")
    
    async def create_collection(
        self,
        collection_name: str,
        dimension: int,
        **kwargs
    ) -> bool:
        """
        Create collection (for pgvector, this is handled by table creation).
        
        Args:
            collection_name: Not used (using chunks table)
            dimension: Vector dimension
            
        Returns:
            True (table already exists from migrations)
        """
        # With pgvector, collections are handled by the chunks table
        # The vector column is already defined in the model
        logger.info(f"Collection '{collection_name}' ready (using chunks table)")
        return True
    
    async def add_vectors(
        self,
        collection_name: str,
        vectors: List[List[float]],
        ids: List[Any],
        metadata: Optional[List[Dict[str, Any]]] = None,
        **kwargs
    ) -> bool:
        """
        Add/update vectors in chunks table.
        
        Args:
            collection_name: Project name or identifier
            vectors: List of embeddings
            ids: List of chunk IDs
            metadata: Optional metadata
            
        Returns:
            True if successful
        """
        try:
            async with async_session_maker() as session:
                for i, (chunk_id, vector) in enumerate(zip(ids, vectors)):
                    # Update chunk with embedding
                    stmt = select(Chunk).where(Chunk.id == chunk_id)
                    result = await session.execute(stmt)
                    chunk = result.scalar_one_or_none()
                    
                    if chunk:
                        chunk.embedding = vector
                
                await session.commit()
                logger.info(f"Added {len(vectors)} vectors to collection '{collection_name}'")
                return True
                
        except Exception as e:
            logger.error(f"Error adding vectors: {str(e)}")
            raise
    
    async def search(
        self,
        collection_name: str,
        query_vector: List[float],
        top_k: int = 5,
        filter_dict: Optional[Dict[str, Any]] = None,
        **kwargs
    ) -> List[Tuple[Any, float, Dict[str, Any]]]:
        """
        Search for similar vectors.
        Falls back to Python-based similarity if pgvector is not available.
        """
        try:
            async with async_session_maker() as session:
                # Build query to get all relevant chunks
                # We fetch the embedding to calculate similarity in Python
                query = select(
                    Chunk.id,
                    Chunk.content,
                    Chunk.extra_metadata,
                    Chunk.asset_id,
                    Chunk.embedding
                ).where(
                    Chunk.embedding.isnot(None)
                )
                
                # Apply filters
                if filter_dict:
                    if 'project_id' in filter_dict:
                        query = query.where(Chunk.project_id == filter_dict['project_id'])
                    if 'asset_id' in filter_dict:
                        query = query.where(Chunk.asset_id == filter_dict['asset_id'])
                
                result = await session.execute(query)
                rows = result.all()
                
                # Calculate similarity in Python
                def cosine_similarity(v1, v2):
                    if not v1 or not v2: return 0.0
                    dot_product = sum(a * b for a, b in zip(v1, v2))
                    norm1 = sum(a * a for a in v1) ** 0.5
                    norm2 = sum(a * a for a in v2) ** 0.5
                    if not norm1 or not norm2: return 0.0
                    return dot_product / (norm1 * norm2)
                
                scored_results = []
                for row in rows:
                    sim = cosine_similarity(query_vector, row.embedding)
                    scored_results.append((
                        row.id,
                        sim,
                        {
                            'content': row.content,
                            'metadata': row.extra_metadata,
                            'asset_id': row.asset_id
                        }
                    ))
                
                # Sort by similarity and take top_k
                scored_results.sort(key=lambda x: x[1], reverse=True)
                results = scored_results[:top_k]
                
                logger.info(f"Found {len(results)} similar chunks using Python fallback")
                return results
                
        except Exception as e:
            logger.error(f"Error searching vectors: {str(e)}")
            raise
    
    async def delete_collection(
        self,
        collection_name: str,
        **kwargs
    ) -> bool:
        """
        Delete all chunks for a project.
        
        Args:
            collection_name: Project ID or identifier
            
        Returns:
            True if successful
        """
        try:
            async with async_session_maker() as session:
                project_id = kwargs.get('project_id')
                if project_id:
                    stmt = delete(Chunk).where(Chunk.project_id == project_id)
                    await session.execute(stmt)
                    await session.commit()
                    logger.info(f"Deleted collection '{collection_name}'")
                return True
                
        except Exception as e:
            logger.error(f"Error deleting collection: {str(e)}")
            raise
    
    async def collection_exists(
        self,
        collection_name: str,
        **kwargs
    ) -> bool:
        """
        Check if project exists.
        
        Args:
            collection_name: Project name
            
        Returns:
            True if exists
        """
        try:
            async with async_session_maker() as session:
                project_id = kwargs.get('project_id')
                if project_id:
                    stmt = select(Project).where(Project.id == project_id)
                    result = await session.execute(stmt)
                    return result.scalar_one_or_none() is not None
                return False
                
        except Exception as e:
            logger.error(f"Error checking collection: {str(e)}")
            return False

----- END FILE -----

----- FILE: backend\providers\vectordb\qdrant_provider.py -----
size: 7345 bytes | mtime: 2025-12-28T18:02:52.656420

"""
Qdrant Provider Implementation.
Uses Qdrant standalone vector database.
"""
from typing import List, Dict, Any, Optional, Tuple
from backend.providers.vectordb.interface import VectorDBInterface
import logging

logger = logging.getLogger(__name__)


class QdrantProvider(VectorDBInterface):
    """
    Qdrant vector database implementation.
    Optional provider - requires Qdrant server running.
    """
    
    def __init__(self, url: str = "http://localhost:6333", api_key: str = ""):
        """
        Initialize Qdrant provider.
        
        Args:
            url: Qdrant server URL
            api_key: Optional API key
        """
        try:
            from qdrant_client import QdrantClient
            from qdrant_client.models import Distance, VectorParams, PointStruct

            # store model classes for later use
            self._Distance = Distance
            self._VectorParams = VectorParams
            self._PointStruct = PointStruct
            
            if url.startswith("path://"):
                path = url.replace("path://", "")
                self.client = QdrantClient(path=path)
                logger.info(f"Qdrant provider initialized with local path: {path}")
            else:
                self.client = QdrantClient(url=url, api_key=api_key if api_key else None)
                logger.info(f"Qdrant provider initialized at {url}")
        except ImportError:
            logger.error("qdrant-client not installed. Install with: pip install qdrant-client")
            raise
    
    async def create_collection(
        self,
        collection_name: str,
        dimension: int,
        **kwargs
    ) -> bool:
        """
        Create Qdrant collection.
        
        Args:
            collection_name: Collection name
            dimension: Vector dimension
            
        Returns:
            True if successful
        """
        try:
            # Check if collection exists
            collections = self.client.get_collections().collections
            exists = any(c.name == collection_name for c in collections)
            
            if not exists:
                self.client.create_collection(
                    collection_name=collection_name,
                    vectors_config=self._VectorParams(
                        size=dimension,
                        distance=self._Distance.COSINE
                    )
                )
                logger.info(f"Created Qdrant collection '{collection_name}'")
            else:
                logger.info(f"Qdrant collection '{collection_name}' already exists")
            
            return True
            
        except Exception as e:
            logger.error(f"Error creating collection: {str(e)}")
            raise
    
    async def add_vectors(
        self,
        collection_name: str,
        vectors: List[List[float]],
        ids: List[Any],
        metadata: Optional[List[Dict[str, Any]]] = None,
        **kwargs
    ) -> bool:
        """
        Add vectors to Qdrant collection.
        
        Args:
            collection_name: Collection name
            vectors: List of embeddings
            ids: List of IDs
            metadata: Optional metadata
            
        Returns:
            True if successful
        """
        try:
            points = []
            for i, (point_id, vector) in enumerate(zip(ids, vectors)):
                payload = metadata[i] if metadata and i < len(metadata) else {}
                points.append(
                    self._PointStruct(
                        id=point_id,
                        vector=vector,
                        payload=payload
                    )
                )
            
            self.client.upsert(
                collection_name=collection_name,
                points=points
            )
            
            logger.info(f"Added {len(points)} points to Qdrant collection '{collection_name}'")
            return True
            
        except Exception as e:
            logger.error(f"Error adding vectors: {str(e)}")
            raise
    
    async def search(
        self,
        collection_name: str,
        query_vector: List[float],
        top_k: int = 5,
        filter_dict: Optional[Dict[str, Any]] = None,
        **kwargs
    ) -> List[Tuple[Any, float, Dict[str, Any]]]:
        """
        Search Qdrant for similar vectors.
        
        Args:
            collection_name: Collection name
            query_vector: Query embedding
            top_k: Number of results
            filter_dict: Optional filters
            
        Returns:
            List of (id, score, payload)
        """
        try:
            # Build filter if provided
            search_filter = None
            if filter_dict:
                from qdrant_client.models import Filter, FieldCondition, MatchValue
                conditions = []
                for key, value in filter_dict.items():
                    conditions.append(
                        FieldCondition(key=key, match=MatchValue(value=value))
                    )
                search_filter = Filter(must=conditions)
            
            # Search
            search_result = self.client.search(
                collection_name=collection_name,
                query_vector=query_vector,
                limit=top_k,
                query_filter=search_filter
            )
            
            # Format results
            results = []
            for hit in search_result:
                results.append((
                    hit.id,
                    hit.score,
                    hit.payload
                ))
            
            logger.info(f"Found {len(results)} similar points in Qdrant")
            return results
            
        except Exception as e:
            logger.error(f"Error searching vectors: {str(e)}")
            raise
    
    async def delete_collection(
        self,
        collection_name: str,
        **kwargs
    ) -> bool:
        """
        Delete Qdrant collection.
        
        Args:
            collection_name: Collection name
            
        Returns:
            True if successful
        """
        try:
            self.client.delete_collection(collection_name=collection_name)
            logger.info(f"Deleted Qdrant collection '{collection_name}'")
            return True
            
        except Exception as e:
            logger.error(f"Error deleting collection: {str(e)}")
            raise
    
    async def collection_exists(
        self,
        collection_name: str,
        **kwargs
    ) -> bool:
        """
        Check if Qdrant collection exists.
        
        Args:
            collection_name: Collection name
            
        Returns:
            True if exists
        """
        try:
            collections = self.client.get_collections().collections
            return any(c.name == collection_name for c in collections)
            
        except Exception as e:
            logger.error(f"Error checking collection: {str(e)}")
            return False

----- END FILE -----

----- FILE: backend\requirements.txt -----
size: 618 bytes | mtime: 2025-12-29T08:44:11.134600

# FastAPI and server
fastapi==0.109.0
uvicorn[standard]==0.27.0
python-multipart==0.0.6

# Database
sqlalchemy==2.0.25
asyncpg==0.29.0
psycopg2-binary==2.9.9
alembic==1.13.1
pgvector==0.2.4

# LangChain
langchain==0.1.4
langchain-google-genai==0.0.6
langchain-community==0.0.16



# Document Processing
pypdf==4.0.1
python-docx==1.1.0

# Google Gemini
google-generativeai==0.3.2

# Vector DB - Qdrant
qdrant-client

# Telegram Bot
python-telegram-bot==20.7

# Utilities
python-dotenv==1.0.0
pydantic==2.5.3
pydantic-settings==2.1.0
aiofiles==23.2.1

# HTTP Client
httpx==0.25.2

----- END FILE -----

----- FILE: backend\routes\__init__.py -----
size: 159 bytes | mtime: 2025-12-28T12:51:36.600896

"""Routes package initialization."""
from backend.routes import projects, documents, query, health

__all__ = ["projects", "documents", "query", "health"]

----- END FILE -----

----- FILE: backend\routes\bot_config.py -----
size: 1999 bytes | mtime: 2025-12-28T12:51:36.606987

"""
Bot Configuration Routes.
API endpoints for configuring the Telegram bot.
"""
from fastapi import APIRouter, HTTPException, UploadFile, File, Form
from pydantic import BaseModel
from typing import Optional
import json
import os
import httpx
from telegram_bot.config import bot_settings

router = APIRouter(prefix="/bot", tags=["Bot Config"])

CONFIG_FILE = "bot_config.json"

class BotConfig(BaseModel):
    active_project_id: Optional[int] = None

def load_config():
    if os.path.exists(CONFIG_FILE):
        try:
            with open(CONFIG_FILE, "r") as f:
                return json.load(f)
        except:
            return {}
    return {}

def save_config(config):
    with open(CONFIG_FILE, "w") as f:
        json.dump(config, f)

@router.get("/config")
async def get_bot_config():
    """Get current bot configuration."""
    return load_config()

@router.post("/config")
async def update_bot_config(config: BotConfig):
    """Update bot configuration (active project)."""
    current_config = load_config()
    if config.active_project_id is not None:
        current_config["active_project_id"] = config.active_project_id
    save_config(current_config)
    return current_config

@router.post("/profile")
async def update_bot_profile(
    name: str = Form(...),
    # image: UploadFile = File(None) # Image upload to be implemented if needed
):
    """
    Update Telegram Bot Profile (Name).
    Requires 'setMyName' permission.
    """
    try:
        async with httpx.AsyncClient() as client:
            # Update Name
            url = f"https://api.telegram.org/bot{bot_settings.telegram_bot_token}/setMyName"
            response = await client.post(url, json={"name": name})
            response.raise_for_status()
            
            return {"status": "success", "message": "Bot profile updated"}
            
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

----- END FILE -----

----- FILE: backend\routes\documents.py -----
size: 4243 bytes | mtime: 2025-12-28T18:02:52.656420

"""
Document Routes.
API endpoints for document management.
"""
from fastapi import APIRouter, Depends, HTTPException, UploadFile, File, BackgroundTasks
from sqlalchemy.ext.asyncio import AsyncSession
from pydantic import BaseModel
from typing import List, Optional, Dict, Any
from datetime import datetime
from backend.database import get_db
from backend.controllers.document_controller import DocumentController

router = APIRouter(tags=["Documents"])
document_controller = DocumentController()


# Response Models
class AssetResponse(BaseModel):
    id: int
    project_id: int
    filename: str
    original_filename: str
    file_size: int
    file_type: str
    status: str
    error_message: Optional[str]
    created_at: datetime
    processed_at: Optional[datetime]
    extra_metadata: Dict[str, Any]
    
    class Config:
        from_attributes = True


# Routes
@router.post("/projects/{project_id}/documents", response_model=AssetResponse, status_code=201)
async def upload_document(
    project_id: int,
    file: UploadFile = File(...),
    background_tasks: BackgroundTasks = BackgroundTasks(),
    db: AsyncSession = Depends(get_db)
):
    """
    Upload document to project.
    Document will be processed in background.
    """
    try:
        # Read file
        file_content = await file.read()
        file_size = len(file_content)
        
        # Upload document
        asset = await document_controller.upload_document(
            db=db,
            project_id=project_id,
            file_content=file_content,
            filename=file.filename,
            file_size=file_size
        )
        
        # Process in background
        background_tasks.add_task(
            document_controller.process_document,
            asset_id=asset.id
        )
        
        return asset
        
    except ValueError as e:
        raise HTTPException(status_code=400, detail=str(e))
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/projects/{project_id}/documents", response_model=List[AssetResponse])
async def list_project_documents(
    project_id: int,
    db: AsyncSession = Depends(get_db)
):
    """List all documents in project."""
    try:
        documents = await document_controller.list_project_documents(
            db=db,
            project_id=project_id
        )
        return documents
    except Exception as e:
        raise HTTPException(status_code=400, detail=str(e))


@router.get("/documents/{asset_id}", response_model=AssetResponse)
async def get_document(
    asset_id: int,
    db: AsyncSession = Depends(get_db)
):
    """Get document by ID."""
    try:
        document = await document_controller.get_document(db=db, asset_id=asset_id)
        if not document:
            raise HTTPException(status_code=404, detail="Document not found")
        return document
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=400, detail=str(e))


@router.post("/documents/{asset_id}/process", response_model=AssetResponse)
async def process_document(
    asset_id: int,
    db: AsyncSession = Depends(get_db)
):
    """Manually trigger document processing."""
    try:
        await document_controller.process_document(asset_id=asset_id)
        document = await document_controller.get_document(db=db, asset_id=asset_id)
        return document
    except ValueError as e:
        raise HTTPException(status_code=400, detail=str(e))
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@router.delete("/documents/{asset_id}", status_code=204)
async def delete_document(
    asset_id: int,
    db: AsyncSession = Depends(get_db)
):
    """Delete document."""
    try:
        deleted = await document_controller.delete_document(db=db, asset_id=asset_id)
        if not deleted:
            raise HTTPException(status_code=404, detail="Document not found")
        return None
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=400, detail=str(e))

----- END FILE -----

----- FILE: backend\routes\health.py -----
size: 1271 bytes | mtime: 2025-12-28T12:51:36.608019

"""
Health Check Routes.
API endpoints for system health monitoring.
"""
from fastapi import APIRouter, Depends
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import text
from backend.database import get_db
from backend.config import settings
from pydantic import BaseModel

router = APIRouter(tags=["Health"])


class HealthResponse(BaseModel):
    status: str
    database: str
    llm_provider: str
    vector_db_provider: str


@router.get("/health", response_model=HealthResponse)
async def health_check(db: AsyncSession = Depends(get_db)):
    """Check system health status."""
    try:
        # Check database connection
        await db.execute(text("SELECT 1"))
        db_status = "connected"
    except Exception:
        db_status = "disconnected"
    
    return {
        "status": "healthy" if db_status == "connected" else "unhealthy",
        "database": db_status,
        "llm_provider": settings.llm_provider,
        "vector_db_provider": settings.vector_db_provider
    }


@router.get("/")
async def root():
    """Root endpoint."""
    return {
        "name": settings.api_title,
        "version": settings.api_version,
        "docs": "/docs",
        "health": "/health"
    }

----- END FILE -----

----- FILE: backend\routes\projects.py -----
size: 4811 bytes | mtime: 2025-12-28T12:51:36.608543

"""
Project Routes.
API endpoints for project management.
"""
from fastapi import APIRouter, Depends, HTTPException
from sqlalchemy.ext.asyncio import AsyncSession
from pydantic import BaseModel, Field
from typing import Optional, List, Dict, Any
from datetime import datetime
from backend.database import get_db
from backend.controllers.project_controller import ProjectController

router = APIRouter(prefix="/projects", tags=["Projects"])
project_controller = ProjectController()


# Request/Response Models
class ProjectCreate(BaseModel):
    name: str = Field(..., min_length=1, max_length=255)
    description: Optional[str] = None
    metadata: Optional[Dict[str, Any]] = None


class ProjectUpdate(BaseModel):
    name: Optional[str] = Field(None, min_length=1, max_length=255)
    description: Optional[str] = None
    metadata: Optional[Dict[str, Any]] = None


class ProjectResponse(BaseModel):
    id: int
    name: str
    description: Optional[str]
    extra_metadata: Dict[str, Any]
    created_at: datetime
    updated_at: Optional[datetime]
    
    class Config:
        from_attributes = True


class ProjectStatsResponse(BaseModel):
    project: ProjectResponse
    stats: Dict[str, Any]


# Routes
@router.post("/", response_model=ProjectResponse, status_code=201)
async def create_project(
    project_data: ProjectCreate,
    db: AsyncSession = Depends(get_db)
):
    """Create a new project."""
    try:
        project = await project_controller.create_project(
            db=db,
            name=project_data.name,
            description=project_data.description,
            metadata=project_data.metadata
        )
        return project
    except Exception as e:
        raise HTTPException(status_code=400, detail=str(e))


@router.get("/", response_model=List[ProjectResponse])
async def list_projects(
    skip: int = 0,
    limit: int = 100,
    db: AsyncSession = Depends(get_db)
):
    """List all projects."""
    try:
        projects = await project_controller.list_projects(db=db, skip=skip, limit=limit)
        return projects
    except Exception as e:
        raise HTTPException(status_code=400, detail=str(e))


@router.get("/{project_id}", response_model=ProjectResponse)
async def get_project(
    project_id: int,
    db: AsyncSession = Depends(get_db)
):
    """Get project by ID."""
    try:
        project = await project_controller.get_project(db=db, project_id=project_id)
        if not project:
            raise HTTPException(status_code=404, detail="Project not found")
        return project
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=400, detail=str(e))


@router.get("/{project_id}/stats", response_model=ProjectStatsResponse)
async def get_project_stats(
    project_id: int,
    db: AsyncSession = Depends(get_db)
):
    """Get project statistics."""
    try:
        project = await project_controller.get_project(db=db, project_id=project_id)
        if not project:
            raise HTTPException(status_code=404, detail="Project not found")
        
        stats = await project_controller.get_project_stats(db=db, project_id=project_id)
        
        return {
            "project": project,
            "stats": stats
        }
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=400, detail=str(e))


@router.put("/{project_id}", response_model=ProjectResponse)
async def update_project(
    project_id: int,
    project_data: ProjectUpdate,
    db: AsyncSession = Depends(get_db)
):
    """Update project."""
    try:
        project = await project_controller.update_project(
            db=db,
            project_id=project_id,
            name=project_data.name,
            description=project_data.description,
            metadata=project_data.metadata
        )
        if not project:
            raise HTTPException(status_code=404, detail="Project not found")
        return project
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=400, detail=str(e))


@router.delete("/{project_id}", status_code=204)
async def delete_project(
    project_id: int,
    db: AsyncSession = Depends(get_db)
):
    """Delete project and all associated data."""
    try:
        deleted = await project_controller.delete_project(db=db, project_id=project_id)
        if not deleted:
            raise HTTPException(status_code=404, detail="Project not found")
        return None
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=400, detail=str(e))

----- END FILE -----

----- FILE: backend\routes\query.py -----
size: 1660 bytes | mtime: 2025-12-28T12:51:36.608543

"""
Query Routes.
API endpoints for querying documents.
"""
from fastapi import APIRouter, Depends, HTTPException
from sqlalchemy.ext.asyncio import AsyncSession
from pydantic import BaseModel, Field
from typing import Optional, List, Dict, Any
from backend.database import get_db
from backend.controllers.query_controller import QueryController

router = APIRouter(tags=["Query"])
query_controller = QueryController()


# Request/Response Models
class QueryRequest(BaseModel):
    query: str = Field(..., min_length=1)
    top_k: int = Field(default=5, ge=1, le=20)
    language: str = Field(default="ar", pattern="^(ar|en)$")
    asset_id: Optional[int] = None


class SourceInfo(BaseModel):
    document_name: str
    chunk_index: int
    similarity: float
    asset_id: int


class QueryResponse(BaseModel):
    answer: str
    sources: List[SourceInfo]
    context_used: int


# Routes
@router.post("/projects/{project_id}/query", response_model=QueryResponse)
async def query_project(
    project_id: int,
    query_data: QueryRequest,
    db: AsyncSession = Depends(get_db)
):
    """
    Ask a question about project documents.
    Returns AI-generated answer with sources.
    """
    try:
        result = await query_controller.answer_query(
            db=db,
            project_id=project_id,
            query=query_data.query,
            top_k=query_data.top_k,
            language=query_data.language,
            asset_id=query_data.asset_id
        )
        
        return result
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

----- END FILE -----

----- FILE: backend\routes\stats.py -----
size: 1182 bytes | mtime: 2025-12-28T12:51:36.609554

"""
Stats Routes.
API endpoints for global statistics.
"""
from fastapi import APIRouter, Depends, HTTPException
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import func, select
from backend.database import get_db
from backend.database.models import Project, Asset, Chunk

router = APIRouter(prefix="/stats", tags=["Stats"])

@router.get("/")
async def get_global_stats(db: AsyncSession = Depends(get_db)):
    """Get global statistics."""
    try:
        # Count projects
        projects_query = select(func.count(Project.id))
        projects_count = await db.scalar(projects_query)
        
        # Count documents
        documents_query = select(func.count(Asset.id))
        documents_count = await db.scalar(documents_query)
        
        # Count chunks
        chunks_query = select(func.count(Chunk.id))
        chunks_count = await db.scalar(chunks_query)
        
        return {
            "projects": projects_count or 0,
            "documents": documents_count or 0,
            "chunks": chunks_count or 0
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

----- END FILE -----

----- FILE: backend\services\__init__.py -----
size: 566 bytes | mtime: 2025-12-28T12:51:36.610571

"""Services package initialization."""
from backend.services.document_loader import DocumentLoaderService
from backend.services.chunking_service import ChunkingService
from backend.services.file_service import FileService
from backend.services.embedding_service import EmbeddingService
from backend.services.query_service import QueryService
from backend.services.answer_service import AnswerService

__all__ = [
    "DocumentLoaderService",
    "ChunkingService",
    "FileService",
    "EmbeddingService",
    "QueryService",
    "AnswerService"
]

----- END FILE -----

----- FILE: backend\services\answer_service.py -----
size: 4895 bytes | mtime: 2025-12-28T12:51:36.615653

"""
Answer Generation Service.
Handles generating AI-powered answers using LLM.
"""
from typing import List, Dict, Any, Optional
from backend.providers.llm.factory import LLMProviderFactory
import logging

logger = logging.getLogger(__name__)


class AnswerService:
    """Service for generating answers from context."""
    
    def __init__(self):
        """Initialize answer service."""
        self.llm_provider = LLMProviderFactory.create_provider()
        logger.info("Answer service initialized")
    
    async def generate_answer(
        self,
        query: str,
        context_chunks: List[Dict[str, Any]],
        language: str = "ar",  # Default to Arabic
        include_sources: bool = True
    ) -> Dict[str, Any]:
        """
        Generate answer from query and context.
        
        Args:
            query: User question
            context_chunks: List of relevant chunks
            language: Response language ('ar' or 'en')
            include_sources: Whether to include source references
            
        Returns:
            Dict with 'answer' and optional 'sources'
        """
        try:
            # Build context from chunks
            context = self._build_context(context_chunks)
            
            # Build prompt
            prompt = self._build_prompt(query, context, language)
            
            # Generate answer
            answer = await self.llm_provider.generate_text(
                prompt=prompt,
                temperature=0.7,
                max_tokens=1024
            )
            
            # Format response
            response = {
                'answer': answer.strip(),
                'context_used': len(context_chunks)
            }
            
            if include_sources:
                response['sources'] = self._extract_sources(context_chunks)
            
            logger.info(f"Generated answer (length={len(answer)})")
            return response
            
        except Exception as e:
            logger.error(f"Error generating answer: {str(e)}")
            raise
    
    def _build_context(self, chunks: List[Dict[str, Any]]) -> str:
        """
        Build context string from chunks.
        
        Args:
            chunks: List of chunk dictionaries
            
        Returns:
            Formatted context string
        """
        context_parts = []
        for i, chunk in enumerate(chunks, 1):
            content = chunk.get('content', '')
            metadata = chunk.get('metadata', {})
            doc_name = metadata.get('document_name', 'Unknown')
            
            context_parts.append(f"[مصدر {i} - {doc_name}]\n{content}")
        
        return "\n\n".join(context_parts)
    
    def _build_prompt(self, query: str, context: str, language: str) -> str:
        """
        Build prompt for LLM.
        
        Args:
            query: User question
            context: Context text
            language: Response language
            
        Returns:
            Formatted prompt
        """
        if language == "ar":
            system_prompt = """أنت مساعد ذكي متخصص في الإجابة على الأسئلة بناءً على المحتوى المقدم.
قم بتحليل السياق المقدم وأجب على السؤال بدقة واحترافية.
إذا لم تجد الإجابة في السياق، قل ذلك بوضوح.
استخدم اللغة العربية الفصحى في إجاباتك."""

            prompt = f"""{system_prompt}

السياق:
{context}

السؤال: {query}

الإجابة:"""
        else:
            system_prompt = """You are an intelligent assistant specialized in answering questions based on provided content.
Analyze the given context and answer the question accurately and professionally.
If you cannot find the answer in the context, state that clearly."""

            prompt = f"""{system_prompt}

Context:
{context}

Question: {query}

Answer:"""
        
        return prompt
    
    def _extract_sources(self, chunks: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        Extract source information from chunks.
        
        Args:
            chunks: List of chunk dictionaries
            
        Returns:
            List of source information
        """
        sources = []
        for chunk in chunks:
            metadata = chunk.get('metadata', {})
            sources.append({
                'document_name': metadata.get('document_name', 'Unknown'),
                'chunk_index': metadata.get('chunk_index', 0),
                'similarity': chunk.get('similarity', 0.0),
                'asset_id': chunk.get('asset_id')
            })
        
        return sources

----- END FILE -----

----- FILE: backend\services\chunking_service.py -----
size: 3339 bytes | mtime: 2025-12-29T08:47:16.832029

"""
Text Chunking Service.
Handles splitting text into chunks using LangChain.
"""
from typing import List, Dict, Any
from langchain.text_splitter import RecursiveCharacterTextSplitter
from backend.config import settings
import logging

logger = logging.getLogger(__name__)


class ChunkingService:
    """Service for chunking text documents."""
    
    def __init__(
        self,
        chunk_size: int = None,
        chunk_overlap: int = None
    ):
        """
        Initialize chunking service.
        
        Args:
            chunk_size: Size of each chunk (defaults to settings)
            chunk_overlap: Overlap between chunks (defaults to settings)
        """
        self.chunk_size = chunk_size or settings.chunk_size
        self.chunk_overlap = chunk_overlap or settings.chunk_overlap
        
        # Initialize text splitter
        self.text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=self.chunk_size,
            chunk_overlap=self.chunk_overlap,
            length_function=len,
            separators=["\n\n", "\n", ". ", " ", ""]
        )
        
        logger.info(f"Chunking service initialized (size={self.chunk_size}, overlap={self.chunk_overlap})")
    
    async def chunk_text(
        self,
        text: str,
        metadata: Dict[str, Any] = None
    ) -> List[Dict[str, Any]]:
        """
        Split text into chunks with metadata.
        
        Args:
            text: Text to chunk
            metadata: Optional base metadata for all chunks
            
        Returns:
            List of chunk dictionaries with 'content' and 'metadata'
        """
        try:
            # Split text
            text_chunks = self.text_splitter.split_text(text)
            
            # Create chunk objects with metadata
            chunks = []
            base_metadata = metadata or {}
            
            for i, chunk_text in enumerate(text_chunks):
                chunk_metadata = {
                    **base_metadata,
                    'chunk_index': i,
                    'total_chunks': len(text_chunks),
                    'chunk_size': len(chunk_text)
                }
                
                chunks.append({
                    'content': chunk_text,
                    'metadata': chunk_metadata
                })
            
            logger.info(f"Created {len(chunks)} chunks from text ({len(text)} characters)")
            return chunks
            
        except Exception as e:
            logger.error(f"Error chunking text: {str(e)}")
            raise
    
    async def chunk_document(
        self,
        text: str,
        document_name: str,
        additional_metadata: Dict[str, Any] = None
    ) -> List[Dict[str, Any]]:
        """
        Chunk document with automatic metadata.
        
        Args:
            text: Document text
            document_name: Name of document
            additional_metadata: Optional additional metadata
            
        Returns:
            List of chunks with metadata
        """
        metadata = {
            'document_name': document_name,
            **(additional_metadata or {})
        }
        
        return await self.chunk_text(text, metadata)

----- END FILE -----

----- FILE: backend\services\document_loader.py -----
size: 4597 bytes | mtime: 2025-12-28T12:51:36.618538

"""
Document Loader Service.
Handles loading and extracting text from various document formats.
"""
from typing import Optional
import os
import logging
from pathlib import Path

logger = logging.getLogger(__name__)


class DocumentLoaderService:
    """Service for loading documents and extracting text."""
    
    @staticmethod
    async def load_document(file_path: str) -> str:
        """
        Load document and extract text content.
        
        Args:
            file_path: Path to document file
            
        Returns:
            Extracted text content
            
        Raises:
            ValueError: If file type is not supported
        """
        file_ext = Path(file_path).suffix.lower()
        
        if file_ext == '.pdf':
            return await DocumentLoaderService._load_pdf(file_path)
        elif file_ext == '.txt':
            return await DocumentLoaderService._load_txt(file_path)
        elif file_ext == '.docx':
            return await DocumentLoaderService._load_docx(file_path)
        else:
            raise ValueError(f"Unsupported file type: {file_ext}")
    
    @staticmethod
    async def _load_pdf(file_path: str) -> str:
        """
        Load PDF file and extract text.
        
        Args:
            file_path: Path to PDF file
            
        Returns:
            Extracted text
        """
        try:
            from pypdf import PdfReader
            
            reader = PdfReader(file_path)
            text_parts = []
            
            for page_num, page in enumerate(reader.pages, 1):
                text = page.extract_text()
                if text.strip():
                    text_parts.append(text)
            
            full_text = "\n\n".join(text_parts)
            logger.info(f"Extracted {len(full_text)} characters from PDF ({len(reader.pages)} pages)")
            
            return full_text
            
        except Exception as e:
            logger.error(f"Error loading PDF: {str(e)}")
            raise
    
    @staticmethod
    async def _load_txt(file_path: str) -> str:
        """
        Load text file.
        
        Args:
            file_path: Path to text file
            
        Returns:
            File content
        """
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                text = f.read()
            
            logger.info(f"Loaded {len(text)} characters from TXT file")
            return text
            
        except UnicodeDecodeError:
            # Try with different encoding
            try:
                with open(file_path, 'r', encoding='latin-1') as f:
                    text = f.read()
                logger.info(f"Loaded {len(text)} characters from TXT file (latin-1 encoding)")
                return text
            except Exception as e:
                logger.error(f"Error loading TXT file: {str(e)}")
                raise
        except Exception as e:
            logger.error(f"Error loading TXT file: {str(e)}")
            raise
    
    @staticmethod
    async def _load_docx(file_path: str) -> str:
        """
        Load DOCX file and extract text.
        
        Args:
            file_path: Path to DOCX file
            
        Returns:
            Extracted text
        """
        try:
            from docx import Document
            
            doc = Document(file_path)
            text_parts = []
            
            for para in doc.paragraphs:
                if para.text.strip():
                    text_parts.append(para.text)
            
            full_text = "\n\n".join(text_parts)
            logger.info(f"Extracted {len(full_text)} characters from DOCX ({len(doc.paragraphs)} paragraphs)")
            
            return full_text
            
        except Exception as e:
            logger.error(f"Error loading DOCX: {str(e)}")
            raise
    
    @staticmethod
    def get_supported_extensions() -> list:
        """Get list of supported file extensions."""
        return ['.pdf', '.txt', '.docx']
    
    @staticmethod
    def is_supported_file(filename: str) -> bool:
        """
        Check if file type is supported.
        
        Args:
            filename: File name or path
            
        Returns:
            True if supported
        """
        ext = Path(filename).suffix.lower()
        return ext in DocumentLoaderService.get_supported_extensions()

----- END FILE -----

----- FILE: backend\services\embedding_service.py -----
size: 2066 bytes | mtime: 2025-12-28T12:51:36.619046

"""
Embedding Service.
Handles generating embeddings using LLM provider.
"""
from typing import List
from backend.providers.llm.factory import LLMProviderFactory
import logging

logger = logging.getLogger(__name__)


class EmbeddingService:
    """Service for generating embeddings."""
    
    def __init__(self):
        """Initialize embedding service with LLM provider."""
        self.llm_provider = LLMProviderFactory.create_provider()
        logger.info(f"Embedding service initialized with {self.llm_provider.get_model_name()}")
    
    async def generate_embeddings(
        self,
        texts: List[str],
        batch_size: int = 10
    ) -> List[List[float]]:
        """
        Generate embeddings for list of texts.
        
        Args:
            texts: List of text strings
            batch_size: Batch size for processing
            
        Returns:
            List of embedding vectors
        """
        try:
            if not texts:
                return []
            
            embeddings = await self.llm_provider.generate_embeddings(
                texts=texts,
                batch_size=batch_size
            )
            
            logger.info(f"Generated {len(embeddings)} embeddings")
            return embeddings
            
        except Exception as e:
            logger.error(f"Error generating embeddings: {str(e)}")
            raise
    
    async def generate_single_embedding(self, text: str) -> List[float]:
        """
        Generate embedding for single text.
        
        Args:
            text: Text string
            
        Returns:
            Embedding vector
        """
        embeddings = await self.generate_embeddings([text])
        return embeddings[0] if embeddings else []
    
    def get_embedding_dimension(self) -> int:
        """
        Get the embedding vector dimension.
        
        Returns:
            Dimension size
        """
        return self.llm_provider.get_embedding_dimension()

----- END FILE -----

----- FILE: backend\services\file_service.py -----
size: 5265 bytes | mtime: 2025-12-28T12:51:36.619046

"""
File Management Service.
Handles file storage with project-based organization.
"""
import os
import uuid
import shutil
from pathlib import Path
from typing import Optional
from backend.config import settings
import logging
import aiofiles

logger = logging.getLogger(__name__)


class FileService:
    """Service for managing uploaded files."""
    
    def __init__(self):
        """Initialize file service."""
        self.upload_dir = Path(settings.upload_dir)
        self.max_size_bytes = settings.max_file_size_mb * 1024 * 1024
        
        # Create upload directory if it doesn't exist
        self.upload_dir.mkdir(parents=True, exist_ok=True)
        logger.info(f"File service initialized (upload_dir={self.upload_dir})")
    
    def get_project_dir(self, project_id: int) -> Path:
        """
        Get directory path for project.
        
        Args:
            project_id: Project ID
            
        Returns:
            Path to project directory
        """
        project_dir = self.upload_dir / f"project_{project_id}"
        project_dir.mkdir(parents=True, exist_ok=True)
        return project_dir
    
    def generate_unique_filename(self, original_filename: str) -> str:
        """
        Generate unique filename while preserving extension.
        
        Args:
            original_filename: Original file name
            
        Returns:
            Unique filename
        """
        file_ext = Path(original_filename).suffix
        unique_id = uuid.uuid4().hex[:12]
        safe_name = Path(original_filename).stem[:50]  # Limit length
        return f"{safe_name}_{unique_id}{file_ext}"
    
    async def save_upload_file(
        self,
        file_content: bytes,
        filename: str,
        project_id: int
    ) -> tuple[str, str]:
        """
        Save uploaded file to project directory.
        
        Args:
            file_content: File content as bytes
            filename: Original filename
            project_id: Project ID
            
        Returns:
            Tuple of (unique_filename, file_path)
            
        Raises:
            ValueError: If file is too large
        """
        # Check file size
        if len(file_content) > self.max_size_bytes:
            raise ValueError(
                f"File too large ({len(file_content)} bytes). "
                f"Maximum size is {settings.max_file_size_mb}MB"
            )
        
        # Generate unique filename
        unique_filename = self.generate_unique_filename(filename)
        
        # Get project directory
        project_dir = self.get_project_dir(project_id)
        file_path = project_dir / unique_filename
        
        # Save file asynchronously
        async with aiofiles.open(file_path, 'wb') as f:
            await f.write(file_content)
        
        logger.info(f"Saved file: {file_path} ({len(file_content)} bytes)")
        
        return unique_filename, str(file_path)
    
    async def delete_file(self, file_path: str) -> bool:
        """
        Delete file from storage.
        
        Args:
            file_path: Path to file
            
        Returns:
            True if deleted successfully
        """
        try:
            path = Path(file_path)
            if path.exists():
                path.unlink()
                logger.info(f"Deleted file: {file_path}")
                return True
            else:
                logger.warning(f"File not found: {file_path}")
                return False
        except Exception as e:
            logger.error(f"Error deleting file: {str(e)}")
            raise
    
    async def delete_project_files(self, project_id: int) -> bool:
        """
        Delete all files for a project.
        
        Args:
            project_id: Project ID
            
        Returns:
            True if deleted successfully
        """
        try:
            project_dir = self.get_project_dir(project_id)
            if project_dir.exists():
                shutil.rmtree(project_dir)
                logger.info(f"Deleted project directory: {project_dir}")
                return True
            return False
        except Exception as e:
            logger.error(f"Error deleting project files: {str(e)}")
            raise
    
    def validate_file(self, filename: str, file_size: int) -> tuple[bool, Optional[str]]:
        """
        Validate file before upload.
        
        Args:
            filename: File name
            file_size: File size in bytes
            
        Returns:
            Tuple of (is_valid, error_message)
        """
        # Check file extension
        from backend.services.document_loader import DocumentLoaderService
        if not DocumentLoaderService.is_supported_file(filename):
            return False, f"Unsupported file type. Supported: {DocumentLoaderService.get_supported_extensions()}"
        
        # Check file size
        if file_size > self.max_size_bytes:
            return False, f"File too large. Maximum size is {settings.max_file_size_mb}MB"
        
        return True, None

----- END FILE -----

----- FILE: backend\services\query_service.py -----
size: 2565 bytes | mtime: 2025-12-28T12:51:36.620058

"""
Query Service.
Handles query processing and similarity search.
"""
from typing import List, Dict, Any, Optional
from backend.services.embedding_service import EmbeddingService
from backend.providers.vectordb.factory import VectorDBProviderFactory
import logging

logger = logging.getLogger(__name__)


class QueryService:
    """Service for processing queries and searching."""
    
    def __init__(self):
        """Initialize query service."""
        self.embedding_service = EmbeddingService()
        self.vector_db = VectorDBProviderFactory.create_provider()
        logger.info("Query service initialized")
    
    async def search_similar_chunks(
        self,
        query: str,
        project_id: int,
        top_k: int = 5,
        asset_id: Optional[int] = None
    ) -> List[Dict[str, Any]]:
        """
        Search for chunks similar to query.
        
        Args:
            query: Search query
            project_id: Project ID to search within
            top_k: Number of results to return
            asset_id: Optional asset ID to filter by
            
        Returns:
            List of similar chunks with metadata
        """
        try:
            # Generate query embedding
            query_embedding = await self.embedding_service.generate_single_embedding(query)
            
            # Build filter
            filter_dict = {'project_id': project_id}
            if asset_id:
                filter_dict['asset_id'] = asset_id
            
            # Search vector database
            results = await self.vector_db.search(
                collection_name=f"project_{project_id}",
                query_vector=query_embedding,
                top_k=top_k,
                filter_dict=filter_dict
            )
            
            # Format results
            formatted_results = []
            for chunk_id, similarity, metadata in results:
                formatted_results.append({
                    'chunk_id': chunk_id,
                    'similarity': similarity,
                    'content': metadata.get('content', ''),
                    'metadata': metadata.get('metadata', {}),
                    'asset_id': metadata.get('asset_id')
                })
            
            logger.info(f"Found {len(formatted_results)} similar chunks for query")
            return formatted_results
            
        except Exception as e:
            logger.error(f"Error searching chunks: {str(e)}")
            raise

----- END FILE -----

----- FILE: bot_config.json -----
size: 24 bytes | mtime: 2025-12-30T08:12:06.670156

{"active_project_id": 1}
----- END FILE -----

----- FILE: check_extension.py -----
size: 1073 bytes | mtime: 2025-12-28T12:51:36.621076

import psycopg2
from backend.config import settings

def check_extension():
    db_url = settings.database_url.replace("postgresql+asyncpg://", "")
    auth, rest = db_url.split("@")
    user, password = auth.split(":")
    host_port, db_name = rest.split("/")
    host = host_port.split(":")[0]
    port = host_port.split(":")[1] if ":" in host_port else "5432"
    
    try:
        conn = psycopg2.connect(
            dbname=db_name,
            user=user,
            password=password,
            host=host,
            port=port
        )
        cur = conn.cursor()
        cur.execute("SELECT * FROM pg_available_extensions WHERE name = 'vector'")
        extension = cur.fetchone()
        if extension:
            print(f"Extension 'vector' is available. Version: {extension[2]}")
        else:
            print("Extension 'vector' is NOT available in pg_available_extensions.")
        cur.close()
        conn.close()
    except Exception as e:
        print(f"Error: {e}")

if __name__ == "__main__":
    check_extension()

----- END FILE -----

----- FILE: create_database.sql -----
size: 378 bytes | mtime: 2025-12-28T12:51:36.621602

-- RAGMind Database Creation Script
-- Run this in PostgreSQL before starting the application

-- Create database
CREATE DATABASE ragmind;

-- Connect to the ragmind database (in psql: \c ragmind)
\c ragmind

-- Enable pgvector extension
CREATE EXTENSION IF NOT EXISTS vector;

-- Verify extension is installed
SELECT * FROM pg_extension WHERE extname = 'vector';

----- END FILE -----

----- FILE: f.py -----
size: 201 bytes | mtime: 2025-12-30T07:50:26.427225


import os, re, logging
logger = logging.getLogger(__name__)

db_url = os.getenv("DATABASE_URL", "")
safe = re.sub(r":([^:@/]+)@", ":***@", db_url)
logger.info(f"Runtime DATABASE_URL = {safe}")

----- END FILE -----

----- FILE: frontend\app.js -----
size: 24616 bytes | mtime: 2025-12-28T12:51:36.622126

/**
 * RAGMind Web Frontend
 * Main Application Logic
 */

// Configuration
const API_BASE_URL = 'http://localhost:8000';

// Translations
const i18n = {
    ar: {
        nav_dashboard: "لوحة التحكم",
        nav_projects: "المشاريع",
        nav_chat: "المحادثة الذكية",
        nav_bot: "إعدادات البوت",
        stat_projects: "إجمالي المشاريع",
        stat_docs: "المستندات",
        stat_chunks: "القطع النصية",
        recent_projects: "المشاريع الأخيرة",
        view_all: "عرض الكل",
        your_projects: "مشاريعك",
        welcome_title: "مرحباً بك في RAGMind",
        project_name_ph: "مثلاً: أبحاث الذكاء الاصطناعي",
        project_desc_ph: "وصف مختصر للمشروع...",
        create_project_btn: "إنشاء المشروع",
        upload_title: "رفع مستندات جديدة",
        upload_desc: "اسحب الملفات هنا أو اضغط للاختيار",
        docs_title: "المستندات الحالية",
        bot_settings_title: "إعدادات بوت التليجرام",
        bot_active_project: "المشروع النشط",
        bot_active_project_desc: "اختر المشروع الذي سيقوم البوت بالإجابة منه.",
        save_settings: "حفظ الإعدادات",
        bot_profile: "ملف البوت",
        bot_profile_desc: "تحديث اسم البوت على تليجرام.",
        bot_name: "اسم البوت",
        update_profile: "تحديث الملف الشخصي",
        select_project_ph: "اختر مشروعاً...",
        delete_confirm: "هل أنت متأكد؟",
        success_saved: "تم الحفظ بنجاح",
        error_generic: "حدث خطأ ما"
    },
    en: {
        nav_dashboard: "Dashboard",
        nav_projects: "Projects",
        nav_chat: "Smart Chat",
        nav_bot: "Bot Settings",
        stat_projects: "Total Projects",
        stat_docs: "Documents",
        stat_chunks: "Text Chunks",
        recent_projects: "Recent Projects",
        view_all: "View All",
        your_projects: "Your Projects",
        welcome_title: "Welcome to RAGMind",
        project_name_ph: "Ex: AI Research",
        project_desc_ph: "Short description...",
        create_project_btn: "Create Project",
        upload_title: "Upload New Documents",
        upload_desc: "Drag files here or click to select",
        docs_title: "Current Documents",
        bot_settings_title: "Telegram Bot Settings",
        bot_active_project: "Active Project",
        bot_active_project_desc: "Select the project the bot will answer from.",
        save_settings: "Save Settings",
        bot_profile: "Bot Profile",
        bot_profile_desc: "Update Bot Name on Telegram.",
        bot_name: "Bot Name",
        update_profile: "Update Profile",
        select_project_ph: "Select a project...",
        delete_confirm: "Are you sure?",
        success_saved: "Saved successfully",
        error_generic: "Something went wrong"
    }
};

// State Management
const state = {
    currentView: 'dashboard',
    projects: [],
    stats: null,
    selectedProject: null,
    chatMessages: [],
    isUploading: false,
    lang: localStorage.getItem('lang') || 'ar',
    theme: localStorage.getItem('theme') || 'dark'
};

// DOM Elements
const elements = {
    viewContainer: document.getElementById('view-container'),
    navItems: document.querySelectorAll('.sidebar-nav li'),
    newProjectBtn: document.getElementById('new-project-btn'),
    modalOverlay: document.getElementById('modal-overlay'),
    modalTitle: document.getElementById('modal-title'),
    modalBody: document.getElementById('modal-body'),
    closeModalBtn: document.querySelector('.close-modal'),
    themeToggle: document.getElementById('theme-toggle'),
    langToggle: document.getElementById('lang-toggle')
};

// --- API Client ---

const api = {
    async get(endpoint) {
        try {
            const response = await fetch(`${API_BASE_URL}${endpoint}`);
            if (!response.ok) throw new Error(`HTTP error! status: ${response.status}`);
            return await response.json();
        } catch (error) {
            console.error(`API Get Error (${endpoint}):`, error);
            showNotification(state.lang === 'ar' ? 'خطأ في الاتصال بالسيرفر' : 'Server Connection Error', 'error');
            throw error;
        }
    },

    async post(endpoint, data, isFormData = false) {
        try {
            const options = {
                method: 'POST',
                body: isFormData ? data : JSON.stringify(data)
            };
            if (!isFormData) {
                options.headers = { 'Content-Type': 'application/json' };
            }

            const response = await fetch(`${API_BASE_URL}${endpoint}`, options);
            if (!response.ok) {
                const errorData = await response.json();
                throw new Error(errorData.detail || 'Error');
            }
            return await response.json();
        } catch (error) {
            console.error(`API Post Error (${endpoint}):`, error);
            showNotification(error.message, 'error');
            throw error;
        }
    },

    async delete(endpoint) {
        try {
            const response = await fetch(`${API_BASE_URL}${endpoint}`, { method: 'DELETE' });
            if (!response.ok) throw new Error('Delete failed');
            return true;
        } catch (error) {
            console.error(`API Delete Error (${endpoint}):`, error);
            showNotification(error.message, 'error');
            throw error;
        }
    }
};

// --- View Rendering ---

const views = {
    async dashboard() {
        renderTemplate('dashboard-template');
        showLoader();

        try {
            const [projects, stats] = await Promise.all([
                api.get('/projects/'),
                api.get('/stats/')
            ]);
            state.projects = projects;

            // Update stats
            document.getElementById('stat-projects').textContent = stats.projects;
            document.getElementById('stat-docs').textContent = stats.documents;
            document.getElementById('stat-chunks').textContent = stats.chunks;

            // Render recent projects
            const list = document.getElementById('recent-projects-list');
            list.innerHTML = '';
            projects.slice(0, 3).forEach(project => {
                list.appendChild(createProjectCard(project));
            });

            applyTranslations();
        } catch (error) {
            console.error('Dashboard Load Error:', error);
        } finally {
            hideLoader();
        }
    },

    async projects() {
        renderTemplate('projects-template');
        showLoader();

        try {
            const projects = await api.get('/projects/');
            state.projects = projects;

            const list = document.getElementById('all-projects-list');
            list.innerHTML = '';
            projects.forEach(project => {
                list.appendChild(createProjectCard(project));
            });
            applyTranslations();
        } catch (error) {
            console.error('Projects Load Error:', error);
        } finally {
            hideLoader();
        }
    },

    async projectDetail(projectId) {
        renderTemplate('project-detail-template');
        showLoader();

        try {
            const project = await api.get(`/projects/${projectId}`);
            const docs = await api.get(`/projects/${projectId}/documents`);

            state.selectedProject = project;

            document.getElementById('project-name-title').textContent = project.name;

            const docsList = document.getElementById('project-docs-list');
            docsList.innerHTML = '';

            if (docs.length === 0) {
                docsList.innerHTML = `<p class="empty-msg">${state.lang === 'ar' ? 'لا توجد مستندات بعد' : 'No documents yet'}</p>`;
            } else {
                docs.forEach(doc => {
                    docsList.appendChild(createDocItem(doc));
                });
            }

            // Setup Upload Zone
            setupUploadZone(projectId);

            document.getElementById('back-to-projects').onclick = () => switchView('projects');
            applyTranslations();
        } catch (error) {
            console.error('Project Detail Load Error:', error);
        } finally {
            hideLoader();
        }
    },

    async chat() {
        renderTemplate('chat-template');

        const select = document.getElementById('chat-project-select');
        const projects = await api.get('/projects/');

        projects.forEach(p => {
            const opt = document.createElement('option');
            opt.value = p.id;
            opt.textContent = p.name;
            select.appendChild(opt);
        });

        const sendBtn = document.getElementById('send-btn');
        const chatInput = document.getElementById('chat-input');

        sendBtn.onclick = handleChatSubmit;
        chatInput.onkeydown = (e) => {
            if (e.key === 'Enter' && !e.shiftKey) {
                e.preventDefault();
                handleChatSubmit();
            }
        };
        applyTranslations();
    },

    async 'bot-config'() {
        renderTemplate('bot-config-template');
        showLoader();

        try {
            const [projects, config] = await Promise.all([
                api.get('/projects/'),
                api.get('/bot/config')
            ]);

            const select = document.getElementById('bot-active-project');
            projects.forEach(p => {
                const opt = document.createElement('option');
                opt.value = p.id;
                opt.textContent = p.name;
                if (config.active_project_id == p.id) opt.selected = true;
                select.appendChild(opt);
            });

            document.getElementById('save-bot-config-btn').onclick = async () => {
                const projectId = select.value;
                if (!projectId) return;
                try {
                    await api.post('/bot/config', { active_project_id: parseInt(projectId) });
                    showNotification(i18n[state.lang].success_saved, 'success');
                } catch (e) {
                    console.error(e);
                }
            };

            document.getElementById('update-bot-profile-btn').onclick = async () => {
                const name = document.getElementById('bot-name-input').value;
                if (!name) return;
                const formData = new FormData();
                formData.append('name', name);
                try {
                    await api.post('/bot/profile', formData, true);
                    showNotification(i18n[state.lang].success_saved, 'success');
                } catch (e) {
                    console.error(e);
                }
            };

            applyTranslations();
        } catch (error) {
            console.error('Bot Config Error:', error);
        } finally {
            hideLoader();
        }
    }
};

// --- Helpers ---

function renderTemplate(templateId) {
    const template = document.getElementById(templateId);
    const clone = template.content.cloneNode(true);
    elements.viewContainer.innerHTML = '';
    elements.viewContainer.appendChild(clone);
}

function showLoader() {
    const loader = document.createElement('div');
    loader.className = 'loader-container';
    loader.innerHTML = '<div class="loader"></div>';
    elements.viewContainer.appendChild(loader);
}

function hideLoader() {
    const loader = elements.viewContainer.querySelector('.loader-container');
    if (loader) loader.remove();
}

function createProjectCard(project) {
    const card = document.createElement('div');
    card.className = 'project-card';
    card.innerHTML = `
        <h3>${project.name}</h3>
        <p>${project.description || (state.lang === 'ar' ? 'لا يوجد وصف' : 'No description')}</p>
        <div class="project-meta">
            <span><i class="far fa-calendar"></i> ${new Date(project.created_at).toLocaleDateString(state.lang === 'ar' ? 'ar-EG' : 'en-US')}</span>
            <button class="delete-project-btn" data-id="${project.id}"><i class="fas fa-trash"></i></button>
        </div>
    `;

    card.onclick = (e) => {
        if (e.target.closest('.delete-project-btn')) {
            handleDeleteProject(project.id);
            return;
        }
        switchView('projectDetail', project.id);
    };

    return card;
}

function createDocItem(doc) {
    const item = document.createElement('div');
    item.className = 'doc-item';
    const statusClass = doc.status === 'completed' ? 'status-done' : (doc.status === 'failed' ? 'status-error' : 'status-processing');
    const statusIcon = doc.status === 'completed' ? 'fa-check-circle' : (doc.status === 'failed' ? 'fa-exclamation-circle' : 'fa-spinner fa-spin');

    const statusText = {
        completed: state.lang === 'ar' ? 'مكتمل' : 'Completed',
        failed: state.lang === 'ar' ? 'فشل' : 'Failed',
        processing: state.lang === 'ar' ? 'جاري المعالجة' : 'Processing'
    };

    item.innerHTML = `
        <div class="doc-info">
            <i class="fas fa-file-pdf"></i>
            <div class="doc-details">
                <span class="doc-name">${doc.original_filename}</span>
                <span class="doc-size">${(doc.file_size / 1024).toFixed(1)} KB</span>
            </div>
        </div>
        <div class="doc-status ${statusClass}">
            <i class="fas ${statusIcon}"></i>
            <span>${statusText[doc.status] || doc.status}</span>
        </div>
        <button class="delete-doc-btn" data-id="${doc.id}"><i class="fas fa-trash"></i></button>
    `;

    item.querySelector('.delete-doc-btn').onclick = () => handleDeleteDoc(doc.id);

    return item;
}

function showNotification(message, type = 'info') {
    const toast = document.createElement('div');
    toast.className = `toast toast-${type}`;
    toast.textContent = message;
    document.body.appendChild(toast);
    setTimeout(() => toast.classList.add('show'), 100);
    setTimeout(() => {
        toast.classList.remove('show');
        setTimeout(() => toast.remove(), 300);
    }, 3000);
}

function applyTranslations() {
    const t = i18n[state.lang];
    document.querySelectorAll('[data-i18n]').forEach(el => {
        const key = el.dataset.i18n;
        if (t[key]) el.textContent = t[key];
    });

    // Update placeholders
    if (document.getElementById('new-project-name')) {
        document.getElementById('new-project-name').placeholder = t.project_name_ph;
        document.getElementById('new-project-desc').placeholder = t.project_desc_ph;
    }

    // Update Lang Button
    elements.langToggle.querySelector('.lang-code').textContent = state.lang === 'ar' ? 'EN' : 'AR';

    // Update Dir
    document.documentElement.dir = state.lang === 'ar' ? 'rtl' : 'ltr';
    document.documentElement.lang = state.lang;
}

function toggleTheme() {
    state.theme = state.theme === 'dark' ? 'light' : 'dark';
    document.body.classList.toggle('light-theme', state.theme === 'light');
    document.body.classList.toggle('dark-theme', state.theme === 'dark');

    const icon = elements.themeToggle.querySelector('i');
    icon.className = state.theme === 'dark' ? 'fas fa-moon' : 'fas fa-sun';

    localStorage.setItem('theme', state.theme);
}

function toggleLang() {
    state.lang = state.lang === 'ar' ? 'en' : 'ar';
    localStorage.setItem('lang', state.lang);
    applyTranslations();
    switchView(state.currentView, state.selectedProject ? state.selectedProject.id : null);
}

// --- Event Handlers ---

async function switchView(viewName, params = null) {
    state.currentView = viewName;

    // Update Nav
    elements.navItems.forEach(item => {
        item.classList.toggle('active', item.dataset.view === viewName);
    });

    // Render View
    if (viewName === 'projectDetail') {
        await views.projectDetail(params);
    } else if (views[viewName]) {
        await views[viewName]();
    }
}

async function handleNewProject() {
    elements.modalTitle.textContent = i18n[state.lang].create_project_btn;
    elements.modalBody.innerHTML = `
        <div class="form-group">
            <label>${state.lang === 'ar' ? 'اسم المشروع' : 'Project Name'}</label>
            <input type="text" id="new-project-name" class="form-control">
        </div>
        <div class="form-group">
            <label>${state.lang === 'ar' ? 'الوصف' : 'Description'}</label>
            <textarea id="new-project-desc" class="form-control"></textarea>
        </div>
        <button id="save-project-btn" class="btn btn-primary w-100 mt-4">${i18n[state.lang].create_project_btn}</button>
    `;
    applyTranslations();

    elements.modalOverlay.classList.remove('hidden');

    document.getElementById('save-project-btn').onclick = async () => {
        const name = document.getElementById('new-project-name').value;
        const description = document.getElementById('new-project-desc').value;

        if (!name) {
            showNotification(state.lang === 'ar' ? 'يرجى إدخال اسم المشروع' : 'Please enter project name', 'warning');
            return;
        }

        try {
            await api.post('/projects/', { name, description });
            showNotification(i18n[state.lang].success_saved, 'success');
            elements.modalOverlay.classList.add('hidden');
            switchView(state.currentView); // Refresh current view
        } catch (error) {
            console.error('Create Project Error:', error);
        }
    };
}

async function handleDeleteProject(id) {
    if (confirm(i18n[state.lang].delete_confirm)) {
        try {
            await api.delete(`/projects/${id}`);
            showNotification(i18n[state.lang].success_saved, 'success');
            switchView(state.currentView);
        } catch (error) {
            console.error('Delete Project Error:', error);
        }
    }
}

async function handleDeleteDoc(id) {
    if (confirm(i18n[state.lang].delete_confirm)) {
        try {
            await api.delete(`/documents/${id}`);
            showNotification(i18n[state.lang].success_saved, 'success');
            if (state.selectedProject) {
                switchView('projectDetail', state.selectedProject.id);
            }
        } catch (error) {
            console.error('Delete Doc Error:', error);
        }
    }
}

async function handleChatSubmit() {
    const input = document.getElementById('chat-input');
    const projectSelect = document.getElementById('chat-project-select');
    const langSelect = document.getElementById('chat-lang');

    const query = input.value.trim();
    const projectId = projectSelect.value;
    const language = langSelect.value;

    if (!query) return;
    if (!projectId) {
        showNotification(state.lang === 'ar' ? 'يرجى اختيار مشروع أولاً' : 'Select a project first', 'warning');
        return;
    }

    addChatMessage('user', query);
    input.value = '';

    const thinkingId = addChatMessage('bot', state.lang === 'ar' ? 'جاري التفكير...' : 'Thinking...', true);

    try {
        const result = await api.post(`/projects/${projectId}/query`, {
            query,
            language,
            top_k: 5
        });

        updateChatMessage(thinkingId, result.answer, result.sources);
    } catch (error) {
        updateChatMessage(thinkingId, i18n[state.lang].error_generic);
    }
}

function addChatMessage(role, text, isThinking = false) {
    const messagesContainer = document.getElementById('chat-messages');
    const welcome = messagesContainer.querySelector('.welcome-msg');
    if (welcome) welcome.remove();

    const id = Date.now();
    const msgDiv = document.createElement('div');
    msgDiv.className = `chat-msg ${role}-msg`;
    msgDiv.id = `msg-${id}`;
    msgDiv.innerHTML = `
        <div class="msg-avatar">${role === 'user' ? 'U' : '<i class="fas fa-robot"></i>'}</div>
        <div class="msg-content">
            <div class="text">${text}</div>
            ${isThinking ? '<div class="typing-indicator"><span></span><span></span><span></span></div>' : ''}
        </div>
    `;
    messagesContainer.appendChild(msgDiv);
    messagesContainer.scrollTop = messagesContainer.scrollHeight;
    return id;
}

function updateChatMessage(id, text, sources = null) {
    const msgDiv = document.getElementById(`msg-${id}`);
    if (!msgDiv) return;

    const content = msgDiv.querySelector('.text');
    const indicator = msgDiv.querySelector('.typing-indicator');
    if (indicator) indicator.remove();

    content.textContent = text;

    if (sources && sources.length > 0) {
        const sourcesDiv = document.createElement('div');
        sourcesDiv.className = 'msg-sources';
        sourcesDiv.innerHTML = `<strong>${state.lang === 'ar' ? 'المصادر:' : 'Sources:'}</strong>`;
        const list = document.createElement('ul');
        sources.slice(0, 3).forEach(s => {
            const li = document.createElement('li');
            li.textContent = `${s.document_name} (${(s.similarity * 100).toFixed(1)}%)`;
            list.appendChild(li);
        });
        sourcesDiv.appendChild(list);
        msgDiv.querySelector('.msg-content').appendChild(sourcesDiv);
    }

    const container = document.getElementById('chat-messages');
    container.scrollTop = container.scrollHeight;
}

function setupUploadZone(projectId) {
    const zone = document.getElementById('upload-zone');
    const input = document.getElementById('file-input');

    zone.onclick = () => input.click();

    zone.ondragover = (e) => {
        e.preventDefault();
        zone.classList.add('dragover');
    };

    zone.ondragleave = () => zone.classList.remove('dragover');

    zone.ondrop = (e) => {
        e.preventDefault();
        zone.classList.remove('dragover');
        handleFiles(e.dataTransfer.files, projectId);
    };

    input.onchange = () => handleFiles(input.files, projectId);
}

async function handleFiles(files, projectId) {
    for (const file of files) {
        const formData = new FormData();
        formData.append('file', file);

        showNotification(`${state.lang === 'ar' ? 'جاري رفع' : 'Uploading'} ${file.name}...`, 'info');

        try {
            await api.post(`/projects/${projectId}/documents`, formData, true);
            showNotification(`${state.lang === 'ar' ? 'تم رفع' : 'Uploaded'} ${file.name}`, 'success');
            switchView('projectDetail', projectId); // Refresh list
        } catch (error) {
            console.error('Upload Error:', error);
        }
    }
}

// --- Initialization ---

document.addEventListener('DOMContentLoaded', () => {
    // Nav Clicks
    elements.navItems.forEach(item => {
        item.onclick = () => switchView(item.dataset.view);
    });

    // New Project Click
    elements.newProjectBtn.onclick = handleNewProject;

    // Close Modal
    elements.closeModalBtn.onclick = () => elements.modalOverlay.classList.add('hidden');
    elements.modalOverlay.onclick = (e) => {
        if (e.target === elements.modalOverlay) elements.modalOverlay.classList.add('hidden');
    };

    // Theme & Lang
    elements.themeToggle.onclick = toggleTheme;
    elements.langToggle.onclick = toggleLang;

    // Init State
    if (state.theme === 'light') {
        document.body.classList.add('light-theme');
        document.body.classList.remove('dark-theme');
        elements.themeToggle.querySelector('i').className = 'fas fa-sun';
    }

    // Initial View
    applyTranslations();
    switchView('dashboard');
});

----- END FILE -----

----- FILE: frontend\index.html -----
size: 11689 bytes | mtime: 2025-12-28T12:51:36.623137

<!DOCTYPE html>
<html lang="ar" dir="rtl">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>RAGMind | لوحة التحكم الذكية</title>
    <!-- Fonts -->
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link
        href="https://fonts.googleapis.com/css2?family=Cairo:wght@300;400;600;700&family=Inter:wght@300;400;600;700&display=swap"
        rel="stylesheet">
    <!-- Icons -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
    <!-- Custom Styles -->
    <link rel="stylesheet" href="style.css">
</head>

<body class="dark-theme">
    <div class="app-container">
        <!-- Sidebar -->
        <aside class="sidebar">
            <div class="sidebar-header">
                <div class="logo">
                    <i class="fas fa-brain-circuit"></i>
                    <span>RAGMind</span>
                </div>
            </div>

            <nav class="sidebar-nav">
                <ul>
                    <li class="active" data-view="dashboard">
                        <i class="fas fa-chart-pie"></i>
                        <span data-i18n="nav_dashboard">لوحة التحكم</span>
                    </li>
                    <li data-view="projects">
                        <i class="fas fa-folder-tree"></i>
                        <span data-i18n="nav_projects">المشاريع</span>
                    </li>
                    <li data-view="chat">
                        <i class="fas fa-comment-dots"></i>
                        <span data-i18n="nav_chat">المحادثة الذكية</span>
                    </li>
                    <li data-view="bot-config">
                        <i class="fas fa-robot"></i>
                        <span data-i18n="nav_bot">إعدادات البوت</span>
                    </li>
                </ul>
            </nav>

            <div class="sidebar-footer">
                <div class="user-info">
                    <div class="avatar">A</div>
                    <div class="details">
                        <p class="name">المستخدم</p>
                        <p class="status">متصل</p>
                    </div>
                </div>
                <button id="lang-toggle" class="icon-btn" title="Switch Language">
                    <span class="lang-code">EN</span>
                </button>
                <button id="theme-toggle" class="icon-btn">
                    <i class="fas fa-moon"></i>
                </button>
            </div>
        </aside>

        <!-- Main Content -->
        <main class="main-content">
            <header class="top-bar">
                <div class="search-bar">
                    <i class="fas fa-search"></i>
                    <input type="text" placeholder="ابحث عن مشروع أو مستند...">
                </div>
                <div class="actions">
                    <button id="new-project-btn" class="btn btn-primary">
                        <i class="fas fa-plus"></i>
                        <span data-i18n="create_project_btn">مشروع جديد</span>
                    </button>
                </div>
            </header>

            <div id="view-container" class="view-container">
                <!-- Views will be injected here -->
                <div class="loader-container">
                    <div class="loader"></div>
                </div>
            </div>
        </main>
    </div>

    <!-- Modals -->
    <div id="modal-overlay" class="modal-overlay hidden">
        <div class="modal">
            <div class="modal-header">
                <h3 id="modal-title">عنوان النافذة</h3>
                <button class="close-modal"><i class="fas fa-times"></i></button>
            </div>
            <div id="modal-body" class="modal-body">
                <!-- Modal content -->
            </div>
        </div>
    </div>

    <!-- Templates -->
    <template id="dashboard-template">
        <div class="dashboard-view">
            <h1 class="view-title" data-i18n="welcome_title">مرحباً بك في RAGMind</h1>
            <div class="stats-grid">
                <div class="stat-card">
                    <div class="icon"><i class="fas fa-folder"></i></div>
                    <div class="info">
                        <span class="label" data-i18n="stat_projects">إجمالي المشاريع</span>
                        <span class="value" id="stat-projects">0</span>
                    </div>
                </div>
                <div class="stat-card">
                    <div class="icon"><i class="fas fa-file-alt"></i></div>
                    <div class="info">
                        <span class="label" data-i18n="stat_docs">المستندات</span>
                        <span class="value" id="stat-docs">0</span>
                    </div>
                </div>
                <div class="stat-card">
                    <div class="icon"><i class="fas fa-microchip"></i></div>
                    <div class="info">
                        <span class="label" data-i18n="stat_chunks">القطع النصية</span>
                        <span class="value" id="stat-chunks">0</span>
                    </div>
                </div>
            </div>

            <section class="recent-projects">
                <div class="section-header">
                    <h2 data-i18n="recent_projects">المشاريع الأخيرة</h2>
                    <a href="#" class="link" data-i18n="view_all">عرض الكل</a>
                </div>
                <div class="projects-grid" id="recent-projects-list">
                    <!-- Projects will be injected here -->
                </div>
            </section>
        </div>
    </template>

    <template id="projects-template">
        <div class="projects-view">
            <div class="section-header">
                <h1 class="view-title" data-i18n="your_projects">مشاريعك</h1>
            </div>
            <div class="projects-grid" id="all-projects-list">
                <!-- Projects will be injected here -->
            </div>
        </div>
    </template>

    <template id="chat-template">
        <div class="chat-view">
            <div class="chat-sidebar">
                <h3 data-i18n="select_project_ph">اختر مشروعاً</h3>
                <select id="chat-project-select" class="form-control">
                    <option value="" data-i18n="select_project_ph">اختر مشروعاً للبدء...</option>
                </select>
                <div class="chat-settings">
                    <label>اللغة:</label>
                    <select id="chat-lang" class="form-control">
                        <option value="ar">العربية</option>
                        <option value="en">English</option>
                    </select>
                </div>
            </div>
            <div class="chat-main">
                <div class="chat-messages" id="chat-messages">
                    <div class="welcome-msg">
                        <i class="fas fa-robot"></i>
                        <h2>كيف يمكنني مساعدتك اليوم؟</h2>
                        <p>اختر مشروعاً من القائمة الجانبية وابدأ في طرح الأسئلة حول مستنداتك.</p>
                    </div>
                </div>
                <div class="chat-input-container">
                    <div class="chat-input-wrapper">
                        <textarea id="chat-input" placeholder="اسأل أي شيء حول مستنداتك..." rows="1"></textarea>
                        <button id="send-btn" class="send-btn">
                            <i class="fas fa-paper-plane"></i>
                        </button>
                    </div>
                </div>
            </div>
        </div>
    </template>

    <template id="project-detail-template">
        <div class="project-detail-view">
            <div class="project-header">
                <button class="back-btn" id="back-to-projects"><i class="fas fa-arrow-right"></i></button>
                <h1 id="project-name-title">اسم المشروع</h1>
            </div>

            <div class="project-content-grid">
                <div class="upload-section">
                    <h3 data-i18n="upload_title">رفع مستندات جديدة</h3>
                    <div class="upload-zone" id="upload-zone">
                        <i class="fas fa-cloud-upload-alt"></i>
                        <p data-i18n="upload_desc">اسحب الملفات هنا أو اضغط للاختيار</p>
                        <span class="hint">يدعم PDF, TXT, DOCX</span>
                        <input type="file" id="file-input" multiple hidden>
                    </div>
                    <div id="upload-progress-list" class="upload-progress-list"></div>
                </div>

                <div class="documents-section">
                    <h3 data-i18n="docs_title">المستندات الحالية</h3>
                    <div class="documents-list" id="project-docs-list">
                        <!-- Documents will be injected here -->
                    </div>
                </div>
            </div>
        </div>
    </template>

    <template id="bot-config-template">
        <div class="bot-config-view">
            <h1 class="view-title" data-i18n="bot_settings_title">إعدادات بوت التليجرام</h1>

            <div class="config-card">
                <div class="config-section">
                    <h3 data-i18n="bot_active_project">المشروع النشط</h3>
                    <p class="config-desc" data-i18n="bot_active_project_desc">اختر المشروع الذي سيقوم البوت بالإجابة
                        منه.</p>
                    <select id="bot-active-project" class="form-control">
                        <option value="">اختر مشروعاً...</option>
                    </select>
                    <button id="save-bot-config-btn" class="btn btn-primary mt-4">
                        <i class="fas fa-save"></i>
                        <span data-i18n="save_settings">حفظ الإعدادات</span>
                    </button>
                </div>

                <div class="config-section mt-4">
                    <h3 data-i18n="bot_profile">ملف البوت</h3>
                    <p class="config-desc" data-i18n="bot_profile_desc">تحديث اسم البوت على تليجرام.</p>

                    <div class="form-group">
                        <label data-i18n="bot_name">اسم البوت</label>
                        <input type="text" id="bot-name-input" class="form-control" placeholder="RAGMind Bot">
                    </div>

                    <button id="update-bot-profile-btn" class="btn btn-primary mt-4">
                        <i class="fas fa-user-edit"></i>
                        <span data-i18n="update_profile">تحديث الملف الشخصي</span>
                    </button>
                </div>
            </div>
        </div>
    </template>

    <!-- Scripts -->
    <script src="app.js"></script>
</body>

</html>
----- END FILE -----

----- FILE: frontend\style.css -----
size: 14685 bytes | mtime: 2025-12-28T12:51:36.624137

:root {
    /* Color Palette - Premium Dark Mode */
    --bg-main: #0a0b10;
    --bg-sidebar: #11131a;
    --bg-card: rgba(255, 255, 255, 0.03);
    --bg-card-hover: rgba(255, 255, 255, 0.06);
    --accent-primary: #6366f1;
    --accent-secondary: #8b5cf6;
    --text-main: #f8fafc;
    --text-muted: #94a3b8;
    --border-color: rgba(255, 255, 255, 0.08);
    --glass-bg: rgba(255, 255, 255, 0.02);
    --glass-border: rgba(255, 255, 255, 0.05);
    --success: #10b981;
    --error: #ef4444;
    --warning: #f59e0b;

    /* Transitions */
    --transition-fast: 0.2s ease;
    --transition-slow: 0.4s cubic-bezier(0.4, 0, 0.2, 1);
}

/* Light Mode Overrides */
body.light-theme {
    --bg-main: #f8fafc;
    --bg-sidebar: #ffffff;
    --bg-card: #ffffff;
    --bg-card-hover: #f1f5f9;
    --text-main: #0f172a;
    --text-muted: #64748b;
    --border-color: #e2e8f0;
    --glass-bg: rgba(255, 255, 255, 0.8);
    --glass-border: #e2e8f0;
}

body.light-theme .main-content {
    background: radial-gradient(circle at top right, rgba(99, 102, 241, 0.1), transparent);
}

body.light-theme .stat-card {
    box-shadow: 0 4px 6px -1px rgba(0, 0, 0, 0.1), 0 2px 4px -1px rgba(0, 0, 0, 0.06);
}

body.light-theme .project-card {
    box-shadow: 0 1px 3px 0 rgba(0, 0, 0, 0.1), 0 1px 2px 0 rgba(0, 0, 0, 0.06);
}

* {
    margin: 0;
    padding: 0;
    box-sizing: border-box;
}

body {
    font-family: 'Inter', 'Cairo', sans-serif;
    background-color: var(--bg-main);
    color: var(--text-main);
    overflow: hidden;
    line-height: 1.6;
}

/* App Layout */
.app-container {
    display: flex;
    height: 100vh;
    width: 100vw;
}

/* Sidebar */
.sidebar {
    width: 280px;
    background-color: var(--bg-sidebar);
    border-left: 1px solid var(--border-color);
    display: flex;
    flex-direction: column;
    padding: 24px;
    z-index: 100;
}

.sidebar-header .logo {
    display: flex;
    align-items: center;
    gap: 12px;
    font-size: 24px;
    font-weight: 700;
    color: var(--accent-primary);
    margin-bottom: 48px;
}

.sidebar-nav ul {
    list-style: none;
}

.sidebar-nav li {
    display: flex;
    align-items: center;
    gap: 12px;
    padding: 14px 18px;
    border-radius: 12px;
    margin-bottom: 8px;
    cursor: pointer;
    color: var(--text-muted);
    transition: var(--transition-fast);
}

.sidebar-nav li:hover {
    background-color: var(--bg-card-hover);
    color: var(--text-main);
}

.sidebar-nav li.active {
    background-color: var(--accent-primary);
    color: white;
    box-shadow: 0 4px 12px rgba(99, 102, 241, 0.3);
}

.sidebar-footer {
    margin-top: auto;
    display: flex;
    align-items: center;
    justify-content: space-between;
    padding-top: 24px;
    border-top: 1px solid var(--border-color);
}

.user-info {
    display: flex;
    align-items: center;
    gap: 12px;
}

.avatar {
    width: 40px;
    height: 40px;
    background: linear-gradient(135deg, var(--accent-primary), var(--accent-secondary));
    border-radius: 50%;
    display: flex;
    align-items: center;
    justify-content: center;
    font-weight: 600;
}

.user-info .name {
    font-size: 14px;
    font-weight: 600;
}

.user-info .status {
    font-size: 12px;
    color: var(--success);
}

/* Main Content */
.main-content {
    flex: 1;
    display: flex;
    flex-direction: column;
    overflow: hidden;
    background: radial-gradient(circle at top right, rgba(99, 102, 241, 0.05), transparent);
}

.top-bar {
    height: 80px;
    padding: 0 40px;
    display: flex;
    align-items: center;
    justify-content: space-between;
    border-bottom: 1px solid var(--border-color);
}

.search-bar {
    display: flex;
    align-items: center;
    background-color: var(--bg-card);
    padding: 10px 20px;
    border-radius: 30px;
    width: 400px;
    border: 1px solid var(--border-color);
}

.search-bar input {
    background: none;
    border: none;
    color: var(--text-main);
    margin-right: 12px;
    width: 100%;
    outline: none;
}

.view-container {
    flex: 1;
    padding: 40px;
    overflow-y: auto;
}

/* Dashboard */
.view-title {
    font-size: 32px;
    font-weight: 700;
    margin-bottom: 32px;
}

.stats-grid {
    display: grid;
    grid-template-columns: repeat(auto-fit, minmax(240px, 1fr));
    gap: 24px;
    margin-bottom: 48px;
}

.stat-card {
    background: var(--glass-bg);
    backdrop-filter: blur(10px);
    border: 1px solid var(--glass-border);
    padding: 24px;
    border-radius: 20px;
    display: flex;
    align-items: center;
    gap: 20px;
    transition: var(--transition-slow);
}

.stat-card:hover {
    transform: translateY(-5px);
    border-color: var(--accent-primary);
}

.stat-card .icon {
    width: 56px;
    height: 56px;
    background: rgba(99, 102, 241, 0.1);
    border-radius: 16px;
    display: flex;
    align-items: center;
    justify-content: center;
    font-size: 24px;
    color: var(--accent-primary);
}

.stat-card .label {
    display: block;
    color: var(--text-muted);
    font-size: 14px;
}

.stat-card .value {
    font-size: 28px;
    font-weight: 700;
}

/* Projects Grid */
.projects-grid {
    display: grid;
    grid-template-columns: repeat(auto-fill, minmax(300px, 1fr));
    gap: 24px;
}

.project-card {
    background: var(--bg-card);
    border: 1px solid var(--border-color);
    border-radius: 20px;
    padding: 24px;
    cursor: pointer;
    transition: var(--transition-fast);
    position: relative;
    overflow: hidden;
}

.project-card:hover {
    background: var(--bg-card-hover);
    border-color: var(--accent-primary);
}

.project-card h3 {
    font-size: 20px;
    margin-bottom: 12px;
}

.project-card p {
    color: var(--text-muted);
    font-size: 14px;
    margin-bottom: 20px;
    display: -webkit-box;
    -webkit-line-clamp: 2;
    -webkit-box-orient: vertical;
    overflow: hidden;
}

.project-meta {
    display: flex;
    justify-content: space-between;
    font-size: 12px;
    color: var(--text-muted);
}

/* Chat View */
.chat-view {
    display: flex;
    height: 100%;
    gap: 24px;
}

.chat-sidebar {
    width: 300px;
    background: var(--bg-card);
    border-radius: 20px;
    padding: 24px;
    display: flex;
    flex-direction: column;
    gap: 20px;
}

.chat-main {
    flex: 1;
    display: flex;
    flex-direction: column;
    background: var(--bg-card);
    border-radius: 20px;
    overflow: hidden;
}

.chat-messages {
    flex: 1;
    padding: 32px;
    overflow-y: auto;
    display: flex;
    flex-direction: column;
    gap: 24px;
}

.welcome-msg {
    text-align: center;
    margin-top: 100px;
    color: var(--text-muted);
}

.welcome-msg i {
    font-size: 64px;
    color: var(--accent-primary);
    margin-bottom: 24px;
}

.chat-input-container {
    padding: 24px 32px;
    background: rgba(0, 0, 0, 0.2);
}

.chat-input-wrapper {
    background: var(--bg-main);
    border: 1px solid var(--border-color);
    border-radius: 16px;
    padding: 12px 20px;
    display: flex;
    align-items: center;
    gap: 16px;
}

.chat-input-wrapper textarea {
    flex: 1;
    background: none;
    border: none;
    color: var(--text-main);
    resize: none;
    outline: none;
    font-family: inherit;
    font-size: 16px;
}

.send-btn {
    width: 44px;
    height: 44px;
    background: var(--accent-primary);
    border: none;
    border-radius: 12px;
    color: white;
    cursor: pointer;
    transition: var(--transition-fast);
}

.send-btn:hover {
    transform: scale(1.05);
    background: var(--accent-secondary);
}

/* Chat Messages */
.chat-msg {
    display: flex;
    gap: 16px;
    max-width: 85%;
    animation: fadeIn 0.3s ease;
}

.user-msg {
    align-self: flex-end;
    flex-direction: row-reverse;
}

.msg-avatar {
    width: 36px;
    height: 36px;
    background: var(--bg-card-hover);
    border-radius: 10px;
    display: flex;
    align-items: center;
    justify-content: center;
    font-weight: 700;
    flex-shrink: 0;
}

.user-msg .msg-avatar {
    background: var(--accent-primary);
}

.msg-content {
    background: var(--bg-card);
    padding: 16px 20px;
    border-radius: 20px;
    border: 1px solid var(--border-color);
}

.user-msg .msg-content {
    background: var(--accent-primary);
    border: none;
    border-bottom-right-radius: 4px;
}

.bot-msg .msg-content {
    border-bottom-left-radius: 4px;
}

.msg-sources {
    margin-top: 12px;
    padding-top: 12px;
    border-top: 1px solid var(--border-color);
    font-size: 13px;
}

.msg-sources ul {
    list-style: none;
    margin-top: 4px;
}

.msg-sources li {
    color: var(--text-muted);
    display: flex;
    align-items: center;
    gap: 8px;
}

.msg-sources li::before {
    content: '•';
    color: var(--accent-primary);
}

/* Typing Indicator */
.typing-indicator {
    display: flex;
    gap: 4px;
    padding: 4px 0;
}

.typing-indicator span {
    width: 6px;
    height: 6px;
    background: var(--text-muted);
    border-radius: 50%;
    animation: bounce 1.4s infinite ease-in-out both;
}

.typing-indicator span:nth-child(1) {
    animation-delay: -0.32s;
}

.typing-indicator span:nth-child(2) {
    animation-delay: -0.16s;
}

@keyframes bounce {

    0%,
    80%,
    100% {
        transform: scale(0);
    }

    40% {
        transform: scale(1.0);
    }
}

/* Document Items */
.doc-item {
    background: var(--bg-card);
    border: 1px solid var(--border-color);
    padding: 16px;
    border-radius: 16px;
    display: flex;
    align-items: center;
    justify-content: space-between;
    margin-bottom: 12px;
    transition: var(--transition-fast);
}

.doc-item:hover {
    border-color: var(--accent-primary);
    background: var(--bg-card-hover);
}

.doc-info {
    display: flex;
    align-items: center;
    gap: 16px;
}

.doc-info i {
    font-size: 24px;
    color: var(--error);
}

.doc-details {
    display: flex;
    flex-direction: column;
}

.doc-name {
    font-weight: 600;
    font-size: 14px;
}

.doc-size {
    font-size: 12px;
    color: var(--text-muted);
}

.doc-status {
    display: flex;
    align-items: center;
    gap: 8px;
    font-size: 12px;
    padding: 4px 12px;
    border-radius: 20px;
}

.status-done {
    background: rgba(16, 185, 129, 0.1);
    color: var(--success);
}

.status-processing {
    background: rgba(245, 158, 11, 0.1);
    color: var(--warning);
}

.status-error {
    background: rgba(239, 68, 68, 0.1);
    color: var(--error);
}

/* Project Detail Layout */
.project-content-grid {
    display: grid;
    grid-template-columns: 1fr 1.5fr;
    gap: 32px;
}

.upload-zone {
    border: 2px dashed var(--border-color);
    border-radius: 20px;
    padding: 40px;
    text-align: center;
    cursor: pointer;
    transition: var(--transition-fast);
}

.upload-zone:hover,
.upload-zone.dragover {
    border-color: var(--accent-primary);
    background: rgba(99, 102, 241, 0.05);
}

.upload-zone i {
    font-size: 48px;
    color: var(--accent-primary);
    margin-bottom: 16px;
}

/* Buttons */
.btn {
    padding: 10px 24px;
    border-radius: 12px;
    border: none;
    font-weight: 600;
    cursor: pointer;
    display: flex;
    align-items: center;
    gap: 10px;
    transition: var(--transition-fast);
}

.btn-primary {
    background: var(--accent-primary);
    color: white;
}

.btn-primary:hover {
    background: var(--accent-secondary);
    box-shadow: 0 4px 15px rgba(99, 102, 241, 0.4);
}

/* Modal */
.modal-overlay {
    position: fixed;
    top: 0;
    left: 0;
    width: 100%;
    height: 100%;
    background: rgba(0, 0, 0, 0.8);
    backdrop-filter: blur(5px);
    display: flex;
    align-items: center;
    justify-content: center;
    z-index: 1000;
    transition: var(--transition-fast);
}

.modal {
    background: var(--bg-sidebar);
    width: 500px;
    border-radius: 24px;
    padding: 32px;
    border: 1px solid var(--border-color);
}

.hidden {
    display: none;
    opacity: 0;
    pointer-events: none;
}

/* Loader */
.loader-container {
    display: flex;
    justify-content: center;
    align-items: center;
    height: 100%;
}

.loader {
    width: 48px;
    height: 48px;
    border: 5px solid var(--bg-card);
    border-bottom-color: var(--accent-primary);
    border-radius: 50%;
    animation: rotation 1s linear infinite;
}

@keyframes rotation {
    0% {
        transform: rotate(0deg);
    }

    100% {
        transform: rotate(360deg);
    }
}

/* Toasts */
.toast {
    position: fixed;
    bottom: 32px;
    left: 50%;
    transform: translateX(-50%) translateY(100px);
    padding: 12px 24px;
    border-radius: 12px;
    background: var(--bg-sidebar);
    border: 1px solid var(--border-color);
    color: var(--text-main);
    z-index: 2000;
    transition: var(--transition-slow);
    box-shadow: 0 10px 30px rgba(0, 0, 0, 0.5);
}

.toast.show {
    transform: translateX(-50%) translateY(0);
}

.toast-success {
    border-left: 4px solid var(--success);
}

.toast-error {
    border-left: 4px solid var(--error);
}

.toast-warning {
    border-left: 4px solid var(--warning);
}

/* Custom Scrollbar */
::-webkit-scrollbar {
    width: 6px;
}

::-webkit-scrollbar-track {
    background: transparent;
}

::-webkit-scrollbar-thumb {
    background: var(--border-color);
    border-radius: 10px;
}

::-webkit-scrollbar-thumb:hover {
    background: var(--text-muted);
}

/* Forms */
.form-control {
    width: 100%;
    background: var(--bg-main);
    border: 1px solid var(--border-color);
    padding: 12px 16px;
    border-radius: 10px;
    color: var(--text-main);
    outline: none;
}

.form-control:focus {
    border-color: var(--accent-primary);
}

/* Animations */
@keyframes fadeIn {
    from {
        opacity: 0;
        transform: translateY(10px);
    }

    to {
        opacity: 1;
        transform: translateY(0);
    }
}

/* Utilities */
.w-100 {
    width: 100%;
}

.mt-4 {
    margin-top: 16px;
}

.empty-msg {
    text-align: center;
    color: var(--text-muted);
    padding: 40px;
}
----- END FILE -----

----- FILE: GITHUB_GUIDE.md -----
size: 5589 bytes | mtime: 2025-12-28T12:51:36.563616

# 🚀 دليل رفع المشروع على GitHub

## الخطوات المطلوبة

### 1️⃣ إنشاء Repository على GitHub

1. افتح [github.com](https://github.com) وسجل دخول
2. اضغط على **"+"** في الأعلى ثم **"New repository"**
3. املأ المعلومات:
   - **Repository name**: `RAGMind` (أو أي اسم تريده)
   - **Description**: `Intelligent Document Q&A System using RAG`
   - **Public** أو **Private** (اختر حسب رغبتك)
   - ❌ **لا تختار** "Initialize with README" (لأن عندنا README جاهز)
   - ❌ **لا تختار** .gitignore أو license (لأن عندنا ملفات جاهزة)
4. اضغط **"Create repository"**

### 2️⃣ نسخ رابط الـ Repository

بعد إنشاء الـ Repository، هتلاقي صفحة فيها أوامر. انسخ الرابط اللي شكله كده:
```
https://github.com/ZozElwakil/RAGMind.git
```

### 3️⃣ تشغيل الأوامر على جهازك

#### الطريقة الأولى: استخدام ملف `push_to_github.bat` (أسهل طريقة) ⭐

1. افتح ملف `push_to_github.bat`
2. غير الرابط في السطر المكتوب فيه:
   ```bat
   set REPO_URL=https://github.com/ZozElwakil/RAGMind.git
   ```
   حط الرابط بتاع الـ Repository اللي عملته
3. احفظ الملف
4. شغل الملف بـ double-click
5. خلاص! المشروع هيتحمل على GitHub تلقائياً

#### الطريقة الثانية: الأوامر اليدوية

افتح **Git Bash** أو **Command Prompt** في مجلد المشروع وشغل الأوامر دي بالترتيب:

```bash
# 1. تهيئة Git في المشروع
git init

# 2. إضافة جميع الملفات
git add .

# 3. عمل Commit أول
git commit -m "Initial commit: RAGMind - Intelligent Document Q&A System"

# 4. تسمية البرانش الرئيسي
git branch -M main

# 5. ربط المشروع بالـ Repository (غير الرابط بتاعك)
git remote add origin https://github.com/ZozElwakil/RAGMind.git

# 6. رفع الملفات على GitHub
git push -u origin main
```

### 4️⃣ إدخال بيانات GitHub

لما يطلب منك Username و Password:
- **Username**: اسم المستخدم بتاعك على GitHub
- **Password**: استخدم **Personal Access Token** مش الباسورد العادي

#### كيفية الحصول على Personal Access Token:

1. روح على GitHub → Settings → Developer settings
2. اختر **Personal access tokens** → **Tokens (classic)**
3. اضغط **Generate new token** → **Generate new token (classic)**
4. املأ المعلومات:
   - **Note**: `RAGMind Upload`
   - **Expiration**: اختر المدة المناسبة
   - **Scopes**: اختار **repo** (كل الصلاحيات بتاعته)
5. اضغط **Generate token**
6. **انسخ الـ Token وحفظه** (مش هتشوفه تاني!)
7. استخدم الـ Token كـ Password

### 5️⃣ التحقق من النجاح

بعد ما تخلص، افتح الرابط:
```
https://github.com/ZozElwakil/RAGMind
```

المفروض تشوف جميع ملفات المشروع موجودة! 🎉

---

## 🔄 تحديث المشروع على GitHub لاحقاً

لو عملت تعديلات على المشروع وعايز ترفعها على GitHub:

```bash
# 1. إضافة التعديلات الجديدة
git add .

# 2. عمل Commit للتعديلات
git commit -m "وصف التعديلات اللي عملتها"

# 3. رفع التعديلات
git push
```

أو استخدم ملف `update_github.bat` الموجود في المشروع.

---

## ❌ حل المشاكل الشائعة

### المشكلة: `fatal: not a git repository`
الحل: شغل الأمر:
```bash
git init
```

### المشكلة: `Authentication failed`
الحل: تأكد إنك بتستخدم Personal Access Token مش الباسورد العادي

### المشكلة: `failed to push some refs`
الحل: شغل الأمر:
```bash
git pull origin main --rebase
git push
```

### المشكلة: الملفات الحساسة (.env) موجودة في Git
الحل: لا تقلق! ملف `.gitignore` موجود ومانع رفع الملفات الحساسة

---

## 📋 الملفات اللي هتتحمل على GitHub

✅ سيتم رفع:
- جميع ملفات الكود (backend/, frontend/, telegram_bot/)
- ملفات الإعدادات (.env.example, setup.bat)
- التوثيق (README.md, LICENSE)
- .gitignore

❌ لن يتم رفع (محمية بـ .gitignore):
- .env (الملف اللي فيه API keys)
- venv/ (البيئة الافتراضية)
- uploads/ (الملفات المرفوعة)
- qdrant_data/ (بيانات Qdrant)
- __pycache__/ (ملفات Python المؤقتة)
- *.log (ملفات السجلات)

---

## 🎯 نصائح

1. **الأمان**: تأكد إن ملف `.env` مش موجود في Git باستخدام الأمر:
   ```bash
   git status
   ```
   لو لقيته موجود، احذفه من Git بالأمر:
   ```bash
   git rm --cached .env
   ```

2. **التوثيق**: الـ README.md جاهز وشكله احترافي على GitHub

3. **الترخيص**: ملف LICENSE موجود (MIT License)

4. **البيئة المحلية**: ملف `.env.example` موجود كمثال للآخرين

---

**بالتوفيق! 🚀**

----- END FILE -----

----- FILE: health_check_utf8.json -----
size: 138 bytes | mtime: 2025-12-28T12:51:36.624137

﻿{
    "status":  "healthy",
    "database":  "connected",
    "llm_provider":  "gemini",
    "vector_db_provider":  "pgvector"
}

----- END FILE -----

----- FILE: push_to_github.bat -----
size: 5118 bytes | mtime: 2025-12-28T18:16:01.984524

@echo off
chcp 65001 >nul
color 0B
echo ========================================
echo    RAGMind - Push to GitHub
echo    Push project to GitHub
echo ========================================
echo.
echo [DEBUG] Script started at %DATE% %TIME%
echo [DEBUG] Current directory: "%CD%"

:: Repository URL - CHANGE THIS!
set REPO_URL=https://github.com/ZozElwakil/RAGMind.git

echo [WARNING] IMPORTANT: Make sure to change REPO_URL in this file!
echo     Current URL: %REPO_URL%
echo.
choice /C YN /M "Have you changed the URL to your own repository?"
if errorlevel 2 (
    echo [WARNING] Please edit the file and change REPO_URL
    echo [DEBUG] User chose not to confirm repository URL
    pause
    exit /b 1
)
echo [DEBUG] Repository URL confirmed
echo.

echo ========================================
echo 1. Initialize Git Repository
echo ========================================
echo [DEBUG] Checking for existing Git repository...

:: Check if already initialized
if exist ".git\" (
    echo [✓] Git repository already exists
    echo [DEBUG] .git directory found
) else (
    echo [INFO] Initializing Git...
    echo [DEBUG] Running: git init
    git init
    if errorlevel 1 (
        echo [ERROR] Failed to initialize Git!
        echo Make sure Git is installed: https://git-scm.com/
        echo [DEBUG] git init failed with errorlevel %errorlevel%
        pause
        exit /b 1
    )
    echo [✓] Git initialized successfully
    echo [DEBUG] Git repository created
)
echo.

echo ========================================
echo 2. Adding All Files
echo ========================================
echo [DEBUG] Running: git add .
git add .
if errorlevel 1 (
    echo [ERROR] Failed to add files!
    echo [DEBUG] git add failed with errorlevel %errorlevel%
    pause
    exit /b 1
)
echo [✓] All files added
echo [DEBUG] Files staged for commit
echo.

echo ========================================
echo 3. Creating Commit
echo ========================================
echo [DEBUG] Running: git commit -m "Initial commit: RAGMind - Intelligent Document Q&A System"
git commit -m "Initial commit: RAGMind - Intelligent Document Q&A System"
if errorlevel 1 (
    echo [WARNING] No new changes or commit already exists
    echo [DEBUG] git commit returned errorlevel %errorlevel%
)
echo [✓] Commit created
echo [DEBUG] Commit operation completed
echo.

echo ========================================
echo 4. Naming Main Branch
echo ========================================
echo [DEBUG] Running: git branch -M main
git branch -M main
if errorlevel 1 (
    echo [WARNING] Failed to rename branch
    echo [DEBUG] git branch failed with errorlevel %errorlevel%
) else (
    echo [✓] Branch renamed to main
    echo [DEBUG] Branch renamed successfully
)
echo.

echo ========================================
echo 5. Connecting Project to GitHub
echo ========================================
echo [DEBUG] Checking for existing origin remote...

:: Check if origin already exists
git remote | findstr /C:"origin" >nul 2>&1
if errorlevel 1 (
    echo [INFO] Connecting project to %REPO_URL%...
    echo [DEBUG] Running: git remote add origin %REPO_URL%
    git remote add origin %REPO_URL%
    if errorlevel 1 (
        echo [ERROR] Failed to connect project!
        echo [DEBUG] git remote add failed with errorlevel %errorlevel%
        pause
        exit /b 1
    )
    echo [✓] Project connected successfully
    echo [DEBUG] Remote origin added
) else (
    echo [WARNING] Remote origin already exists
    echo [INFO] Updating URL...
    echo [DEBUG] Running: git remote set-url origin %REPO_URL%
    git remote set-url origin %REPO_URL%
    echo [✓] URL updated
    echo [DEBUG] Remote origin URL updated
)
echo.

echo ========================================
echo 6. Pushing Files to GitHub
echo ========================================
echo [INFO] Pushing files...
echo [WARNING] You will be prompted for:
echo     - Username: Your GitHub username
echo     - Password: Personal Access Token (NOT your regular password!)
echo.
echo [INFO] To get a Token:
echo     GitHub → Settings → Developer settings → Personal access tokens
echo.
echo [DEBUG] Running: git push -u origin main
git push -u origin main
if errorlevel 1 (
    echo.
    echo [ERROR] Failed to push files!
    echo.
    echo Possible causes:
    echo   1. Incorrect credentials (use Token, not Password)
    echo   2. Incorrect URL
    echo   3. No internet connection
    echo.
    echo To try again, run the command:
    echo   git push -u origin main
    echo.
    echo [DEBUG] Push failed with errorlevel %errorlevel%
    pause
    exit /b 1
)

echo.
echo ========================================
echo ✅ Project pushed successfully!
echo ========================================
echo.
echo You can now visit the project at:
echo %REPO_URL%
echo.
echo For future updates, use: update_github.bat
echo.
echo [DEBUG] Push completed successfully at %DATE% %TIME%
pause

----- END FILE -----

----- FILE: README.md -----
size: 22872 bytes | mtime: 2025-12-28T12:51:36.565615

# RAGMind - Intelligent Document Q&A System

A robust Retrieval-Augmented Generation (RAG) system built with FastAPI that enables document upload, intelligent processing, vector-based similarity search, and AI-powered answer generation. Upload documents (PDF, TXT, DOCX), automatically process them into searchable chunks with embeddings, store in PostgreSQL with pgvector, and retrieve contextual answers powered by Google Gemini for your AI applications.

## 🏗️ Architecture Overview

### Core Components

```
┌─────────────────┐     ┌─────────────────┐     ┌─────────────────┐
│   Web Client    │────▶│   FastAPI API   │────▶│   Controllers   │
│  (Upload/Query) │     │   Routes        │     │  (Business      │
│   + Telegram    │     │                 │     │   Logic)        │
└─────────────────┘     └─────────────────┘     └─────────┬───────┘
                                                           │
                        ┌──────────────────────────────────┼──────────────┐
                        ▼                                  ▼              ▼
                ┌───────────────┐              ┌──────────────┐  ┌──────────────┐
                │  PostgreSQL   │              │ LLM Provider │  │ Vector DB    │
                │  + pgvector   │              │ (Google      │  │ (pgvector/   │
                │  (Chunks,     │              │  Gemini      │  │  Qdrant)     │
                │   Projects,   │              │  2.5 Flash)  │  │              │
                │   Assets)     │              │              │  │              │
                └───────────────┘              └──────────────┘  └──────────────┘
                        ▲                              ▲                  ▲
                        │                              │                  │
                        └──────────┬───────────────────┴──────────────────┘
                                   ▼
                        ┌─────────────────┐     ┌─────────────────┐
                        │   LangChain     │────▶│   Document      │
                        │  Text Splitter  │     │   Loaders       │
                        │  (Chunking)     │     │  (PDF, TXT,     │
                        │                 │     │   DOCX)         │
                        └─────────────────┘     └─────────────────┘
                                   ▲
                                   │
                        ┌─────────────────┐
                        │   File Storage  │
                        │  (Project-based │
                        │   Organization) │
                        └─────────────────┘
```

### Data Flow

```
Document Upload → File validation → Unique naming → Project storage
                                                          ↓
Document Processing → Content extraction → Text chunking → Metadata preservation
                                                          ↓
Data Storage → PostgreSQL (via SQLAlchemy async) → Project organization
                                                          ↓
Vector Embeddings → Gemini Embeddings → Generate embeddings → Store in VectorDB
                                                          ↓
Similarity Search → Query vectors → VectorDB search → Retrieve top-k chunks
                                                          ↓
Answer Generation → Prompt construction → Gemini LLM → AI-powered answers
```

### Provider Architecture

The system uses a **Factory Pattern** for extensible provider management:

#### LLM Providers:
- Abstract `LLMInterface` defines the contract
- `LLMProviderFactory` creates provider instances
- Support for **Google Gemini** (easily extensible to OpenAI, Cohere, etc.)
- Unified API for text generation and embeddings

#### VectorDB Providers:
- Abstract `VectorDBInterface` defines the contract
- `VectorDBProviderFactory` creates provider instances
- **PGVector** implementation for PostgreSQL with pgvector extension
- **Qdrant** implementation for standalone vector storage
- Support for collection management and similarity search
- Configurable distance metrics (cosine, dot product, L2)

## 🛠️ Technical Stack

- **Backend Framework**: FastAPI with async/await patterns and lifespan context management
- **Database**: PostgreSQL with pgvector extension for vector similarity
- **ORM**: SQLAlchemy 2.0 with async support (asyncpg driver)
- **Vector Database**: PGVector (PostgreSQL) or Qdrant for vector storage
- **LLM Provider**: Google Gemini 2.5 Flash for embeddings and text generation
- **Document Processing**: LangChain (text splitting, document loading)
- **PDF Processing**: pypdf for efficient PDF text extraction
- **DOCX Processing**: python-docx for Word document parsing
- **Data Validation**: Pydantic v2 with custom validators
- **File Handling**: aiofiles for async I/O operations
- **Bot Integration**: python-telegram-bot for Telegram interface
- **Python Version**: 3.8+
- **Additional Libraries**: asyncpg, sqlalchemy, alembic, aiofiles, python-dotenv, python-multipart, qdrant-client, google-generativeai, langchain

## 📁 Project Structure

```
RAGMind/
├── backend/                          # Python Backend
│   ├── main.py                       # FastAPI application & lifespan
│   ├── config.py                     # Settings management (Pydantic)
│   ├── requirements.txt              # Python dependencies
│   │
│   ├── routes/                       # API Endpoints
│   │   ├── __init__.py
│   │   ├── health.py                 # Health check endpoints
│   │   ├── projects.py               # Project management
│   │   ├── documents.py              # Document upload/management
│   │   ├── query.py                  # RAG query endpoints
│   │   ├── stats.py                  # Statistics endpoints
│   │   └── bot_config.py             # Telegram bot configuration
│   │
│   ├── controllers/                  # Business Logic Layer
│   │   ├── __init__.py
│   │   ├── project_controller.py     # Project CRUD operations
│   │   ├── document_controller.py    # Document processing logic
│   │   └── query_controller.py       # RAG query logic
│   │
│   ├── services/                     # Core Services
│   │   ├── __init__.py
│   │   ├── document_loader.py        # Document parsing (PDF, TXT, DOCX)
│   │   ├── chunking_service.py       # Text chunking with LangChain
│   │   ├── embedding_service.py      # Generate embeddings
│   │   ├── query_service.py          # Vector similarity search
│   │   ├── answer_service.py         # LLM answer generation
│   │   └── file_service.py           # File upload/storage
│   │
│   ├── database/                     # Database Layer
│   │   ├── __init__.py
│   │   ├── models.py                 # SQLAlchemy ORM models
│   │   ├── connection.py             # Database connection management
│   │   └── init_database.py          # Database initialization
│   │
│   └── providers/                    # External Service Integrations
│       ├── llm/                      # LLM Provider Abstraction
│       │   ├── __init__.py
│       │   ├── interface.py          # LLM interface definition
│       │   ├── factory.py            # Provider factory
│       │   └── gemini_provider.py    # Google Gemini implementation
│       │
│       └── vectordb/                 # Vector DB Abstraction
│           ├── __init__.py
│           ├── interface.py          # VectorDB interface
│           ├── factory.py            # Provider factory
│           ├── pgvector_provider.py  # PostgreSQL pgvector
│           └── qdrant_provider.py    # Qdrant implementation
│
├── frontend/                         # Web Frontend
│   ├── index.html                    # Main HTML (Arabic/English RTL)
│   ├── style.css                     # Styling (dark/light themes)
│   └── app.js                        # Application logic (Vanilla JS)
│
├── telegram_bot/                     # Telegram Bot
│   ├── __init__.py
│   ├── bot.py                        # Bot initialization
│   ├── config.py                     # Bot configuration
│   └── handlers.py                   # Message/command handlers
│
├── uploads/                          # File Storage
│   └── {project_id}/                 # Project-specific directories
│
├── .env                              # Environment variables
├── .env.example                      # Environment template
├── setup.bat                         # Automated setup script
├── start_backend.bat                 # Start backend server
├── start_telegram_bot.bat            # Start Telegram bot
├── create_database.sql               # Database initialization
└── README.md                         # This file
```

## 🚀 API Endpoints

### Health & Stats

| Method | Endpoint | Description |
|--------|----------|-------------|
| GET | `/health` | System health check and status |
| GET | `/stats/` | Get statistics (projects, documents, chunks) |

### Project Management

| Method | Endpoint | Description |
|--------|----------|-------------|
| GET | `/projects/` | List all projects |
| POST | `/projects/` | Create new project |
| GET | `/projects/{id}` | Get project details |
| DELETE | `/projects/{id}` | Delete project and all associated data |
| GET | `/projects/{id}/documents` | List project documents |

### Document Management

| Method | Endpoint | Description |
|--------|----------|-------------|
| POST | `/projects/{id}/documents` | Upload document to project |
| DELETE | `/documents/{id}` | Delete document |
| GET | `/documents/{id}/chunks` | Get document text chunks |

### RAG/Query Endpoints

| Method | Endpoint | Description |
|--------|----------|-------------|
| POST | `/projects/{id}/query` | Query project documents with AI-powered answers |

### Bot Configuration

| Method | Endpoint | Description |
|--------|----------|-------------|
| GET | `/bot/config` | Get Telegram bot configuration |
| POST | `/bot/config` | Update bot active project |
| POST | `/bot/profile` | Update bot profile name |

### Response Structure

All endpoints return JSON responses with consistent structure:

```json
{
  "status": "success",
  "message": "Operation completed successfully",
  "data": {}
}
```

## 📋 Request/Response Examples

### 1. Create Project

```bash
curl -X POST "http://localhost:8000/projects/" \
     -H "Content-Type: application/json" \
     -d '{
       "name": "AI Research Papers",
       "description": "Collection of AI and ML research papers"
     }'
```

**Response:**
```json
{
  "id": 1,
  "name": "AI Research Papers",
  "description": "Collection of AI and ML research papers",
  "created_at": "2025-12-28T10:00:00Z",
  "updated_at": null
}
```

### 2. Upload Document

```bash
curl -X POST "http://localhost:8000/projects/1/documents" \
     -F "file=@research_paper.pdf"
```

**Response:**
```json
{
  "id": 1,
  "project_id": 1,
  "filename": "abc123_research_paper.pdf",
  "original_filename": "research_paper.pdf",
  "file_size": 524288,
  "file_type": "pdf",
  "status": "uploaded",
  "created_at": "2025-12-28T10:05:00Z"
}
```

### 3. Query Documents (RAG)

```bash
curl -X POST "http://localhost:8000/projects/1/query" \
     -H "Content-Type: application/json" \
     -d '{
       "query": "What are the main findings of the research?",
       "language": "en",
       "top_k": 5
     }'
```

**Response:**
```json
{
  "answer": "Based on the research papers, the main findings include: 1) Transformer architectures significantly outperform traditional RNNs in NLP tasks...",
  "sources": [
    {
      "chunk_id": 42,
      "content": "Our experiments demonstrate that...",
      "document_name": "research_paper.pdf",
      "similarity": 0.89
    },
    {
      "chunk_id": 87,
      "content": "The results show significant improvements...",
      "document_name": "research_paper.pdf",
      "similarity": 0.85
    }
  ],
  "context_used": 5
}
```

### 4. Search Similar Documents

```bash
curl -X POST "http://localhost:8000/projects/1/query" \
     -H "Content-Type: application/json" \
     -d '{
       "query": "transformer architecture",
       "language": "en",
       "top_k": 3
     }'
```

**Response:**
```json
{
  "answer": "Transformer architecture is a neural network design...",
  "sources": [
    {
      "chunk_id": 15,
      "content": "The Transformer architecture relies on self-attention mechanisms...",
      "document_name": "attention_is_all_you_need.pdf",
      "similarity": 0.92
    }
  ],
  "context_used": 3
}
```

## 🔧 Configuration

### RAG Workflow

The RAG system follows a complete pipeline:

1. **Upload Documents**: Upload PDF, TXT, or DOCX files to project-specific directories
2. **Process & Chunk**: Extract text and split into semantic chunks with configurable overlap
3. **Generate Embeddings**: Create vector embeddings using Google Gemini
4. **Store Vectors**: Index embeddings in vector database (PGVector or Qdrant)
5. **Query Processing**: Convert user queries into embeddings
6. **Retrieve Context**: Find top-k most relevant document chunks via vector similarity
7. **Generate Answers**: Use Gemini LLM to generate contextual answers

### Key Features

- ✅ **Multi-Provider Support**: Switch between PGVector and Qdrant for vector storage
- ✅ **Bilingual UI**: Arabic and English support with RTL/LTR layouts
- ✅ **Telegram Integration**: Query documents via Telegram bot
- ✅ **Async Processing**: Non-blocking I/O for efficient operations
- ✅ **Flexible Chunking**: Configurable chunk sizes and overlap
- ✅ **Project Isolation**: Separate vector collections per project
- ✅ **Dark/Light Themes**: Modern UI with theme switching
- ✅ **Real-time Processing**: Live status updates for document processing

### Environment Variables

Create a `.env` file in the project root (see `.env.example` for template):

```ini
# Database Configuration
DATABASE_URL=postgresql+asyncpg://postgres:YOUR_PASSWORD@localhost:5432/ragmind

# LLM Provider Configuration
GEMINI_API_KEY=YOUR_GEMINI_API_KEY
LLM_PROVIDER=gemini
GEMINI_MODEL=gemini-2.5-flash

# Vector Database Configuration
VECTOR_DB_PROVIDER=pgvector  # or qdrant
QDRANT_URL=http://localhost:6333
QDRANT_API_KEY=

# Storage Configuration
UPLOAD_DIR=./uploads
MAX_FILE_SIZE_MB=50

# Text Chunking Configuration
CHUNK_SIZE=1000
CHUNK_OVERLAP=200

# API Configuration
API_HOST=0.0.0.0
API_PORT=8000

# Telegram Bot Configuration (Optional)
TELEGRAM_BOT_TOKEN=
TELEGRAM_ADMIN_ID=

# CORS Configuration
CORS_ORIGINS=["http://localhost:3000", "http://localhost:8080"]

# Logging Configuration
LOG_LEVEL=INFO
```

## 📊 Database Schema

### PostgreSQL Tables (with pgvector extension)

#### `projects` Table

```sql
CREATE TABLE projects (
    id SERIAL PRIMARY KEY,
    name VARCHAR(255) NOT NULL,
    description TEXT,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    updated_at TIMESTAMP WITH TIME ZONE,
    metadata JSONB DEFAULT '{}'
);

CREATE INDEX ix_projects_name ON projects(name);
```

#### `assets` Table

```sql
CREATE TABLE assets (
    id SERIAL PRIMARY KEY,
    project_id INTEGER NOT NULL REFERENCES projects(id) ON DELETE CASCADE,
    filename VARCHAR(500) NOT NULL,
    original_filename VARCHAR(500) NOT NULL,
    file_path VARCHAR(1000) NOT NULL,
    file_size INTEGER NOT NULL,
    file_type VARCHAR(50) NOT NULL,
    status VARCHAR(50) DEFAULT 'uploaded',
    error_message TEXT,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    processed_at TIMESTAMP WITH TIME ZONE,
    metadata JSONB DEFAULT '{}'
);

CREATE INDEX ix_assets_project_id ON assets(project_id);
CREATE INDEX ix_assets_status ON assets(status);
```

#### `chunks` Table

```sql
CREATE TABLE chunks (
    id SERIAL PRIMARY KEY,
    project_id INTEGER NOT NULL REFERENCES projects(id) ON DELETE CASCADE,
    asset_id INTEGER NOT NULL REFERENCES assets(id) ON DELETE CASCADE,
    content TEXT NOT NULL,
    chunk_index INTEGER NOT NULL,
    embedding JSONB,
    metadata JSONB DEFAULT '{}',
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

CREATE INDEX ix_chunks_project_id ON chunks(project_id);
CREATE INDEX ix_chunks_asset_id ON chunks(asset_id);
```

### Schema Features

- ✅ **Foreign Keys**: Proper relationships with cascading deletes
- ✅ **JSONB**: Flexible metadata storage
- ✅ **Timestamps**: Automatic tracking of creation/update times
- ✅ **Indexes**: Optimized for common query patterns
- ✅ **Vector Support**: pgvector extension for similarity search

## 📋 Prerequisites & Installation

### Prerequisites

- Python 3.8+
- PostgreSQL 14+ with pgvector extension
- Google Gemini API Key
- (Optional) Qdrant for vector storage
- (Optional) Telegram Bot Token

### Quick Start (Automated)

1. **Clone the repository:**

```bash
git clone https://github.com/yourusername/RAGMind.git
cd RAGMind
```

2. **Run the automated setup script:**

```bash
setup.bat
```

The setup script will:
- ✅ Check Python installation
- ✅ Create virtual environment
- ✅ Install all dependencies
- ✅ Create `.env` file from template
- ✅ Create necessary directories
- ✅ Guide database setup

3. **Configure environment variables:**

Edit `.env` file and add:
- `DATABASE_URL`
- `GEMINI_API_KEY`
- (Optional) `TELEGRAM_BOT_TOKEN`

4. **Setup PostgreSQL:**

```sql
CREATE DATABASE ragmind;
\c ragmind
CREATE EXTENSION vector;
```

5. **Initialize database tables:**

```bash
python -m backend.init_database
```

6. **Start the application:**

```bash
start_backend.bat
```

7. **Access the application:**
- Web UI: http://localhost:8000
- API Docs: http://localhost:8000/docs
- ReDoc: http://localhost:8000/redoc

### Manual Installation

```bash
# 1. Create virtual environment
python -m venv venv
source venv/bin/activate  # Linux/Mac
venv\Scripts\activate     # Windows

# 2. Install dependencies
pip install -r backend/requirements.txt

# 3. Create .env file
cp .env.example .env
# Edit .env with your credentials

# 4. Setup PostgreSQL
# Create database and install pgvector extension

# 5. Initialize database
python -m backend.init_database

# 6. Run the application
uvicorn backend.main:app --reload --host 0.0.0.0 --port 8000
```

## 🧪 Testing - Complete RAG Workflow

### Step-by-Step Testing

```bash
# 1. Create a project
curl -X POST "http://localhost:8000/projects/" \
     -H "Content-Type: application/json" \
     -d '{
       "name": "Test Project",
       "description": "Testing RAG workflow"
     }'

# 2. Upload a PDF document
curl -X POST "http://localhost:8000/projects/1/documents" \
     -F "file=@sample.pdf"

# 3. Wait for automatic processing (status will change to 'completed')
# Check document status:
curl "http://localhost:8000/projects/1/documents"

# 4. Query the documents
curl -X POST "http://localhost:8000/projects/1/query" \
     -H "Content-Type: application/json" \
     -d '{
       "query": "What is the main topic?",
       "language": "en",
       "top_k": 5
     }'

# 5. Verify data in PostgreSQL
psql -U postgres -d ragmind
# SELECT COUNT(*) FROM chunks WHERE project_id = 1;
# SELECT * FROM assets WHERE project_id = 1;
```

### Testing Telegram Bot

1. Start the bot:
```bash
start_telegram_bot.bat
```

2. Configure active project in web UI:
- Go to "Bot Settings"
- Select active project
- Save configuration

3. Chat with bot on Telegram:
```
/start
Ask any question about your documents
```

## 🔐 Security Considerations

- ✅ **API Keys**: Stored in `.env` file (gitignored)
- ✅ **CORS**: Configured for allowed origins only
- ✅ **File Validation**: Type and size checks on upload
- ✅ **Database**: Async connection pooling with SQLAlchemy
- ✅ **Error Handling**: Graceful error messages without sensitive data
- ✅ **SQL Injection**: Protected by SQLAlchemy ORM

## 🐛 Troubleshooting

### Common Issues

**Database Connection Error:**
```
✓ Ensure PostgreSQL is running
✓ Verify DATABASE_URL in .env
✓ Check pgvector extension is installed
```

**Gemini API Error:**
```
✓ Verify GEMINI_API_KEY is valid
✓ Check API quota/limits
✓ Ensure internet connection
```

**File Upload Fails:**
```
✓ Check upload directory has write permissions
✓ Verify file type is supported (PDF, TXT, DOCX)
✓ Ensure file size under MAX_FILE_SIZE_MB
```

**Vector Search Returns No Results:**
```
✓ Verify documents are processed (status='completed')
✓ Check embeddings are generated
✓ Confirm Vector DB connection
```

## 📝 License

This project is licensed under the MIT License. See [LICENSE](LICENSE) file for details.

## 👥 Contributors

**Abdulmoezz Elwakil** ([@AbdulmoezzElwakil](https://github.com/ZozElwakil))

---

**Built with ❤️ for EELU University Project**

----- END FILE -----

----- FILE: scripts\extract_all.py -----
size: 5470 bytes | mtime: 2025-12-30T08:22:09.737498

"""Concatenate project files into a single text file.

Usage examples:
  python scripts/extract_all.py --root . --output all_code.txt
  python scripts/extract_all.py --root . --output ALL_CODE.txt --ext .py,.js,.html --skip-dirs venv,node_modules --max-size 5242880

Features:
- Skips common ignored directories by default (.git, venv, __pycache__, node_modules, etc.)
- Skips binary files and files larger than --max-size (default 5MB)
- Allows specifying extensions (comma-separated) or use --all to include every file (text-only)
- Adds headers with relative path, size and mtime for each file
"""

from __future__ import annotations
import argparse
import os
from pathlib import Path
from datetime import datetime

DEFAULT_EXTS = [
    ".py", ".js", ".ts", ".jsx", ".tsx", ".html", ".css", ".md", ".txt",
    ".json", ".yml", ".yaml", ".sql", ".ini", ".cfg", ".bat", ".sh", ".ps1",
    ".java", ".c", ".cpp", ".h", ".hpp", ".rb", ".go", ".rs", ".php"
]

DEFAULT_SKIP_DIRS = {".git", "venv", "env", "__pycache__", "node_modules", ".venv", ".idea", ".vscode", ".pytest_cache", ".mypy_cache", "qdrant_data", "qdrant_data_test"}

def is_binary_file(p: Path) -> bool:
    try:
        with p.open("rb") as f:
            chunk = f.read(1024)
            if b"\0" in chunk:
                return True
            # heuristic: check for large proportion of non-text bytes
            textchars = bytearray({7,8,9,10,12,13,27} | set(range(0x20, 0x100)))
            return bool(chunk) and sum(c not in textchars for c in chunk) / len(chunk) > 0.30
    except Exception:
        return True


def gather_files(root: Path, include_exts: set[str] | None, skip_dirs: set[str], include_all: bool, max_size: int, output_path: Path) -> list[Path]:
    files = []
    for dirpath, dirnames, filenames in os.walk(root):
        # Filter out skip dirs in-place for os.walk
        dirnames[:] = [d for d in dirnames if d not in skip_dirs]
        for fn in filenames:
            file_path = Path(dirpath) / fn
            # skip the output file itself
            if output_path and file_path.resolve() == output_path.resolve():
                continue
            # skip hidden system files like .DS_Store
            if fn in {".DS_Store"}:
                continue
            try:
                if file_path.is_dir():
                    continue
            except Exception:
                continue
            # size limit
            try:
                size = file_path.stat().st_size
            except Exception:
                continue
            if size > max_size:
                continue
            if not include_all:
                if include_exts and file_path.suffix.lower() not in include_exts:
                    continue
            # skip binary
            if is_binary_file(file_path):
                continue
            files.append(file_path)
    files.sort()
    return files


def write_output(files: list[Path], root: Path, out_file: Path):
    written = 0
    with out_file.open("w", encoding="utf-8", errors="replace") as out:
        for p in files:
            try:
                rel = p.relative_to(root)
            except Exception:
                rel = p
            stat = p.stat()
            header = f"\n----- FILE: {rel} -----\nsize: {stat.st_size} bytes | mtime: {datetime.fromtimestamp(stat.st_mtime).isoformat()}\n\n"
            out.write(header)
            with p.open("r", encoding="utf-8", errors="replace") as f:
                for line in f:
                    out.write(line)
            out.write("\n----- END FILE -----\n")
            written += 1
    return written


def parse_args():
    p = argparse.ArgumentParser(description="Concatenate project files into a single file.")
    p.add_argument("--root", default='.', help="Root directory to scan (default: .)")
    p.add_argument("--output", default='ALL_CODE.txt', help="Output filename (default: ALL_CODE.txt)")
    p.add_argument("--ext", default=','.join(DEFAULT_EXTS), help="Comma-separated extensions to include (default: common code/text extensions). Use e.g. '.py,.js' or empty for none")
    p.add_argument("--all", action='store_true', help="Include all text files regardless of extension (skips binary)")
    p.add_argument("--skip-dirs", default=','.join(sorted(DEFAULT_SKIP_DIRS)), help="Comma-separated directories to skip (default: common dirs)")
    p.add_argument("--max-size", type=int, default=5*1024*1024, help="Maximum file size in bytes to include (default: 5MB)")
    return p.parse_args()


def main():
    args = parse_args()
    root = Path(args.root).resolve()
    out = Path(args.output).resolve()
    include_all = args.all
    include_exts = None if include_all else {ext.strip().lower() for ext in args.ext.split(',') if ext.strip()}
    skip_dirs = {d.strip() for d in args.skip_dirs.split(',') if d.strip()}

    print(f"Scanning {root} (include_all={include_all})...")
    files = gather_files(root, include_exts, skip_dirs, include_all, args.max_size, out)
    print(f"Found {len(files)} files to include.")
    if not files:
        print("No files to write. Exiting.")
        return 1
    print(f"Writing to {out} ...")
    written = write_output(files, root, out)
    print(f"Done. Wrote {written} files into {out}.")
    return 0

if __name__ == '__main__':
    raise SystemExit(main())
----- END FILE -----

----- FILE: setup.bat -----
size: 10370 bytes | mtime: 2025-12-28T18:16:01.982472

@echo off
setlocal EnableExtensions EnableDelayedExpansion

chcp 65001 >nul
color 0A
title RAGMind - Setup

:: Ensure we run from the script directory (project root)
set "ROOT=%~dp0"
pushd "%ROOT%" >nul

echo ========================================
echo    RAGMind - Setup Script
echo    Installing all project requirements
echo ========================================
echo.
echo [DEBUG] Script started at %DATE% %TIME%
echo [INFO] Project root: "%CD%"
echo [DEBUG] Current user: %USERNAME%
echo [DEBUG] Windows version: %OS%
echo.

:: Check if Python is installed
echo [DEBUG] Checking Python installation...
python --version >nul 2>&1
if errorlevel 1 (
    echo [ERROR] Python is not installed on this system!
    echo Please install Python 3.8 or later from: https://www.python.org/
    echo [DEBUG] Python check failed with errorlevel %errorlevel%
    pause
    popd
    exit /b 1
)

echo [✓] Python installed:
python --version
echo [DEBUG] Python check passed
echo.

:: Optional: Check if psql exists (non-blocking)
echo [DEBUG] Checking PostgreSQL client installation...
where psql >nul 2>&1
if errorlevel 1 (
    echo [WARNING] psql not found in PATH. Make sure PostgreSQL is installed and running.
    echo          Download from: https://www.postgresql.org/download/
    echo [DEBUG] psql check returned errorlevel %errorlevel%
) else (
    echo [✓] PostgreSQL client (psql) found
    echo [DEBUG] psql check passed
)
echo.

:: Create virtual environment
echo ========================================
echo 1. Creating Virtual Environment
echo ========================================
echo [DEBUG] Checking for existing virtual environment...
if exist "venv\" (
    echo [WARNING] Virtual environment already exists: "%CD%\venv"
    echo [DEBUG] Virtual environment directory found
    choice /C YN /M "Do you want to recreate it?"
    if errorlevel 2 (
        echo [INFO] Skipping virtual environment creation
        goto skip_venv
    )
    echo [INFO] Deleting existing virtual environment...
    rmdir /s /q "venv"
    if errorlevel 1 (
        echo [ERROR] Failed to delete existing virtual environment!
        echo [DEBUG] rmdir failed with errorlevel %errorlevel%
        pause
        popd
        exit /b 1
    )
    echo [DEBUG] Old virtual environment deleted
)

echo [INFO] Creating new virtual environment...
echo [DEBUG] Running: python -m venv "venv"
python -m venv "venv"
if errorlevel 1 (
    echo [ERROR] Failed to create virtual environment!
    echo [DEBUG] venv creation failed with errorlevel %errorlevel%
    pause
    popd
    exit /b 1
)
echo [✓] Virtual environment created successfully
echo [DEBUG] Virtual environment created at: "%CD%\venv"
echo.

:skip_venv

:: Activate virtual environment
echo ========================================
echo 2. Activating Virtual Environment
echo ========================================
echo [DEBUG] Checking for activation script...
if not exist "venv\Scripts\activate.bat" (
    echo [ERROR] Activation script not found: venv\Scripts\activate.bat
    echo [DEBUG] Activation script missing - venv may be corrupted
    pause
    popd
    exit /b 1
)
echo [DEBUG] Activating virtual environment...
call "venv\Scripts\activate.bat"
if errorlevel 1 (
    echo [ERROR] Failed to activate virtual environment!
    echo [DEBUG] Activation failed with errorlevel %errorlevel%
    pause
    popd
    exit /b 1
)
echo [✓] Virtual environment activated
echo [DEBUG] Python executable now: %VIRTUAL_ENV%\Scripts\python.exe
echo.

:: Upgrade pip and install uv (use python -m pip to guarantee venv pip)
echo ========================================
echo 3. Upgrading pip and installing uv
echo ========================================
echo [DEBUG] Upgrading pip and installing uv...
python -m pip install --upgrade pip uv
if errorlevel 1 (
    echo [ERROR] Failed to upgrade pip or install uv
    echo [DEBUG] pip/uv installation failed with errorlevel %errorlevel%
    pause
    popd
    exit /b 1
)
echo [✓] pip upgraded and uv installed
echo [DEBUG] Checking uv version...
uv --version
echo.

:: Resolve requirements file
echo ========================================
echo 4. Installing Required Libraries (may take a few minutes...)
echo ========================================
echo [DEBUG] Looking for requirements file...
set "REQ_FILE="

if exist "backend\requirements.txt" (
    set "REQ_FILE=backend\requirements.txt"
    echo [DEBUG] Found backend\requirements.txt
)
if not defined REQ_FILE if exist "requirements.txt" (
    set "REQ_FILE=requirements.txt"
    echo [DEBUG] Found requirements.txt
)

if not defined REQ_FILE (
    echo [ERROR] Requirements file not found:
    echo        - backend\requirements.txt
    echo        - requirements.txt
    echo.
    echo [INFO] Current directory contents:
    dir /b
    echo.
    if exist "backend\" (
        echo [INFO] Backend directory contents:
        dir /b "backend"
    ) else (
        echo [WARNING] Backend directory does not exist
    )
    echo [DEBUG] Requirements file search failed
    pause
    popd
    exit /b 1
)

echo [INFO] Will install from: "%REQ_FILE%"
echo [DEBUG] Starting package installation with uv...
uv pip install -r "%REQ_FILE%"
if errorlevel 1 (
    echo [ERROR] Failed to install libraries!
    echo Check requirements file and internet connection
    echo [DEBUG] uv pip install failed with errorlevel %errorlevel%
    pause
    popd
    exit /b 1
)
echo [✓] All libraries installed successfully
echo [DEBUG] Package installation completed
echo.

:: Create .env file if not exists
echo ========================================
echo 5. Creating Configuration File (.env)
echo ========================================
echo [DEBUG] Checking for existing .env file...
if exist ".env" (
    echo [WARNING] .env file already exists
    echo [DEBUG] .env file found at: "%CD%\.env"
    choice /C YN /M "Do you want to recreate it from template?"
    if errorlevel 2 (
        echo [INFO] Skipping .env creation
        goto skip_env
    )
)

if exist ".env.example" (
    echo [INFO] Copying settings from .env.example...
    echo [DEBUG] Copying .env.example to .env
    copy /Y ".env.example" ".env" >nul
    if errorlevel 1 (
        echo [ERROR] Failed to copy .env.example!
        echo [DEBUG] Copy failed with errorlevel %errorlevel%
        pause
        popd
        exit /b 1
    )
    echo [✓] .env file created
    echo [WARNING] Please edit .env file and add:
    echo     - DATABASE_URL
    echo     - GEMINI_API_KEY
    echo     - TELEGRAM_BOT_TOKEN (optional)
    echo [DEBUG] .env file created successfully
) else (
    echo [WARNING] .env.example file not found
    echo Please create .env file manually with required settings
    echo [DEBUG] .env.example not found
)
echo.

:skip_env

:: Create directories
echo ========================================
echo 6. Creating Project Directories
echo ========================================
echo [DEBUG] Creating uploads directory...
if not exist "uploads\" (
    mkdir "uploads"
    echo [DEBUG] Created uploads directory
) else (
    echo [DEBUG] uploads directory already exists
)
echo [✓] uploads directory ready

echo [DEBUG] Creating qdrant_data directory...
if not exist "qdrant_data\" (
    mkdir "qdrant_data"
    echo [DEBUG] Created qdrant_data directory
) else (
    echo [DEBUG] qdrant_data directory already exists
)
echo [✓] qdrant_data directory ready
echo.

:: Database setup instructions
echo ========================================
echo 7. Database Setup
echo ========================================
echo [WARNING] PostgreSQL must be set up manually:
echo.
echo     1. Start PostgreSQL service
echo     2. Open pgAdmin or psql
echo     3. Run these commands:
echo        CREATE DATABASE ragmind;
echo        \c ragmind
echo        CREATE EXTENSION vector;
echo.
echo     4. Update DATABASE_URL in .env file
echo.
echo [DEBUG] Database setup instructions displayed
choice /C YN /M "Have you set up the database?"
if errorlevel 2 (
    echo [WARNING] Please set up the database before running the project
    echo [DEBUG] User chose not to confirm database setup
) else (
    echo [✓] Database is ready
    echo [DEBUG] User confirmed database setup
)
echo.

:: Initialize database
echo ========================================
echo 8. Initializing Database Tables
echo ========================================
echo [DEBUG] Prompting for database initialization...
choice /C YN /M "Do you want to initialize database tables now?"
if errorlevel 2 goto skip_db_init

echo [INFO] Initializing database...
echo [DEBUG] Running: python -m backend.init_database
python -m backend.init_database
if errorlevel 1 (
    echo [ERROR] Database initialization failed
    echo Please check:
    echo   - PostgreSQL connection
    echo   - DATABASE_URL in .env file
    echo   - pgvector extension installed (CREATE EXTENSION vector;)
    echo [DEBUG] Database init failed with errorlevel %errorlevel%
) else (
    echo [✓] Database initialized successfully
    echo [DEBUG] Database initialization completed
)
goto after_db_init

:skip_db_init
echo [INFO] You can initialize the database later with:
echo     python -m backend.init_database
echo [DEBUG] Database initialization skipped by user

:after_db_init
echo.

:: Summary
echo ========================================
echo ✅ Setup Complete!
echo ========================================
echo.
echo Next Steps:
echo -----------
echo 1. Edit .env file and add:
echo    - DATABASE_URL (required)
echo    - GEMINI_API_KEY (required)
echo    - TELEGRAM_BOT_TOKEN (optional)
echo.
echo 2. To run the project:
echo    - Start Backend: start_backend.bat
echo    - Start Telegram Bot: start_telegram_bot.bat (optional)
echo.
echo 3. Open browser at: http://localhost:8000
echo.
echo ========================================
echo 📚 For more information, see README.md
echo ========================================
echo.
echo [DEBUG] Setup script completed at %DATE% %TIME%
echo [DEBUG] Exit code: 0
pause

popd >nul
pause
endlocal

----- END FILE -----

----- FILE: start_backend.bat -----
size: 4771 bytes | mtime: 2025-12-30T08:09:00.634995

@echo off
setlocal EnableExtensions EnableDelayedExpansion

REM ========================================
REM RAGMind Backend Startup Script
REM ========================================

echo ========================================
echo    RAGMind Backend Server
echo ========================================
echo.
echo [DEBUG] Script started at %DATE% %TIME%
echo [DEBUG] User: %USERNAME%
echo.

REM --- Always run from script directory ---
set "SCRIPT_DIR=%~dp0"
pushd "%SCRIPT_DIR%" >nul
echo [DEBUG] Script directory: "%SCRIPT_DIR%"
echo [DEBUG] Current directory: "%CD%"
echo.

REM --- Check if virtual environment exists ---
if not exist "venv\Scripts\activate.bat" (
    echo ERROR: Virtual environment not found!
    echo Please run setup.bat first to set up the project.
    echo Expected: "%CD%\venv\Scripts\activate.bat"
    pause
    popd
    exit /b 1
)

REM --- Check if .env exists ---
if not exist ".env" (
    echo ERROR: .env file not found!
    echo Please run setup.bat to create the configuration file.
    pause
    popd
    exit /b 1
)

REM --- Activate virtual environment ---
echo Activating virtual environment...
call "venv\Scripts\activate.bat"
if errorlevel 1 (
    echo ERROR: Failed to activate virtual environment!
    pause
    popd
    exit /b 1
)
echo.

REM --- Quick sanity: show python path/version ---
python -c "import sys; print('[DEBUG] Python:', sys.executable); print('[DEBUG] Version:', sys.version.split()[0])"
echo.

REM --- Check configuration (Gemini key) ---
echo Checking configuration...
python -c "from backend.config import settings; assert settings.gemini_api_key, 'GEMINI_API_KEY not set in .env'" 2>nul
if errorlevel 1 (
    echo.
    echo ERROR: GEMINI_API_KEY not configured!
    echo Please set GEMINI_API_KEY in the .env file
    echo Get your key from: https://makersuite.google.com/app/apikey
    echo.
    pause
    popd
    exit /b 1
)
echo [✓] Configuration OK
echo.

REM --- Print DATABASE_URL safely (mask password) ---
echo [DEBUG] Reading DATABASE_URL from backend.config (masked)...
python -c "import re; from backend.config import settings; u=str(getattr(settings,'database_url','')); print('[DEBUG] DATABASE_URL =', re.sub(r':([^:@/]+)@', ':***@', u) if u else '<EMPTY>')"
echo.

REM --- Ensure DATABASE_URL exists and prefer 127.0.0.1 instead of localhost ---
REM (Avoid ipv6 ::1 edge cases and make behavior consistent)
python -c "from backend.config import settings; assert getattr(settings,'database_url',None), 'DATABASE_URL not set in .env'" 2>nul
if errorlevel 1 (
    echo ERROR: DATABASE_URL not set in .env
    echo Please set DATABASE_URL, e.g.:
    echo   DATABASE_URL=postgresql+asyncpg://postgres:saeed@127.0.0.1:5432/ragmind
    pause
    popd
    exit /b 1
)

REM If .env still has localhost, patch it in-place to 127.0.0.1 (safe, local dev)
findstr /I "DATABASE_URL=.*@localhost:" ".env" >nul
if not errorlevel 1 (
    echo [DEBUG] Detected localhost in .env DATABASE_URL - rewriting to 127.0.0.1 for stability...
    powershell -NoProfile -Command ^
      "$p='.env'; $c=Get-Content $p -Raw; $c=$c -replace '@localhost:', '@127.0.0.1:'; Set-Content -Path $p -Value $c -NoNewline"
    echo [✓] Updated .env: localhost -^> 127.0.0.1
    echo.
)

REM --- Smoke test DB connectivity using asyncpg (fast & reliable) ---
echo Testing database connectivity...
python -c "import asyncio; import asyncpg; from backend.config import settings; async def t(): c=await asyncpg.connect(str(settings.database_url)); v=await c.fetchval('select 1'); await c.close(); print('[✓] DB OK, select 1 ->', v); asyncio.run(t())"
if errorlevel 1 (
    echo.
    echo ERROR: Database connectivity test failed!
    echo - Ensure PostgreSQL is running
    echo - Ensure user/password are correct in .env DATABASE_URL
    echo - Ensure database exists (ragmind)
    echo.
    pause
    popd
    exit /b 1
)
echo.

REM --- Initialize database ---
echo Initializing database...
python backend\init_database.py
if errorlevel 1 (
    echo.
    echo ERROR: Database initialization failed!
    echo Please ensure PostgreSQL is running and configured correctly.
    echo Check DATABASE_URL in .env file
    echo.
    pause
    popd
    exit /b 1
)
echo [✓] Database initialized
echo.

REM --- Start server ---
echo Starting FastAPI server...
echo Server will be available at: http://localhost:8000
echo API docs at: http://localhost:8000/docs
echo.
echo [DEBUG] Starting uvicorn server...
echo [DEBUG] Command: python -m uvicorn backend.main:app --reload --host 0.0.0.0 --port 8000
python -m uvicorn backend.main:app --reload --host 0.0.0.0 --port 8000

popd
endlocal

----- END FILE -----

----- FILE: start_telegram_bot.bat -----
size: 1511 bytes | mtime: 2025-12-28T18:16:01.982472

@echo off
REM RAGMind Telegram Bot Startup Script

echo ========================================
echo    RAGMind Telegram Bot
echo ========================================
echo.
echo [DEBUG] Script started at %DATE% %TIME%
echo [DEBUG] Current directory: "%CD%"
echo [DEBUG] User: %USERNAME%
echo.
REM Check if .env exists
if not exist ".env" (
    echo ERROR: .env file not found!
    echo Please run setup.bat to create the configuration file.
    pause
    exit /b 1
)

REM Activate virtual environment
if not exist "venv" (
    echo ERROR: Virtual environment not found!
    echo Please run start_backend.bat first to create it.
    pause
    exit /b 1
)

echo Activating virtual environment...
call venv\Scripts\activate.bat
if errorlevel 1 (
    echo ERROR: Failed to activate virtual environment!
    pause
    exit /b 1
)
echo.

REM Check if bot token is configured
echo Checking configuration...
python -c "from backend.config import settings; assert settings.telegram_bot_token, 'TELEGRAM_BOT_TOKEN not set in .env'" 2>nul
if errorlevel 1 (
    echo.
    echo ERROR: Telegram bot token not configured!
    echo Please set TELEGRAM_BOT_TOKEN in the .env file
    echo Get token from @BotFather on Telegram
    echo.
    pause
    exit /b 1
)
echo [✓] Bot token configured
echo.

REM Start bot
echo Starting Telegram bot...
echo.
echo [DEBUG] Starting Telegram bot...
echo [DEBUG] Command: python -m telegram_bot.bot
python -m telegram_bot.bot

----- END FILE -----

----- FILE: telegram_bot\__init__.py -----
size: 67 bytes | mtime: 2025-12-28T12:51:36.633696

"""Telegram bot package initialization."""
__version__ = "1.0.0"

----- END FILE -----

----- FILE: telegram_bot\bot.py -----
size: 1971 bytes | mtime: 2025-12-28T18:16:01.984524

"""
RAGMind Telegram Bot.
Main bot application using pyTelegramBotAPI.
"""
import telebot
from telegram_bot.config import bot_settings
from telegram_bot import handlers
import logging

# Configure logging
logging.basicConfig(
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    level=logging.INFO
)
logger = logging.getLogger(__name__)

logger.info("🤖 Initializing RAGMind Telegram Bot...")

# Initialize bot
try:
    bot = telebot.TeleBot(bot_settings.telegram_bot_token)
    logger.info("✅ Bot initialized successfully")
except Exception as e:
    logger.error(f"❌ Failed to initialize bot: {str(e)}")
    raise

def print_bot_link():
    """Print bot link to console."""
    try:
        bot_info = bot.get_me()
        bot_link = f"https://t.me/{bot_info.username}"
        logger.info(f"Bot is running! Share this link: {bot_link}")
    except Exception as e:
        logger.error(f"Error getting bot info: {str(e)}")

def setup_handlers():
    """Register all handlers."""
    # Pass bot instance to handlers
    handlers.set_bot(bot)
    
    # Command handlers
    bot.message_handler(commands=['start'])(handlers.start_command)
    bot.message_handler(commands=['help'])(handlers.help_command)
    
    # Text message handler (for queries)
    bot.message_handler(func=lambda message: True)(handlers.handle_message)

def main():
    """Start the bot."""
    logger.info("Setting up message handlers...")
    setup_handlers()
    logger.info("✅ Handlers registered")
    
    print_bot_link()
    
    logger.info("🚀 Starting RAGMind Telegram Bot...")
    logger.info("Bot will run indefinitely (infinity_polling)")
    try:
        bot.infinity_polling()
    except KeyboardInterrupt:
        logger.info("Bot stopped by user (Ctrl+C)")
    except Exception as e:
        logger.error(f"Bot crashed: {str(e)}")
        raise

if __name__ == "__main__":
    main()

----- END FILE -----

----- FILE: telegram_bot\config.py -----
size: 985 bytes | mtime: 2025-12-28T12:51:36.638222

"""
Telegram Bot Configuration.
Loads bot settings from environment.
"""
from pydantic_settings import BaseSettings, SettingsConfigDict
from pydantic import Field
from pathlib import Path

# Get project root directory
ROOT_DIR = Path(__file__).resolve().parent.parent
ENV_FILE = ROOT_DIR / ".env"

class BotSettings(BaseSettings):
    """Bot configuration settings."""
    
    telegram_bot_token: str = Field(default="", alias="TELEGRAM_BOT_TOKEN")
    telegram_admin_id: str = Field(default="", alias="TELEGRAM_ADMIN_ID")
    api_base_url: str = Field(default="http://localhost:8000", alias="API_BASE_URL")
    
    model_config = SettingsConfigDict(
        env_file=str(ENV_FILE),
        env_file_encoding="utf-8",
        case_sensitive=False,
        extra="ignore"
    )


# Global settings instance
try:
    bot_settings = BotSettings()
except Exception:
    # Fallback to defaults if .env fails
    bot_settings = BotSettings(_env_file=None)

----- END FILE -----

----- FILE: telegram_bot\handlers.py -----
size: 3368 bytes | mtime: 2025-12-28T12:51:36.639221

"""
Telegram Bot Handlers.
Command and message handlers for the bot using pyTelegramBotAPI.
"""
import httpx
from telegram_bot.config import bot_settings
import logging
import json
import os

logger = logging.getLogger(__name__)

# Bot instance (will be set from bot.py)
bot = None

CONFIG_FILE = "bot_config.json"

def set_bot(bot_instance):
    global bot
    bot = bot_instance

def get_active_project():
    """Get active project ID from config."""
    if os.path.exists(CONFIG_FILE):
        try:
            with open(CONFIG_FILE, "r") as f:
                config = json.load(f)
                return config.get("active_project_id")
        except:
            return None
    return None

def start_command(message):
    """Handle /start command."""
    bot.reply_to(
        message,
        "مرحباً بك في RAGMind Bot! 🤖\n\n"
        "أنا هنا للإجابة على أسئلتك بناءً على المشروع النشط.\n"
        "فقط أرسل سؤالك وسأجيب فوراً."
    )

def help_command(message):
    """Handle /help command."""
    bot.reply_to(
        message,
        "📚 دليل الاستخدام\n\n"
        "فقط أرسل سؤالك كتابةً وسأقوم بالبحث في مستندات المشروع النشط والإجابة عليك.\n"
        "لا توجد أوامر معقدة!"
    )

def handle_message(message):
    """Handle text messages (queries)."""
    # Ignore commands
    if message.text.startswith('/'):
        return
    
    project_id = get_active_project()
    
    if not project_id:
        bot.reply_to(
            message,
            "⚠️ عذراً، البوت غير مرتبط بمشروع حالياً.\n"
            "يرجى التواصل مع المسؤول لتحديد مشروع نشط."
        )
        return
    
    query = message.text
    
    # Send thinking message
    thinking_msg = bot.reply_to(message, "🤔 جاري البحث عن الإجابة...")
    
    try:
        # Query API
        with httpx.Client() as client:
            response = client.post(
                f"{bot_settings.api_base_url}/projects/{project_id}/query",
                json={
                    "query": query,
                    "top_k": 5,
                    "language": "ar"
                },
                timeout=60.0
            )
            response.raise_for_status()
            result = response.json()
        
        # Format answer
        answer = f"💡 الإجابة:\n\n{result['answer']}\n\n"
        
        if result.get('sources'):
            answer += "📚 المصادر:\n"
            for i, source in enumerate(result['sources'][:3], 1):
                answer += f"{i}. {source['document_name']} "
                answer += f"({source['similarity']:.1%})\n"
        
        bot.edit_message_text(
            answer,
            chat_id=message.chat.id,
            message_id=thinking_msg.message_id
        )
        
    except Exception as e:
        logger.error(f"Error querying: {str(e)}")
        bot.edit_message_text(
            f"❌ حدث خطأ في معالجة السؤال: {str(e)}",
            chat_id=message.chat.id,
            message_id=thinking_msg.message_id
        )

----- END FILE -----

----- FILE: test_qdrant.py -----
size: 657 bytes | mtime: 2025-12-28T12:51:36.639221

from qdrant_client import QdrantClient
import os

try:
    path = "./qdrant_data_test"
    if not os.path.exists(path):
        os.makedirs(path)
    
    print(f"Initializing Qdrant at {path}...")
    client = QdrantClient(path=path)
    print("Success!")
    
    # Try to create a collection
    from qdrant_client.models import Distance, VectorParams
    client.create_collection(
        collection_name="test",
        vectors_config=VectorParams(size=768, distance=Distance.COSINE)
    )
    print("Collection created!")
    
except Exception as e:
    print(f"Error: {str(e)}")
    import traceback
    traceback.print_exc()

----- END FILE -----

----- FILE: update_github.bat -----
size: 2481 bytes | mtime: 2025-12-28T18:16:01.984524

@echo off
chcp 65001 >nul
color 0E
echo ========================================
echo    RAGMind - Update GitHub
echo    Update project on GitHub
echo ========================================
echo.
echo [DEBUG] Script started at %DATE% %TIME%
echo [DEBUG] Current directory: "%CD%"

:: Check if Git is initialized
if not exist ".git\" (
    echo [ERROR] Project is not connected to Git!
    echo Please run push_to_github.bat first
    echo [DEBUG] .git directory not found
    pause
    exit /b 1
)
echo [DEBUG] Git repository found
echo.

echo ========================================
echo 1. Adding New Changes
echo ========================================
echo [DEBUG] Running: git add .
git add .
echo [✓] Changes added
echo [DEBUG] Files staged
echo.

echo ========================================
echo 2. Showing Changed Files
echo ========================================
echo [DEBUG] Running: git status --short
git status --short
echo [DEBUG] Status displayed
echo.

echo ========================================
echo 3. Creating Commit
echo ========================================
set /p COMMIT_MSG="Enter description of changes: "
if "%COMMIT_MSG%"=="" set COMMIT_MSG=Update project files
echo [DEBUG] Commit message: "%COMMIT_MSG%"

echo [DEBUG] Running: git commit -m "%COMMIT_MSG%"
git commit -m "%COMMIT_MSG%"
if errorlevel 1 (
    echo [WARNING] No new changes to commit
    echo [DEBUG] git commit returned errorlevel %errorlevel%
    echo.
    choice /C YN /M "Do you want to continue anyway?"
    if errorlevel 2 (
        echo [INFO] Cancelled
        echo [DEBUG] User cancelled operation
        pause
        exit /b 0
    )
)
echo [✓] Commit created
echo [DEBUG] Commit operation completed
echo.

echo ========================================
echo 4. Pushing Updates to GitHub
echo ========================================
echo [INFO] Pushing updates...
echo [DEBUG] Running: git push
git push
if errorlevel 1 (
    echo.
    echo [ERROR] Failed to push updates!
    echo.
    echo Try the following command:
    echo   git pull origin main --rebase
    echo   git push
    echo.
    echo [DEBUG] Push failed with errorlevel %errorlevel%
    pause
    exit /b 1
)

echo.
echo ========================================
echo ✅ Project updated successfully!
echo ========================================
echo.
echo [DEBUG] Update completed at %DATE% %TIME%
pause

----- END FILE -----
